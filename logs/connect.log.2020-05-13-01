[2020-05-13 01:00:04,239] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:00:04,418] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:00:14,418] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:00:14,418] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:00:24,418] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:00:24,419] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:00:34,419] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:00:34,419] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:00:44,419] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:00:44,420] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:00:54,420] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:00:54,420] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:01:04,420] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:01:04,420] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:01:14,421] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:01:14,421] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:01:24,421] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:01:24,421] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:01:34,422] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:01:34,422] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:01:44,422] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:01:44,433] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:01:54,434] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:01:54,434] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:02:04,435] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:02:04,436] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:02:14,437] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:02:14,437] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:02:24,438] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:02:24,438] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:02:34,438] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:02:34,438] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:02:44,439] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:02:44,439] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:02:54,439] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:02:54,439] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:03:04,440] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:03:04,440] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:03:14,440] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:03:14,441] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:03:24,442] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:03:24,444] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:03:34,444] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:03:34,445] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:03:44,445] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:03:44,445] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:03:54,446] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:03:54,446] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:04:04,446] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:04:04,462] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:04:14,463] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:04:14,463] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:04:24,463] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:04:24,463] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:04:34,463] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:04:34,464] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:04:44,464] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:04:44,481] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:04:54,482] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:04:54,482] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:05:04,482] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:05:04,482] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:05:14,483] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:05:14,483] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:05:24,484] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:05:24,484] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:05:34,484] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:05:34,484] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:05:44,485] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:05:44,504] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:05:54,504] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:05:54,505] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:06:04,505] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:06:04,505] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:06:14,506] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:06:14,526] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:06:24,527] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:06:24,527] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:06:34,527] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:06:34,527] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:06:44,528] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:06:44,529] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:06:54,530] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:06:54,552] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:07:04,552] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:07:04,575] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:07:14,575] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:07:14,576] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:07:16,078] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:66)
[2020-05-13 01:07:16,079] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-05-13 01:07:16,081] INFO Stopped http_localhost8083@3add81c4{HTTP/1.1,[http/1.1]}{localhost:8083} (org.eclipse.jetty.server.AbstractConnector:343)
[2020-05-13 01:07:16,082] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-05-13 01:07:16,083] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-05-13 01:07:16,083] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:609)
[2020-05-13 01:07:16,083] INFO [Worker clientId=connect-1, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:583)
[2020-05-13 01:07:16,084] INFO Stopping connector mysql-connector-demo (org.apache.kafka.connect.runtime.Worker:358)
[2020-05-13 01:07:16,084] INFO Stopping task mysql-connector-demo-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-05-13 01:07:16,085] INFO Stopped connector mysql-connector-demo (org.apache.kafka.connect.runtime.Worker:374)
[2020-05-13 01:07:16,085] INFO [Worker clientId=connect-1, groupId=connect-cluster] Member connect-1-306d3560-0d18-41f5-b9b1-25cdd60ee184 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:916)
[2020-05-13 01:07:16,086] WARN [Worker clientId=connect-1, groupId=connect-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:897)
[2020-05-13 01:07:16,087] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:165)
[2020-05-13 01:07:16,088] INFO [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 01:07:16,091] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:191)
[2020-05-13 01:07:16,091] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:272)
[2020-05-13 01:07:16,091] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:165)
[2020-05-13 01:07:16,091] INFO [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 01:07:16,093] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:191)
[2020-05-13 01:07:16,094] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:274)
[2020-05-13 01:07:16,094] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-05-13 01:07:16,094] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:115)
[2020-05-13 01:07:16,094] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:165)
[2020-05-13 01:07:16,094] INFO [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 01:07:16,098] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:191)
[2020-05-13 01:07:16,098] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:117)
[2020-05-13 01:07:16,099] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-05-13 01:07:16,099] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:287)
[2020-05-13 01:07:16,101] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:629)
[2020-05-13 01:07:16,101] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:71)
[2020-05-13 01:07:17,837] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -Djava.awt.headless=true, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Private Build, OpenJDK 64-Bit Server VM, 11.0.5, 11.0.5+10-post-Ubuntu-0ubuntu1.119.04
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.4.1.jar:bin/../libs/connect-basic-auth-extension-2.4.1.jar:bin/../libs/connect-file-2.4.1.jar:bin/../libs/connect-json-2.4.1.jar:bin/../libs/connect-mirror-2.4.1.jar:bin/../libs/connect-mirror-client-2.4.1.jar:bin/../libs/connect-runtime-2.4.1.jar:bin/../libs/connect-transforms-2.4.1.jar:bin/../libs/guava-20.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.0.jar:bin/../libs/jackson-core-2.10.0.jar:bin/../libs/jackson-databind-2.10.0.jar:bin/../libs/jackson-dataformat-csv-2.10.0.jar:bin/../libs/jackson-datatype-jdk8-2.10.0.jar:bin/../libs/jackson-jaxrs-base-2.10.0.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:bin/../libs/jackson-module-paranamer-2.10.0.jar:bin/../libs/jackson-module-scala_2.12-2.10.0.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.20.v20190813.jar:bin/../libs/jetty-continuation-9.4.20.v20190813.jar:bin/../libs/jetty-http-9.4.20.v20190813.jar:bin/../libs/jetty-io-9.4.20.v20190813.jar:bin/../libs/jetty-security-9.4.20.v20190813.jar:bin/../libs/jetty-server-9.4.20.v20190813.jar:bin/../libs/jetty-servlet-9.4.20.v20190813.jar:bin/../libs/jetty-servlets-9.4.20.v20190813.jar:bin/../libs/jetty-util-9.4.20.v20190813.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.4.1.jar:bin/../libs/kafka_2.12-2.4.1-sources.jar:bin/../libs/kafka-clients-2.4.1.jar:bin/../libs/kafka-log4j-appender-2.4.1.jar:bin/../libs/kafka-streams-2.4.1.jar:bin/../libs/kafka-streams-examples-2.4.1.jar:bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:bin/../libs/kafka-streams-test-utils-2.4.1.jar:bin/../libs/kafka-tools-2.4.1.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.6.0.jar:bin/../libs/maven-artifact-3.6.1.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.0.jar:bin/../libs/reflections-0.9.11.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.2.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.28.jar:bin/../libs/slf4j-log4j12-1.7.28.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.3-1.jar
	os.spec = Linux, amd64, 5.0.0-38-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-05-13 01:07:17,843] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectDistributed:90)
[2020-05-13 01:07:17,863] INFO Loading plugin from: /home/admina/Desktop/ghtk/kafka/debezium-connector-mysql-0.9.2.Final-plugin/debezium-connector-mysql (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:241)
[2020-05-13 01:07:18,381] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/admina/Desktop/ghtk/kafka/debezium-connector-mysql-0.9.2.Final-plugin/debezium-connector-mysql/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:264)
[2020-05-13 01:07:18,383] INFO Added plugin 'io.debezium.connector.mysql.MySqlConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:18,383] INFO Added plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:18,383] INFO Added plugin 'io.debezium.transforms.UnwrapFromEnvelope' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:18,383] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:18,383] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:18,383] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,750] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@8bcc55f (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:264)
[2020-05-13 01:07:19,750] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,750] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,750] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,751] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,751] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,753] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,753] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,754] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,754] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,754] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,754] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,754] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,754] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,755] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,755] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,755] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,755] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,755] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,755] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,756] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,756] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,756] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,756] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,756] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,756] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,757] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,757] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,757] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,757] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,757] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,757] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,758] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,758] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,758] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,758] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,758] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,758] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,758] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,759] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,759] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,759] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,759] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,759] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 01:07:19,760] INFO Added aliases 'MySqlConnector' and 'MySql' to plugin 'io.debezium.connector.mysql.MySqlConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,761] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,761] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,761] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,761] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,762] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,762] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,762] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,762] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,762] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,763] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,763] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,763] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,763] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,763] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,763] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,764] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,764] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,764] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,764] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,764] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,765] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,765] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,765] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,765] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,765] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,765] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,766] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 01:07:19,766] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,766] INFO Added alias 'ByLogicalTableRouter' to plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 01:07:19,767] INFO Added alias 'UnwrapFromEnvelope' to plugin 'io.debezium.transforms.UnwrapFromEnvelope' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 01:07:19,767] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 01:07:19,768] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 01:07:19,769] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 01:07:19,769] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 01:07:19,770] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,770] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,770] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 01:07:19,863] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = None
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = null
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.path = [/home/admina/Desktop/ghtk/kafka/debezium-connector-mysql-0.9.2.Final-plugin]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = localhost
	rest.port = 8083
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:347)
[2020-05-13 01:07:19,867] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-05-13 01:07:19,870] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 01:07:20,025] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,025] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,025] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,025] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,025] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,025] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,025] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,025] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,026] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,026] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,026] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,026] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,026] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,026] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,026] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,027] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 01:07:20,027] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 01:07:20,027] INFO Kafka startTimeMs: 1589306840026 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 01:07:20,294] INFO Kafka cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-05-13 01:07:20,316] INFO Logging initialized @2742ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-05-13 01:07:20,358] INFO Added connector for http://localhost:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-05-13 01:07:20,358] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-05-13 01:07:20,363] INFO jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 11.0.5+10-post-Ubuntu-0ubuntu1.119.04 (org.eclipse.jetty.server.Server:359)
[2020-05-13 01:07:20,391] INFO Started http_localhost8083@6ac4944a{HTTP/1.1,[http/1.1]}{localhost:8083} (org.eclipse.jetty.server.AbstractConnector:293)
[2020-05-13 01:07:20,391] INFO Started @2817ms (org.eclipse.jetty.server.Server:399)
[2020-05-13 01:07:20,433] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-05-13 01:07:20,433] INFO REST server listening at http://localhost:8083/, advertising URL http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-05-13 01:07:20,434] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-05-13 01:07:20,434] INFO REST admin endpoints at http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-05-13 01:07:20,434] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-05-13 01:07:20,439] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-05-13 01:07:20,449] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 01:07:20,450] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 01:07:20,450] INFO Kafka startTimeMs: 1589306840449 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 01:07:20,601] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 01:07:20,602] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 01:07:20,640] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 01:07:20,641] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 01:07:20,641] INFO Kafka startTimeMs: 1589306840640 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 01:07:20,643] INFO Kafka Connect distributed worker initialization took 2799ms (org.apache.kafka.connect.cli.ConnectDistributed:128)
[2020-05-13 01:07:20,643] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:50)
[2020-05-13 01:07:20,646] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-05-13 01:07:20,646] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:275)
[2020-05-13 01:07:20,649] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-05-13 01:07:20,649] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:108)
[2020-05-13 01:07:20,649] INFO Starting KafkaBasedLog with topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:126)
[2020-05-13 01:07:20,649] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 01:07:20,653] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,653] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,653] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,653] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,653] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,653] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,653] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,653] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,653] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,654] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,654] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,654] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,654] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,654] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,654] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,654] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 01:07:20,655] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 01:07:20,655] INFO Kafka startTimeMs: 1589306840654 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 01:07:20,689] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 01:07:20,696] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-05-13 01:07:20,718] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,719] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,719] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,720] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,720] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,720] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,720] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,720] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,720] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,721] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,721] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,721] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,721] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,721] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,722] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,722] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 01:07:20,722] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 01:07:20,722] INFO Kafka startTimeMs: 1589306840722 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 01:07:20,730] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 01:07:20,733] INFO [Producer clientId=producer-1] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 01:07:20,762] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:20,762] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:20,762] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:20,763] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:20,763] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:20,763] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:20,763] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:20,763] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:20,763] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:20,763] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:20,763] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:20,763] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:20,764] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:20,764] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:20,764] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 01:07:20,764] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 01:07:20,764] INFO Kafka startTimeMs: 1589306840764 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 01:07:20,773] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 01:07:20,781] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-05-13 01:07:20,781] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-05-13 01:07:20,781] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:140)
[2020-05-13 01:07:20,786] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Subscribed to partition(s): connect-offsets-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1123)
[2020-05-13 01:07:20,789] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:564)
[2020-05-13 01:07:20,817] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 01:07:20,858] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:159)
[2020-05-13 01:07:20,859] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:161)
[2020-05-13 01:07:20,859] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:110)
[2020-05-13 01:07:20,861] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-05-13 01:07:20,862] INFO Starting KafkaBasedLog with topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:126)
[2020-05-13 01:07:20,862] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 01:07:20,866] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,866] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,867] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,867] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,867] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,867] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,867] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,868] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,868] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,868] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,868] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,868] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,868] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,868] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,868] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,868] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 01:07:20,868] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 01:07:20,868] INFO Kafka startTimeMs: 1589306840868 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 01:07:20,881] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 01:07:20,886] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,887] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,887] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,887] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,887] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,887] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,887] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,887] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,888] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,888] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,888] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,888] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,888] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,889] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,890] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,891] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 01:07:20,891] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 01:07:20,892] INFO Kafka startTimeMs: 1589306840891 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 01:07:20,893] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 01:07:20,901] INFO [Producer clientId=producer-2] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 01:07:20,902] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:20,902] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:20,903] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:20,903] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:20,903] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:20,903] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:20,903] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:20,903] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:20,903] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:20,904] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:20,904] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:20,904] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:20,904] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:20,904] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:20,904] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 01:07:20,904] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 01:07:20,904] INFO Kafka startTimeMs: 1589306840904 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 01:07:20,909] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 01:07:20,913] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Subscribed to partition(s): connect-status-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1123)
[2020-05-13 01:07:20,914] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:564)
[2020-05-13 01:07:20,923] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Resetting offset for partition connect-status-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 01:07:20,958] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:159)
[2020-05-13 01:07:20,958] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:161)
[2020-05-13 01:07:20,960] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:262)
[2020-05-13 01:07:20,961] INFO Starting KafkaBasedLog with topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:126)
[2020-05-13 01:07:20,961] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 01:07:20,964] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,965] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,965] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,965] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,965] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,965] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,965] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,965] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,965] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,966] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,966] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,966] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,966] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,966] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,966] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 01:07:20,966] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 01:07:20,967] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 01:07:20,967] INFO Kafka startTimeMs: 1589306840966 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 01:07:20,982] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 01:07:20,990] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,991] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,991] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,991] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:20,994] INFO [Producer clientId=producer-3] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 01:07:20,998] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:21,001] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:21,001] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:21,001] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:21,001] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:21,001] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:21,001] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:21,001] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:21,001] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:21,002] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:21,002] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 01:07:21,002] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 01:07:21,002] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 01:07:21,002] INFO Kafka startTimeMs: 1589306841002 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 01:07:21,003] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 01:07:21,007] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:21,007] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:21,007] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:21,007] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:21,007] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:21,007] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:21,007] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:21,008] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:21,008] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:21,008] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:21,008] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:21,008] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:21,008] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:21,008] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 01:07:21,008] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 01:07:21,008] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 01:07:21,009] INFO Kafka startTimeMs: 1589306841008 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 01:07:21,015] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 01:07:21,023] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Subscribed to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1123)
[2020-05-13 01:07:21,024] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:564)
[2020-05-13 01:07:21,032] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 01:07:21,041] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:159)
[2020-05-13 01:07:21,041] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:161)
[2020-05-13 01:07:21,042] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:267)
[2020-05-13 01:07:21,042] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:279)
[2020-05-13 01:07:21,053] INFO [Worker clientId=connect-1, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 01:07:21,053] INFO [Worker clientId=connect-1, groupId=connect-cluster] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2020-05-13 01:07:21,058] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:222)
[2020-05-13 01:07:21,058] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 01:07:21,071] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 01:07:21,102] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation 7 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:484)
[2020-05-13 01:07:21,115] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 7 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-877f6e5f-28d2-4495-a559-bcaf5fa75c6c', leaderUrl='http://localhost:8083/', offset=7, connectorIds=[mysql-connector-demo], taskIds=[mysql-connector-demo-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1542)
[2020-05-13 01:07:21,117] WARN [Worker clientId=connect-1, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1013)
[2020-05-13 01:07:21,118] INFO [Worker clientId=connect-1, groupId=connect-cluster] Current config state offset -1 is behind group assignment 7, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1074)
[2020-05-13 01:07:21,408] INFO Started o.e.j.s.ServletContextHandler@4f82663e{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:824)
[2020-05-13 01:07:21,408] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-05-13 01:07:21,408] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:56)
[2020-05-13 01:07:21,539] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 7 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1078)
[2020-05-13 01:07:21,539] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 7 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1104)
[2020-05-13 01:07:21,542] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector mysql-connector-demo (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1179)
[2020-05-13 01:07:21,542] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task mysql-connector-demo-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1139)
[2020-05-13 01:07:21,546] INFO Creating task mysql-connector-demo-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-05-13 01:07:21,547] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-05-13 01:07:21,548] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-05-13 01:07:21,548] INFO Creating connector mysql-connector-demo of type io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-05-13 01:07:21,548] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-05-13 01:07:21,549] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-05-13 01:07:21,551] INFO Instantiated connector mysql-connector-demo with version 0.9.2.Final of type class io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-05-13 01:07:21,557] INFO TaskConfig values: 
	task.class = class io.debezium.connector.mysql.MySqlConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-05-13 01:07:21,560] INFO Instantiated task mysql-connector-demo-0 with version 0.9.2.Final of type io.debezium.connector.mysql.MySqlConnectorTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-05-13 01:07:21,561] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 01:07:21,562] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task mysql-connector-demo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-05-13 01:07:21,563] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 01:07:21,563] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mysql-connector-demo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-05-13 01:07:21,563] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mysql-connector-demo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-05-13 01:07:21,579] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:514)
[2020-05-13 01:07:21,585] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-mysql-connector-demo-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 01:07:21,586] INFO Finished creating connector mysql-connector-demo (org.apache.kafka.connect.runtime.Worker:273)
[2020-05-13 01:07:21,587] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-05-13 01:07:21,588] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-05-13 01:07:21,590] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 01:07:21,592] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 01:07:21,592] INFO Kafka startTimeMs: 1589306841590 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 01:07:21,594] INFO [Producer clientId=connector-producer-mysql-connector-demo-0] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 01:07:21,603] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1125)
[2020-05-13 01:07:21,640] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1440)
[2020-05-13 01:07:21,686] INFO Starting MySqlConnectorTask with configuration: (io.debezium.connector.common.BaseSourceTask:42)
[2020-05-13 01:07:21,688] INFO    connector.class = io.debezium.connector.mysql.MySqlConnector (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 01:07:21,689] INFO    database.user = debezium (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 01:07:21,689] INFO    database.server.id = 1 (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 01:07:21,689] INFO    database.history.kafka.bootstrap.servers = localhost:9092 (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 01:07:21,689] INFO    database.history.kafka.topic = dbhistory.demo (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 01:07:21,689] INFO    database.server.name = ghtk_chat (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 01:07:21,689] INFO    database.port = 3306 (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 01:07:21,689] INFO    include.schema.changes = true (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 01:07:21,689] INFO    table.whitelist = ghtk_chat.channels (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 01:07:21,690] INFO    task.class = io.debezium.connector.mysql.MySqlConnectorTask (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 01:07:21,690] INFO    database.hostname = localhost (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 01:07:21,690] INFO    database.password = ******** (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 01:07:21,690] INFO    name = mysql-connector-demo (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 01:07:22,087] INFO KafkaDatabaseHistory Consumer config: {key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, enable.auto.commit=false, group.id=mysql-connector-demo-dbhistory, bootstrap.servers=localhost:9092, fetch.min.bytes=1, session.timeout.ms=10000, auto.offset.reset=earliest, client.id=mysql-connector-demo-dbhistory} (io.debezium.relational.history.KafkaDatabaseHistory:163)
[2020-05-13 01:07:22,087] INFO KafkaDatabaseHistory Producer config: {retries=1, value.serializer=org.apache.kafka.common.serialization.StringSerializer, acks=1, batch.size=32768, max.block.ms=10000, bootstrap.servers=localhost:9092, buffer.memory=1048576, key.serializer=org.apache.kafka.common.serialization.StringSerializer, client.id=mysql-connector-demo-dbhistory, linger.ms=0} (io.debezium.relational.history.KafkaDatabaseHistory:164)
[2020-05-13 01:07:22,089] INFO ProducerConfig values: 
	acks = 1
	batch.size = 32768
	bootstrap.servers = [localhost:9092]
	buffer.memory = 1048576
	client.dns.lookup = default
	client.id = mysql-connector-demo-dbhistory
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 10000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 01:07:22,093] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 01:07:22,094] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 01:07:22,094] INFO Kafka startTimeMs: 1589306842093 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 01:07:22,094] INFO Found existing offset: {ts_sec=1589301382, file=mysql-bin.000008, pos=950, gtids=1507ff86-e9aa-11e9-b5ab-000c29f4a13b:1-3112, row=1, server_id=1, event=2} (io.debezium.connector.mysql.MySqlConnectorTask:82)
[2020-05-13 01:07:22,097] INFO [Producer clientId=mysql-connector-demo-dbhistory] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 01:07:22,098] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = mysql-connector-demo-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = mysql-connector-demo-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 01:07:22,102] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 01:07:22,102] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 01:07:22,102] INFO Kafka startTimeMs: 1589306842102 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 01:07:22,108] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 01:07:22,137] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = mysql-connector-demo-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = mysql-connector-demo-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 01:07:22,140] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 01:07:22,140] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 01:07:22,140] INFO Kafka startTimeMs: 1589306842140 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 01:07:22,141] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Subscribed to topic(s): dbhistory.demo (org.apache.kafka.clients.consumer.KafkaConsumer:969)
[2020-05-13 01:07:22,144] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 01:07:22,148] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2020-05-13 01:07:22,149] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 01:07:22,154] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 01:07:22,158] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Finished assignment for group at generation 1: {mysql-connector-demo-dbhistory-202add5d-71bb-4b13-a950-05d48ae38f9d=Assignment(partitions=[dbhistory.demo-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:585)
[2020-05-13 01:07:22,161] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Successfully joined group with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:484)
[2020-05-13 01:07:22,163] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Adding newly assigned partitions: dbhistory.demo-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:267)
[2020-05-13 01:07:22,169] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Found no committed offset for partition dbhistory.demo-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1241)
[2020-05-13 01:07:22,170] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Resetting offset for partition dbhistory.demo-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 01:07:22,608] ERROR Unexpected exception while processing record 'ConsumerRecord(topic = dbhistory.demo, partition = 0, leaderEpoch = 0, offset = 7, CreateTime = 1589301948755, serialized key size = -1, serialized value size = 479, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {
  "source" : {
    "server" : "ghtk_chat"
  },
  "position" : {
    "ts_sec" : 1589301948,
    "file" : "mysql-bin.000008",
    "pos" : 1860,
    "gtids" : "1507ff86-e9aa-11e9-b5ab-000c29f4a13b:1-3112",
    "server_id" : 1
  },
  "databaseName" : "ghtk_chat",
  "ddl" : "CREATE DEFINER=`root`@`localhost` TRIGGER `channels_BEFORE_UPDATE` BEFORE UPDATE ON `channels` FOR EACH ROW\nBEGIN\n    if(New.updatedAt is null) then \n\t\tset New.updatedAt= Now(); \n    end if;\n\nEND"
})' (io.debezium.relational.history.KafkaDatabaseHistory:248)
io.debezium.text.ParsingException: no viable alternative at input 'CREATE DEFINER=`root`@`localhost` TRIGGER `channels_BEFORE_UPDATE` BEFORE UPDATE ON `channels` FOR EACH ROW\nBEGIN\n    if(New.updatedAt is null) then \n\t\tset New.updatedAt'
	at io.debezium.antlr.ParsingErrorListener.syntaxError(ParsingErrorListener.java:40)
	at org.antlr.v4.runtime.ProxyErrorListener.syntaxError(ProxyErrorListener.java:41)
	at org.antlr.v4.runtime.Parser.notifyErrorListeners(Parser.java:544)
	at org.antlr.v4.runtime.DefaultErrorStrategy.reportNoViableAlternative(DefaultErrorStrategy.java:282)
	at org.antlr.v4.runtime.DefaultErrorStrategy.reportError(DefaultErrorStrategy.java:121)
	at io.debezium.ddl.parser.mysql.generated.MySqlParser.sqlStatements(MySqlParser.java:1075)
	at io.debezium.ddl.parser.mysql.generated.MySqlParser.root(MySqlParser.java:809)
	at io.debezium.connector.mysql.antlr.MySqlAntlrDdlParser.parseTree(MySqlAntlrDdlParser.java:71)
	at io.debezium.connector.mysql.antlr.MySqlAntlrDdlParser.parseTree(MySqlAntlrDdlParser.java:44)
	at io.debezium.antlr.AntlrDdlParser.parse(AntlrDdlParser.java:80)
	at io.debezium.relational.history.AbstractDatabaseHistory.lambda$recover$1(AbstractDatabaseHistory.java:104)
	at io.debezium.relational.history.KafkaDatabaseHistory.recoverRecords(KafkaDatabaseHistory.java:238)
	at io.debezium.relational.history.AbstractDatabaseHistory.recover(AbstractDatabaseHistory.java:73)
	at io.debezium.connector.mysql.MySqlSchema.loadHistory(MySqlSchema.java:251)
	at io.debezium.connector.mysql.MySqlTaskContext.loadHistory(MySqlTaskContext.java:165)
	at io.debezium.connector.mysql.MySqlConnectorTask.start(MySqlConnectorTask.java:105)
	at io.debezium.connector.common.BaseSourceTask.start(BaseSourceTask.java:47)
	at org.apache.kafka.connect.runtime.WorkerSourceTask.execute(WorkerSourceTask.java:208)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:177)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:227)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.antlr.v4.runtime.NoViableAltException
	at org.antlr.v4.runtime.atn.ParserATNSimulator.noViableAlt(ParserATNSimulator.java:2023)
	at org.antlr.v4.runtime.atn.ParserATNSimulator.execATN(ParserATNSimulator.java:467)
	at org.antlr.v4.runtime.atn.ParserATNSimulator.adaptivePredict(ParserATNSimulator.java:393)
	at io.debezium.ddl.parser.mysql.generated.MySqlParser.sqlStatements(MySqlParser.java:883)
	... 19 more
[2020-05-13 01:07:22,610] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Revoke previously assigned partitions dbhistory.demo-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:286)
[2020-05-13 01:07:22,610] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Member mysql-connector-demo-dbhistory-202add5d-71bb-4b13-a950-05d48ae38f9d sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:916)
[2020-05-13 01:07:22,615] INFO Stopping MySQL connector task (io.debezium.connector.mysql.MySqlConnectorTask:428)
[2020-05-13 01:07:22,615] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:07:22,615] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:07:22,615] ERROR WorkerSourceTask{id=mysql-connector-demo-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:179)
org.apache.kafka.connect.errors.ConnectException: io.debezium.text.ParsingException: no viable alternative at input 'CREATE DEFINER=`root`@`localhost` TRIGGER `channels_BEFORE_UPDATE` BEFORE UPDATE ON `channels` FOR EACH ROW\nBEGIN\n    if(New.updatedAt is null) then \n\t\tset New.updatedAt'
	at io.debezium.connector.mysql.MySqlConnectorTask.start(MySqlConnectorTask.java:273)
	at io.debezium.connector.common.BaseSourceTask.start(BaseSourceTask.java:47)
	at org.apache.kafka.connect.runtime.WorkerSourceTask.execute(WorkerSourceTask.java:208)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:177)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:227)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: io.debezium.text.ParsingException: no viable alternative at input 'CREATE DEFINER=`root`@`localhost` TRIGGER `channels_BEFORE_UPDATE` BEFORE UPDATE ON `channels` FOR EACH ROW\nBEGIN\n    if(New.updatedAt is null) then \n\t\tset New.updatedAt'
	at io.debezium.antlr.ParsingErrorListener.syntaxError(ParsingErrorListener.java:40)
	at org.antlr.v4.runtime.ProxyErrorListener.syntaxError(ProxyErrorListener.java:41)
	at org.antlr.v4.runtime.Parser.notifyErrorListeners(Parser.java:544)
	at org.antlr.v4.runtime.DefaultErrorStrategy.reportNoViableAlternative(DefaultErrorStrategy.java:282)
	at org.antlr.v4.runtime.DefaultErrorStrategy.reportError(DefaultErrorStrategy.java:121)
	at io.debezium.ddl.parser.mysql.generated.MySqlParser.sqlStatements(MySqlParser.java:1075)
	at io.debezium.ddl.parser.mysql.generated.MySqlParser.root(MySqlParser.java:809)
	at io.debezium.connector.mysql.antlr.MySqlAntlrDdlParser.parseTree(MySqlAntlrDdlParser.java:71)
	at io.debezium.connector.mysql.antlr.MySqlAntlrDdlParser.parseTree(MySqlAntlrDdlParser.java:44)
	at io.debezium.antlr.AntlrDdlParser.parse(AntlrDdlParser.java:80)
	at io.debezium.relational.history.AbstractDatabaseHistory.lambda$recover$1(AbstractDatabaseHistory.java:104)
	at io.debezium.relational.history.KafkaDatabaseHistory.recoverRecords(KafkaDatabaseHistory.java:238)
	at io.debezium.relational.history.AbstractDatabaseHistory.recover(AbstractDatabaseHistory.java:73)
	at io.debezium.connector.mysql.MySqlSchema.loadHistory(MySqlSchema.java:251)
	at io.debezium.connector.mysql.MySqlTaskContext.loadHistory(MySqlTaskContext.java:165)
	at io.debezium.connector.mysql.MySqlConnectorTask.start(MySqlConnectorTask.java:105)
	... 9 more
Caused by: org.antlr.v4.runtime.NoViableAltException
	at org.antlr.v4.runtime.atn.ParserATNSimulator.noViableAlt(ParserATNSimulator.java:2023)
	at org.antlr.v4.runtime.atn.ParserATNSimulator.execATN(ParserATNSimulator.java:467)
	at org.antlr.v4.runtime.atn.ParserATNSimulator.adaptivePredict(ParserATNSimulator.java:393)
	at io.debezium.ddl.parser.mysql.generated.MySqlParser.sqlStatements(MySqlParser.java:883)
	... 19 more
[2020-05-13 01:07:22,616] ERROR WorkerSourceTask{id=mysql-connector-demo-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:180)
[2020-05-13 01:07:22,616] INFO Stopping MySQL connector task (io.debezium.connector.mysql.MySqlConnectorTask:428)
[2020-05-13 01:07:22,616] INFO [Producer clientId=connector-producer-mysql-connector-demo-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 01:07:31,599] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:07:31,600] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:07:41,600] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:07:41,626] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:07:51,627] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:07:51,630] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:08:01,630] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:08:01,632] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:08:11,632] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:08:11,637] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:08:21,638] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:08:21,644] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:08:31,644] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:08:31,646] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:08:41,647] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:08:41,649] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:08:51,650] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:08:51,651] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:09:01,652] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:09:01,658] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:09:11,659] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:09:11,659] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:09:21,659] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:09:21,675] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:09:31,676] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:09:31,677] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:09:41,678] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:09:41,695] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:09:51,696] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:09:51,713] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:10:01,713] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:10:01,715] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:10:11,716] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:10:11,716] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:10:21,716] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:10:21,719] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:10:31,719] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:10:31,721] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:10:41,721] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:10:41,722] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:10:51,723] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:10:51,724] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:11:01,725] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:11:01,727] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:11:11,727] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:11:11,754] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:11:21,754] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:11:21,755] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:11:31,755] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:11:31,782] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:11:41,783] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:11:41,783] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:11:51,784] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:11:51,812] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:12:01,812] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:12:01,813] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:12:11,813] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:12:11,843] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 01:12:21,844] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 01:12:21,844] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
