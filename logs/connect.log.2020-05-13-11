[2020-05-13 11:00:00,877] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:00:00,878] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:00:10,878] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:00:10,878] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:00:20,878] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:00:20,904] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:00:30,904] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:00:30,930] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:00:40,930] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:00:40,956] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:00:50,957] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:00:50,974] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:01:00,974] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:01:01,001] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:01:11,002] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:01:11,030] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:01:21,030] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:01:21,058] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:01:31,059] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:01:31,059] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:01:41,060] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:01:41,088] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:01:51,089] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:01:51,090] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:02:01,091] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:02:01,091] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:02:11,092] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:02:11,094] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:02:21,095] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:02:21,125] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:02:31,126] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:02:31,127] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:02:41,127] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:02:41,308] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:02:51,309] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:02:51,314] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:03:01,314] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:03:01,317] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:03:11,317] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:03:11,325] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:03:21,325] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:03:21,336] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:03:31,336] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:03:31,344] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:03:41,344] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:03:41,347] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:03:51,348] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:03:51,348] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:04:01,348] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:04:01,350] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:04:11,351] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:04:11,354] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:04:21,354] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:04:21,366] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:04:31,367] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:04:31,377] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:04:41,378] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:04:41,392] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:04:51,392] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:04:51,395] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:05:01,395] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:05:01,410] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:05:11,410] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:05:11,414] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:05:21,415] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:05:21,417] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:05:31,417] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:05:31,431] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:05:41,432] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:05:41,449] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:05:49,257] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:66)
[2020-05-13 11:05:49,276] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-05-13 11:05:49,301] INFO Stopped http_localhost8083@60b85ba1{HTTP/1.1,[http/1.1]}{localhost:8083} (org.eclipse.jetty.server.AbstractConnector:343)
[2020-05-13 11:05:49,302] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-05-13 11:05:49,303] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-05-13 11:05:49,303] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:609)
[2020-05-13 11:05:49,304] INFO [Worker clientId=connect-1, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:583)
[2020-05-13 11:05:49,304] INFO Stopping connector mysql-connector-demo (org.apache.kafka.connect.runtime.Worker:358)
[2020-05-13 11:05:49,304] INFO Stopping task mysql-connector-demo-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-05-13 11:05:49,307] INFO Stopped connector mysql-connector-demo (org.apache.kafka.connect.runtime.Worker:374)
[2020-05-13 11:05:49,308] INFO [Worker clientId=connect-1, groupId=connect-cluster] Member connect-1-e47872b3-63d7-4dac-ad4b-f6064284aa6f sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:916)
[2020-05-13 11:05:49,308] WARN [Worker clientId=connect-1, groupId=connect-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:897)
[2020-05-13 11:05:49,311] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:165)
[2020-05-13 11:05:49,313] INFO [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:05:49,320] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:191)
[2020-05-13 11:05:49,321] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:272)
[2020-05-13 11:05:49,321] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:165)
[2020-05-13 11:05:49,321] INFO [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:05:49,327] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:191)
[2020-05-13 11:05:49,327] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:274)
[2020-05-13 11:05:49,327] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-05-13 11:05:49,329] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:115)
[2020-05-13 11:05:49,329] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:165)
[2020-05-13 11:05:49,330] INFO [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:05:49,332] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:191)
[2020-05-13 11:05:49,333] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:117)
[2020-05-13 11:05:49,333] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-05-13 11:05:49,333] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:287)
[2020-05-13 11:05:49,335] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:629)
[2020-05-13 11:05:49,336] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:71)
[2020-05-13 11:05:51,137] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -Djava.awt.headless=true, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Private Build, OpenJDK 64-Bit Server VM, 11.0.5, 11.0.5+10-post-Ubuntu-0ubuntu1.119.04
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.4.1.jar:bin/../libs/connect-basic-auth-extension-2.4.1.jar:bin/../libs/connect-file-2.4.1.jar:bin/../libs/connect-json-2.4.1.jar:bin/../libs/connect-mirror-2.4.1.jar:bin/../libs/connect-mirror-client-2.4.1.jar:bin/../libs/connect-runtime-2.4.1.jar:bin/../libs/connect-transforms-2.4.1.jar:bin/../libs/guava-20.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.0.jar:bin/../libs/jackson-core-2.10.0.jar:bin/../libs/jackson-databind-2.10.0.jar:bin/../libs/jackson-dataformat-csv-2.10.0.jar:bin/../libs/jackson-datatype-jdk8-2.10.0.jar:bin/../libs/jackson-jaxrs-base-2.10.0.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:bin/../libs/jackson-module-paranamer-2.10.0.jar:bin/../libs/jackson-module-scala_2.12-2.10.0.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.20.v20190813.jar:bin/../libs/jetty-continuation-9.4.20.v20190813.jar:bin/../libs/jetty-http-9.4.20.v20190813.jar:bin/../libs/jetty-io-9.4.20.v20190813.jar:bin/../libs/jetty-security-9.4.20.v20190813.jar:bin/../libs/jetty-server-9.4.20.v20190813.jar:bin/../libs/jetty-servlet-9.4.20.v20190813.jar:bin/../libs/jetty-servlets-9.4.20.v20190813.jar:bin/../libs/jetty-util-9.4.20.v20190813.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.4.1.jar:bin/../libs/kafka_2.12-2.4.1-sources.jar:bin/../libs/kafka-clients-2.4.1.jar:bin/../libs/kafka-log4j-appender-2.4.1.jar:bin/../libs/kafka-streams-2.4.1.jar:bin/../libs/kafka-streams-examples-2.4.1.jar:bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:bin/../libs/kafka-streams-test-utils-2.4.1.jar:bin/../libs/kafka-tools-2.4.1.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.6.0.jar:bin/../libs/maven-artifact-3.6.1.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.0.jar:bin/../libs/reflections-0.9.11.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.2.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.28.jar:bin/../libs/slf4j-log4j12-1.7.28.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.3-1.jar
	os.spec = Linux, amd64, 5.0.0-38-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-05-13 11:05:51,147] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectDistributed:90)
[2020-05-13 11:05:51,182] INFO Loading plugin from: /home/admina/Desktop/ghtk/kafka/debezium-connector-mysql-0.9.2.Final-plugin/debezium-connector-mysql (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:241)
[2020-05-13 11:05:51,998] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/admina/Desktop/ghtk/kafka/debezium-connector-mysql-0.9.2.Final-plugin/debezium-connector-mysql/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:264)
[2020-05-13 11:05:52,000] INFO Added plugin 'io.debezium.connector.mysql.MySqlConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:52,000] INFO Added plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:52,001] INFO Added plugin 'io.debezium.transforms.UnwrapFromEnvelope' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:52,001] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:52,001] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:52,001] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:52,023] INFO Loading plugin from: /home/admina/Desktop/ghtk/kafka/debezium-connector-mysql-0.10.0.Beta2-plugin/debezium-connector-mysql (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:241)
[2020-05-13 11:05:52,397] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/admina/Desktop/ghtk/kafka/debezium-connector-mysql-0.10.0.Beta2-plugin/debezium-connector-mysql/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:264)
[2020-05-13 11:05:52,397] INFO Added plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:52,397] INFO Added plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,235] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@8bcc55f (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:264)
[2020-05-13 11:05:54,235] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,237] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,238] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,238] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,238] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,238] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,238] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,239] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,239] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,239] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,239] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,239] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,239] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,240] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,240] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,240] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,240] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,240] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,240] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,241] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,241] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,241] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,243] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,243] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,243] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,243] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,244] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,244] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,244] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,244] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,244] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,244] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,244] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,245] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,245] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,245] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,245] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,245] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,245] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,245] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,246] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,246] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,246] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:05:54,247] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,247] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,248] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,248] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,248] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,248] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,248] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,248] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,249] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,249] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,249] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,249] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,249] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,250] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,250] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,250] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,250] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,250] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,250] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,250] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,251] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,251] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,251] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,251] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,251] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,251] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,251] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:05:54,252] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,252] INFO Added alias 'ByLogicalTableRouter' to plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:05:54,252] INFO Added alias 'ExtractNewRecordState' to plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:05:54,252] INFO Added alias 'UnwrapFromEnvelope' to plugin 'io.debezium.transforms.UnwrapFromEnvelope' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:05:54,252] INFO Added alias 'EventRouter' to plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:05:54,253] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:05:54,253] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:05:54,253] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:05:54,253] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:05:54,254] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,254] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,254] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:05:54,367] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = None
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = null
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.path = [/home/admina/Desktop/ghtk/kafka/debezium-connector-mysql-0.9.2.Final-plugin, /home/admina/Desktop/ghtk/kafka/debezium-connector-mysql-0.10.0.Beta2-plugin]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = localhost
	rest.port = 8083
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:347)
[2020-05-13 11:05:54,370] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-05-13 11:05:54,372] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 11:05:54,546] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:54,546] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:54,546] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:54,546] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:54,547] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:54,547] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:54,547] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:54,547] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:54,547] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:54,547] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:54,547] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:54,547] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:54,548] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:54,548] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:54,548] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:54,548] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:05:54,548] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:05:54,549] INFO Kafka startTimeMs: 1589342754548 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:05:54,860] INFO Kafka cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-05-13 11:05:54,891] INFO Logging initialized @4117ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-05-13 11:05:54,942] INFO Added connector for http://localhost:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-05-13 11:05:54,942] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-05-13 11:05:54,948] INFO jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 11.0.5+10-post-Ubuntu-0ubuntu1.119.04 (org.eclipse.jetty.server.Server:359)
[2020-05-13 11:05:54,995] INFO Started http_localhost8083@29b732a2{HTTP/1.1,[http/1.1]}{localhost:8083} (org.eclipse.jetty.server.AbstractConnector:293)
[2020-05-13 11:05:54,996] INFO Started @4221ms (org.eclipse.jetty.server.Server:399)
[2020-05-13 11:05:55,026] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-05-13 11:05:55,026] INFO REST server listening at http://localhost:8083/, advertising URL http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-05-13 11:05:55,027] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-05-13 11:05:55,028] INFO REST admin endpoints at http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-05-13 11:05:55,028] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-05-13 11:05:55,039] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-05-13 11:05:55,052] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:05:55,053] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:05:55,053] INFO Kafka startTimeMs: 1589342755052 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:05:55,224] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 11:05:55,225] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 11:05:55,288] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:05:55,289] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:05:55,289] INFO Kafka startTimeMs: 1589342755288 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:05:55,291] INFO Kafka Connect distributed worker initialization took 4143ms (org.apache.kafka.connect.cli.ConnectDistributed:128)
[2020-05-13 11:05:55,291] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:50)
[2020-05-13 11:05:55,291] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-05-13 11:05:55,291] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:275)
[2020-05-13 11:05:55,293] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-05-13 11:05:55,293] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:108)
[2020-05-13 11:05:55,293] INFO Starting KafkaBasedLog with topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:126)
[2020-05-13 11:05:55,294] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 11:05:55,298] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,298] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,298] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,298] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,298] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,298] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,299] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,299] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,299] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,299] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,299] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,299] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,299] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,299] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,299] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,299] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:05:55,300] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:05:55,300] INFO Kafka startTimeMs: 1589342755299 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:05:55,338] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:05:55,339] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-05-13 11:05:55,361] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,367] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,367] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,368] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,368] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,369] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,369] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,369] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,369] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,369] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,369] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,370] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,370] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,370] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,370] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,370] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:05:55,370] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:05:55,371] INFO Kafka startTimeMs: 1589342755370 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:05:55,375] INFO [Producer clientId=producer-1] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:05:55,378] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:05:55,411] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,412] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,412] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,412] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,412] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,413] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,413] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,413] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,413] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,413] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,413] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,413] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,413] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,413] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,414] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:05:55,414] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:05:55,414] INFO Kafka startTimeMs: 1589342755414 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:05:55,423] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:05:55,439] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Subscribed to partition(s): connect-offsets-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1123)
[2020-05-13 11:05:55,441] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-05-13 11:05:55,442] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-05-13 11:05:55,444] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:140)
[2020-05-13 11:05:55,445] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:564)
[2020-05-13 11:05:55,472] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 11:05:55,526] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:159)
[2020-05-13 11:05:55,527] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:161)
[2020-05-13 11:05:55,528] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:110)
[2020-05-13 11:05:55,530] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-05-13 11:05:55,531] INFO Starting KafkaBasedLog with topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:126)
[2020-05-13 11:05:55,531] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 11:05:55,535] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,535] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,535] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,535] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,535] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,535] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,536] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,536] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,536] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,536] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,536] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,536] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,536] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,537] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,537] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,537] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:05:55,537] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:05:55,537] INFO Kafka startTimeMs: 1589342755537 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:05:55,565] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:05:55,573] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,574] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,574] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,574] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,574] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,575] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,575] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,575] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,575] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,575] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,575] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,575] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,575] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,576] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,576] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,576] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:05:55,576] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:05:55,576] INFO Kafka startTimeMs: 1589342755576 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:05:55,577] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:05:55,590] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,591] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,591] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,591] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,591] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,591] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,591] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,591] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,592] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,592] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,592] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,592] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,592] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,592] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,592] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:05:55,592] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:05:55,593] INFO Kafka startTimeMs: 1589342755592 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:05:55,594] INFO [Producer clientId=producer-2] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:05:55,598] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:05:55,607] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Subscribed to partition(s): connect-status-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1123)
[2020-05-13 11:05:55,607] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:564)
[2020-05-13 11:05:55,618] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Resetting offset for partition connect-status-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 11:05:55,668] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:159)
[2020-05-13 11:05:55,668] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:161)
[2020-05-13 11:05:55,670] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:262)
[2020-05-13 11:05:55,670] INFO Starting KafkaBasedLog with topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:126)
[2020-05-13 11:05:55,671] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 11:05:55,674] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,674] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,674] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,675] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,675] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,675] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,675] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,675] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,675] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,675] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,675] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,675] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,676] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,676] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,676] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:05:55,676] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:05:55,676] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:05:55,676] INFO Kafka startTimeMs: 1589342755676 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:05:55,699] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:05:55,713] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,714] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,714] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,714] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,714] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,715] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,715] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,715] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,715] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,715] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,715] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,715] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,715] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,715] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,715] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:05:55,716] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:05:55,716] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:05:55,716] INFO Kafka startTimeMs: 1589342755716 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:05:55,717] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:05:55,727] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,728] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,728] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,728] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,728] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,728] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,728] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,729] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,729] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,729] INFO [Producer clientId=producer-3] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:05:55,729] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,730] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,730] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,730] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,730] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:05:55,730] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:05:55,731] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:05:55,731] INFO Kafka startTimeMs: 1589342755730 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:05:55,740] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:05:55,754] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Subscribed to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1123)
[2020-05-13 11:05:55,754] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:564)
[2020-05-13 11:05:55,765] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 11:05:55,793] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:159)
[2020-05-13 11:05:55,794] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:161)
[2020-05-13 11:05:55,794] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:267)
[2020-05-13 11:05:55,794] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:279)
[2020-05-13 11:05:55,802] INFO [Worker clientId=connect-1, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:05:55,804] INFO [Worker clientId=connect-1, groupId=connect-cluster] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2020-05-13 11:05:55,809] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:222)
[2020-05-13 11:05:55,810] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:05:55,823] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:05:55,872] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation 15 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:484)
[2020-05-13 11:05:55,874] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 15 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-8fe9bdd9-7db6-4194-8372-4263d01de8ed', leaderUrl='http://localhost:8083/', offset=12, connectorIds=[mysql-connector-demo], taskIds=[mysql-connector-demo-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1542)
[2020-05-13 11:05:55,874] WARN [Worker clientId=connect-1, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1013)
[2020-05-13 11:05:55,875] INFO [Worker clientId=connect-1, groupId=connect-cluster] Current config state offset -1 is behind group assignment 12, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1074)
[2020-05-13 11:05:56,204] INFO Started o.e.j.s.ServletContextHandler@50194e8d{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:824)
[2020-05-13 11:05:56,204] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-05-13 11:05:56,204] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:56)
[2020-05-13 11:05:56,284] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 12 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1078)
[2020-05-13 11:05:56,285] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 12 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1104)
[2020-05-13 11:05:56,286] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector mysql-connector-demo (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1179)
[2020-05-13 11:05:56,286] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task mysql-connector-demo-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1139)
[2020-05-13 11:05:56,291] INFO Creating task mysql-connector-demo-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-05-13 11:05:56,292] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-05-13 11:05:56,293] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-05-13 11:05:56,293] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-05-13 11:05:56,293] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-05-13 11:05:56,294] INFO Creating connector mysql-connector-demo of type io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-05-13 11:05:56,296] INFO Instantiated connector mysql-connector-demo with version 0.10.0.Beta2 of type class io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-05-13 11:05:56,297] INFO TaskConfig values: 
	task.class = class io.debezium.connector.mysql.MySqlConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-05-13 11:05:56,299] INFO Instantiated task mysql-connector-demo-0 with version 0.10.0.Beta2 of type io.debezium.connector.mysql.MySqlConnectorTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-05-13 11:05:56,299] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 11:05:56,300] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task mysql-connector-demo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-05-13 11:05:56,300] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 11:05:56,300] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mysql-connector-demo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-05-13 11:05:56,300] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mysql-connector-demo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-05-13 11:05:56,304] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:514)
[2020-05-13 11:05:56,329] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-mysql-connector-demo-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:05:56,345] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:05:56,345] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:05:56,345] INFO Kafka startTimeMs: 1589342756344 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:05:56,354] INFO [Producer clientId=connector-producer-mysql-connector-demo-0] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:05:56,355] INFO Finished creating connector mysql-connector-demo (org.apache.kafka.connect.runtime.Worker:273)
[2020-05-13 11:05:56,356] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-05-13 11:05:56,357] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-05-13 11:05:56,366] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1125)
[2020-05-13 11:05:56,393] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1440)
[2020-05-13 11:05:56,439] INFO Starting MySqlConnectorTask with configuration: (io.debezium.connector.common.BaseSourceTask:43)
[2020-05-13 11:05:56,440] INFO    connector.class = io.debezium.connector.mysql.MySqlConnector (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:05:56,441] INFO    database.user = debezium (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:05:56,441] INFO    database.server.id = 1 (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:05:56,441] INFO    database.history.kafka.bootstrap.servers = localhost:9092 (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:05:56,441] INFO    database.history.kafka.topic = dbhistory.demo (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:05:56,441] INFO    database.server.name = ghtk_chat (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:05:56,441] INFO    database.port = 3306 (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:05:56,441] INFO    include.schema.changes = true (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:05:56,441] INFO    table.whitelist = ghtk_chat.channels (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:05:56,441] INFO    task.class = io.debezium.connector.mysql.MySqlConnectorTask (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:05:56,441] INFO    database.hostname = localhost (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:05:56,442] INFO    database.password = ******** (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:05:56,442] INFO    name = mysql-connector-demo (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:05:56,859] INFO KafkaDatabaseHistory Consumer config: {key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, enable.auto.commit=false, group.id=mysql-connector-demo-dbhistory, bootstrap.servers=localhost:9092, fetch.min.bytes=1, session.timeout.ms=10000, auto.offset.reset=earliest, client.id=mysql-connector-demo-dbhistory} (io.debezium.relational.history.KafkaDatabaseHistory:171)
[2020-05-13 11:05:56,860] INFO KafkaDatabaseHistory Producer config: {retries=1, value.serializer=org.apache.kafka.common.serialization.StringSerializer, acks=1, batch.size=32768, max.block.ms=10000, bootstrap.servers=localhost:9092, buffer.memory=1048576, key.serializer=org.apache.kafka.common.serialization.StringSerializer, client.id=mysql-connector-demo-dbhistory, linger.ms=0} (io.debezium.relational.history.KafkaDatabaseHistory:172)
[2020-05-13 11:05:56,863] INFO ProducerConfig values: 
	acks = 1
	batch.size = 32768
	bootstrap.servers = [localhost:9092]
	buffer.memory = 1048576
	client.dns.lookup = default
	client.id = mysql-connector-demo-dbhistory
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 10000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:05:56,869] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:05:56,869] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:05:56,869] INFO Kafka startTimeMs: 1589342756869 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:05:56,870] INFO Found existing offset: {ts_sec=1589301382, file=mysql-bin.000008, pos=950, gtids=1507ff86-e9aa-11e9-b5ab-000c29f4a13b:1-3112, row=1, server_id=1, event=2} (io.debezium.connector.mysql.MySqlConnectorTask:82)
[2020-05-13 11:05:56,873] INFO [Producer clientId=mysql-connector-demo-dbhistory] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:05:56,875] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = mysql-connector-demo-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = mysql-connector-demo-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:05:56,883] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:05:56,884] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:05:56,884] INFO Kafka startTimeMs: 1589342756883 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:05:56,893] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:05:56,924] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = mysql-connector-demo-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = mysql-connector-demo-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:05:56,930] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:05:56,930] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:05:56,930] INFO Kafka startTimeMs: 1589342756930 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:05:56,931] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Subscribed to topic(s): dbhistory.demo (org.apache.kafka.clients.consumer.KafkaConsumer:969)
[2020-05-13 11:05:56,942] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:05:56,947] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2020-05-13 11:05:56,950] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:05:56,959] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:05:56,965] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Finished assignment for group at generation 1: {mysql-connector-demo-dbhistory-3720f1df-8d29-4ede-9180-e20ee625608c=Assignment(partitions=[dbhistory.demo-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:585)
[2020-05-13 11:05:56,973] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Successfully joined group with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:484)
[2020-05-13 11:05:56,976] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Adding newly assigned partitions: dbhistory.demo-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:267)
[2020-05-13 11:05:56,979] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Found no committed offset for partition dbhistory.demo-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1241)
[2020-05-13 11:05:56,981] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Resetting offset for partition dbhistory.demo-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 11:05:57,657] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Revoke previously assigned partitions dbhistory.demo-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:286)
[2020-05-13 11:05:57,657] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Member mysql-connector-demo-dbhistory-3720f1df-8d29-4ede-9180-e20ee625608c sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:916)
[2020-05-13 11:05:57,689] INFO MySQL current GTID set 1507ff86-e9aa-11e9-b5ab-000c29f4a13b:1-3112 does contain the GTID set required by the connector 1507ff86-e9aa-11e9-b5ab-000c29f4a13b:1-3112 (io.debezium.connector.mysql.MySqlConnectorTask:493)
[2020-05-13 11:05:57,718] INFO GTIDs known by the server but not processed yet , for replication are available only  (io.debezium.connector.mysql.MySqlConnectorTask:498)
[2020-05-13 11:05:57,753] INFO Requested thread factory for connector MySqlConnector, id = ghtk_chat named = binlog-client (io.debezium.util.Threads:250)
[2020-05-13 11:05:57,777] INFO Creating thread debezium-mysqlconnector-ghtk_chat-binlog-client (io.debezium.util.Threads:267)
[2020-05-13 11:05:57,785] INFO Creating thread debezium-mysqlconnector-ghtk_chat-binlog-client (io.debezium.util.Threads:267)
[2020-05-13 11:05:57,894] INFO Connected to MySQL binlog at localhost:3306, starting at GTIDs 1507ff86-e9aa-11e9-b5ab-000c29f4a13b:1-3112 and binlog file 'mysql-bin.000008', pos=950, skipping 2 events plus 1 rows (io.debezium.connector.mysql.BinlogReader:1019)
[2020-05-13 11:05:57,895] INFO WorkerSourceTask{id=mysql-connector-demo-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:209)
[2020-05-13 11:05:57,895] INFO Creating thread debezium-mysqlconnector-ghtk_chat-binlog-client (io.debezium.util.Threads:267)
[2020-05-13 11:05:57,937] ERROR Error during binlog processing. Last offset stored = null, binlog reader near position = mysql-bin.000008/950 (io.debezium.connector.mysql.BinlogReader:1069)
[2020-05-13 11:05:57,939] INFO Stopped reading binlog after 0 events, no new offset was recorded (io.debezium.connector.mysql.BinlogReader:1007)
[2020-05-13 11:05:58,239] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:05:58,240] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:05:58,241] ERROR WorkerSourceTask{id=mysql-connector-demo-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:179)
org.apache.kafka.connect.errors.ConnectException: Could not open log file Error code: 1236; SQLSTATE: HY000.
	at io.debezium.connector.mysql.AbstractReader.wrap(AbstractReader.java:230)
	at io.debezium.connector.mysql.AbstractReader.failed(AbstractReader.java:197)
	at io.debezium.connector.mysql.BinlogReader$ReaderThreadLifecycleListener.onCommunicationFailure(BinlogReader.java:1033)
	at com.github.shyiko.mysql.binlog.BinaryLogClient.listenForEventPackets(BinaryLogClient.java:950)
	at com.github.shyiko.mysql.binlog.BinaryLogClient.connect(BinaryLogClient.java:580)
	at com.github.shyiko.mysql.binlog.BinaryLogClient$7.run(BinaryLogClient.java:825)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: com.github.shyiko.mysql.binlog.network.ServerException: Could not open log file
	at com.github.shyiko.mysql.binlog.BinaryLogClient.listenForEventPackets(BinaryLogClient.java:914)
	... 3 more
[2020-05-13 11:05:58,247] ERROR WorkerSourceTask{id=mysql-connector-demo-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:180)
[2020-05-13 11:05:58,247] INFO Stopping MySQL connector task (io.debezium.connector.mysql.MySqlConnectorTask:430)
[2020-05-13 11:05:58,247] INFO ChainedReader: Stopping the binlog reader (io.debezium.connector.mysql.ChainedReader:121)
[2020-05-13 11:05:58,247] INFO Discarding 0 unsent record(s) due to the connector shutting down (io.debezium.connector.mysql.BinlogReader:129)
[2020-05-13 11:05:58,247] INFO Discarding 0 unsent record(s) due to the connector shutting down (io.debezium.connector.mysql.BinlogReader:129)
[2020-05-13 11:05:58,248] INFO [Producer clientId=mysql-connector-demo-dbhistory] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:05:58,253] INFO Connector task finished all work and is now shutdown (io.debezium.connector.mysql.MySqlConnectorTask:465)
[2020-05-13 11:05:58,253] INFO [Producer clientId=connector-producer-mysql-connector-demo-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:06:06,358] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:06:06,362] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:06:16,363] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:06:16,382] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:06:26,383] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:06:26,386] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:06:36,386] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:06:36,390] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:06:46,390] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:06:46,410] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:06:56,411] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:06:56,411] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:07:05,354] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:05,355] INFO [Worker clientId=connect-1, groupId=connect-cluster] Group coordinator localhost:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:808)
[2020-05-13 11:07:05,354] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Error sending fetch request (sessionId=1282261903, epoch=141) to node 0: {}. (org.apache.kafka.clients.FetchSessionHandler:445)
org.apache.kafka.common.errors.DisconnectException
[2020-05-13 11:07:05,354] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:05,355] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Error sending fetch request (sessionId=2093537844, epoch=140) to node 0: {}. (org.apache.kafka.clients.FetchSessionHandler:445)
org.apache.kafka.common.errors.DisconnectException
[2020-05-13 11:07:05,355] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Error sending fetch request (sessionId=660646797, epoch=140) to node 0: {}. (org.apache.kafka.clients.FetchSessionHandler:445)
org.apache.kafka.common.errors.DisconnectException
[2020-05-13 11:07:05,453] WARN [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:05,454] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:05,454] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:05,454] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:05,455] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:05,456] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:05,456] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:05,553] WARN [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:05,554] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:05,556] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:05,604] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:05,604] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:05,606] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:05,606] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:05,754] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:05,754] WARN [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:05,756] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:05,804] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:05,806] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:05,806] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:05,855] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:06,205] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:06,206] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:06,206] WARN [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:06,207] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:06,258] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:06,258] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:06,306] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:06,412] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:07:06,412] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:07:07,008] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:07,009] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:07,109] WARN [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:07,110] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:07,159] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:07,209] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:07,211] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:07,861] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:07,962] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:08,011] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:08,112] WARN [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:08,114] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:08,212] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:08,212] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:08,355] INFO [Worker clientId=connect-1, groupId=connect-cluster] Broker coordinator was unreachable for 3000ms. Revoking previous assignment Assignment{error=0, leader='connect-1-8fe9bdd9-7db6-4194-8372-4263d01de8ed', leaderUrl='http://localhost:8083/', offset=12, connectorIds=[mysql-connector-demo], taskIds=[mysql-connector-demo-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} to avoid running tasks while not being a member the group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:137)
[2020-05-13 11:07:08,356] INFO Stopping connector mysql-connector-demo (org.apache.kafka.connect.runtime.Worker:358)
[2020-05-13 11:07:08,356] INFO Stopping task mysql-connector-demo-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-05-13 11:07:08,358] INFO Stopped connector mysql-connector-demo (org.apache.kafka.connect.runtime.Worker:374)
[2020-05-13 11:07:08,358] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1617)
[2020-05-13 11:07:08,814] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:08,942] WARN [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:09,057] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:09,165] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:09,267] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:09,366] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:09,415] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:09,917] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:09,942] WARN [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:10,220] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:10,260] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:10,268] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:10,326] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:10,526] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:11,078] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:11,084] WARN [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:11,162] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:11,325] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:11,326] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:11,481] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:11,579] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:11,931] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:12,065] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:12,093] WARN [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:12,178] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:12,379] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:07:13,038] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Error while fetching metadata with correlation id 151 : {connect-status=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:07:13,042] WARN [Producer clientId=producer-3] Error while fetching metadata with correlation id 7 : {connect-configs=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:07:13,144] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Error while fetching metadata with correlation id 152 : {connect-status=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:07:13,150] WARN [Producer clientId=producer-3] Error while fetching metadata with correlation id 8 : {connect-configs=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:07:13,249] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Error while fetching metadata with correlation id 153 : {connect-status=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:07:13,254] WARN [Producer clientId=producer-3] Error while fetching metadata with correlation id 9 : {connect-configs=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:07:13,290] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Error while fetching metadata with correlation id 152 : {connect-configs=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:07:13,299] WARN [Producer clientId=producer-2] Error while fetching metadata with correlation id 9 : {connect-status=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:07:13,353] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Error while fetching metadata with correlation id 154 : {connect-status=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:07:13,358] WARN [Producer clientId=producer-3] Error while fetching metadata with correlation id 10 : {connect-configs=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:07:13,394] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Error while fetching metadata with correlation id 153 : {connect-configs=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:07:13,403] WARN [Producer clientId=producer-2] Error while fetching metadata with correlation id 10 : {connect-status=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:07:13,458] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Error while fetching metadata with correlation id 155 : {connect-status=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:07:13,477] WARN [Producer clientId=producer-3] Error while fetching metadata with correlation id 11 : {connect-configs=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:07:13,501] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Error while fetching metadata with correlation id 154 : {connect-configs=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:07:13,508] WARN [Producer clientId=producer-2] Error while fetching metadata with correlation id 11 : {connect-status=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:07:13,674] INFO [Worker clientId=connect-1, groupId=connect-cluster] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2020-05-13 11:07:13,714] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1623)
[2020-05-13 11:07:13,714] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:222)
[2020-05-13 11:07:13,714] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:07:13,728] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation 16 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:484)
[2020-05-13 11:07:13,728] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 16 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-8fe9bdd9-7db6-4194-8372-4263d01de8ed', leaderUrl='http://localhost:8083/', offset=13, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=300000} with rebalance delay: 300000 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1542)
[2020-05-13 11:07:13,729] WARN [Worker clientId=connect-1, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1013)
[2020-05-13 11:07:13,729] INFO [Worker clientId=connect-1, groupId=connect-cluster] Current config state offset 12 is behind group assignment 13, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1074)
[2020-05-13 11:07:14,121] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 13 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1078)
[2020-05-13 11:07:14,121] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 13 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1104)
[2020-05-13 11:07:14,121] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1125)
[2020-05-13 11:10:53,286] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:66)
[2020-05-13 11:10:53,287] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-05-13 11:10:53,299] INFO Stopped http_localhost8083@29b732a2{HTTP/1.1,[http/1.1]}{localhost:8083} (org.eclipse.jetty.server.AbstractConnector:343)
[2020-05-13 11:10:53,300] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-05-13 11:10:53,303] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-05-13 11:10:53,303] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:609)
[2020-05-13 11:10:53,303] INFO [Worker clientId=connect-1, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:583)
[2020-05-13 11:10:53,304] INFO [Worker clientId=connect-1, groupId=connect-cluster] Member connect-1-8fe9bdd9-7db6-4194-8372-4263d01de8ed sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:916)
[2020-05-13 11:10:53,305] WARN [Worker clientId=connect-1, groupId=connect-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:897)
[2020-05-13 11:10:53,310] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:165)
[2020-05-13 11:10:53,311] INFO [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:10:53,320] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:191)
[2020-05-13 11:10:53,321] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:272)
[2020-05-13 11:10:53,321] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:165)
[2020-05-13 11:10:53,323] INFO [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:10:53,331] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:191)
[2020-05-13 11:10:53,331] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:274)
[2020-05-13 11:10:53,331] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-05-13 11:10:53,332] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:115)
[2020-05-13 11:10:53,333] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:165)
[2020-05-13 11:10:53,335] INFO [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:10:53,338] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:191)
[2020-05-13 11:10:53,338] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:117)
[2020-05-13 11:10:53,339] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-05-13 11:10:53,339] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:287)
[2020-05-13 11:10:53,340] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:629)
[2020-05-13 11:10:53,340] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:71)
[2020-05-13 11:10:54,490] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -Djava.awt.headless=true, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Private Build, OpenJDK 64-Bit Server VM, 11.0.5, 11.0.5+10-post-Ubuntu-0ubuntu1.119.04
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.4.1.jar:bin/../libs/connect-basic-auth-extension-2.4.1.jar:bin/../libs/connect-file-2.4.1.jar:bin/../libs/connect-json-2.4.1.jar:bin/../libs/connect-mirror-2.4.1.jar:bin/../libs/connect-mirror-client-2.4.1.jar:bin/../libs/connect-runtime-2.4.1.jar:bin/../libs/connect-transforms-2.4.1.jar:bin/../libs/guava-20.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.0.jar:bin/../libs/jackson-core-2.10.0.jar:bin/../libs/jackson-databind-2.10.0.jar:bin/../libs/jackson-dataformat-csv-2.10.0.jar:bin/../libs/jackson-datatype-jdk8-2.10.0.jar:bin/../libs/jackson-jaxrs-base-2.10.0.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:bin/../libs/jackson-module-paranamer-2.10.0.jar:bin/../libs/jackson-module-scala_2.12-2.10.0.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.20.v20190813.jar:bin/../libs/jetty-continuation-9.4.20.v20190813.jar:bin/../libs/jetty-http-9.4.20.v20190813.jar:bin/../libs/jetty-io-9.4.20.v20190813.jar:bin/../libs/jetty-security-9.4.20.v20190813.jar:bin/../libs/jetty-server-9.4.20.v20190813.jar:bin/../libs/jetty-servlet-9.4.20.v20190813.jar:bin/../libs/jetty-servlets-9.4.20.v20190813.jar:bin/../libs/jetty-util-9.4.20.v20190813.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.4.1.jar:bin/../libs/kafka_2.12-2.4.1-sources.jar:bin/../libs/kafka-clients-2.4.1.jar:bin/../libs/kafka-log4j-appender-2.4.1.jar:bin/../libs/kafka-streams-2.4.1.jar:bin/../libs/kafka-streams-examples-2.4.1.jar:bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:bin/../libs/kafka-streams-test-utils-2.4.1.jar:bin/../libs/kafka-tools-2.4.1.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.6.0.jar:bin/../libs/maven-artifact-3.6.1.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.0.jar:bin/../libs/reflections-0.9.11.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.2.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.28.jar:bin/../libs/slf4j-log4j12-1.7.28.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.3-1.jar
	os.spec = Linux, amd64, 5.0.0-38-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-05-13 11:10:54,503] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectDistributed:90)
[2020-05-13 11:10:54,520] INFO Loading plugin from: /home/admina/Desktop/ghtk/kafka/debezium-connector-mysql-0.10.0.Beta2-plugin/debezium-connector-mysql (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:241)
[2020-05-13 11:10:55,228] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/admina/Desktop/ghtk/kafka/debezium-connector-mysql-0.10.0.Beta2-plugin/debezium-connector-mysql/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:264)
[2020-05-13 11:10:55,232] INFO Added plugin 'io.debezium.connector.mysql.MySqlConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:55,232] INFO Added plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:55,232] INFO Added plugin 'io.debezium.transforms.UnwrapFromEnvelope' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:55,232] INFO Added plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:55,233] INFO Added plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:55,233] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:55,233] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:55,233] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,429] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@8bcc55f (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:264)
[2020-05-13 11:10:56,430] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,430] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,430] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,432] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,432] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,432] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,432] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,433] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,433] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,433] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,433] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,433] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,433] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,434] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,434] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,434] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,434] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,434] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,434] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,434] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,435] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,435] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,435] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,435] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,435] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,435] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,435] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,436] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,436] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,436] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,436] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,436] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,437] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,437] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,437] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,437] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,437] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,438] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,438] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,438] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,438] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,438] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,439] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:10:56,440] INFO Added aliases 'MySqlConnector' and 'MySql' to plugin 'io.debezium.connector.mysql.MySqlConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,440] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,440] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,440] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,440] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,441] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,441] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,441] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,441] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,441] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,442] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,442] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,442] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,442] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,442] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,443] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,443] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,443] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,443] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,443] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,444] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,444] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,444] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,444] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,444] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,444] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,445] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,445] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:10:56,445] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,445] INFO Added alias 'ByLogicalTableRouter' to plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:10:56,446] INFO Added alias 'ExtractNewRecordState' to plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:10:56,446] INFO Added alias 'UnwrapFromEnvelope' to plugin 'io.debezium.transforms.UnwrapFromEnvelope' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:10:56,447] INFO Added alias 'EventRouter' to plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:10:56,447] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:10:56,447] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:10:56,448] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:10:56,448] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:10:56,448] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,449] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,449] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:10:56,521] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = None
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = null
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.path = [/home/admina/Desktop/ghtk/kafka/debezium-connector-mysql-0.10.0.Beta2-plugin]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = localhost
	rest.port = 8083
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:347)
[2020-05-13 11:10:56,525] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-05-13 11:10:56,529] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 11:10:56,697] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:56,697] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:56,697] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:56,697] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:56,697] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:56,697] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:56,698] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:56,698] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:56,698] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:56,698] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:56,698] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:56,698] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:56,698] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:56,698] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:56,699] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:56,699] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:10:56,699] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:10:56,699] INFO Kafka startTimeMs: 1589343056699 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:10:57,021] INFO Kafka cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-05-13 11:10:57,038] INFO Logging initialized @2843ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-05-13 11:10:57,089] INFO Added connector for http://localhost:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-05-13 11:10:57,089] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-05-13 11:10:57,095] INFO jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 11.0.5+10-post-Ubuntu-0ubuntu1.119.04 (org.eclipse.jetty.server.Server:359)
[2020-05-13 11:10:57,124] INFO Started http_localhost8083@5a12c728{HTTP/1.1,[http/1.1]}{localhost:8083} (org.eclipse.jetty.server.AbstractConnector:293)
[2020-05-13 11:10:57,124] INFO Started @2929ms (org.eclipse.jetty.server.Server:399)
[2020-05-13 11:10:57,170] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-05-13 11:10:57,170] INFO REST server listening at http://localhost:8083/, advertising URL http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-05-13 11:10:57,170] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-05-13 11:10:57,170] INFO REST admin endpoints at http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-05-13 11:10:57,171] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-05-13 11:10:57,174] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-05-13 11:10:57,182] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:10:57,182] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:10:57,182] INFO Kafka startTimeMs: 1589343057182 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:10:57,280] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 11:10:57,281] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 11:10:57,321] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:10:57,321] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:10:57,321] INFO Kafka startTimeMs: 1589343057320 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:10:57,323] INFO Kafka Connect distributed worker initialization took 2820ms (org.apache.kafka.connect.cli.ConnectDistributed:128)
[2020-05-13 11:10:57,323] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:50)
[2020-05-13 11:10:57,324] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-05-13 11:10:57,324] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:275)
[2020-05-13 11:10:57,325] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-05-13 11:10:57,325] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:108)
[2020-05-13 11:10:57,325] INFO Starting KafkaBasedLog with topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:126)
[2020-05-13 11:10:57,326] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 11:10:57,332] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,332] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,332] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,332] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,333] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,333] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,333] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,333] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,333] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,333] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,333] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,333] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,333] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,333] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,333] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,334] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:10:57,334] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:10:57,334] INFO Kafka startTimeMs: 1589343057334 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:10:57,379] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:10:57,383] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-05-13 11:10:57,404] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,405] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,405] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,406] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,406] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,406] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,406] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,406] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,406] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,406] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,407] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,407] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,407] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,408] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,408] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,408] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:10:57,408] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:10:57,408] INFO Kafka startTimeMs: 1589343057408 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:10:57,416] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:10:57,416] INFO [Producer clientId=producer-1] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:10:57,449] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,450] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,450] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,450] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,450] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,450] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,450] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,450] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,450] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,450] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,451] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,451] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,451] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,451] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,451] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:10:57,451] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:10:57,452] INFO Kafka startTimeMs: 1589343057451 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:10:57,465] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:10:57,493] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-05-13 11:10:57,494] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-05-13 11:10:57,497] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:140)
[2020-05-13 11:10:57,497] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Subscribed to partition(s): connect-offsets-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1123)
[2020-05-13 11:10:57,502] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:564)
[2020-05-13 11:10:57,538] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 11:10:57,594] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:159)
[2020-05-13 11:10:57,595] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:161)
[2020-05-13 11:10:57,596] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:110)
[2020-05-13 11:10:57,598] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-05-13 11:10:57,598] INFO Starting KafkaBasedLog with topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:126)
[2020-05-13 11:10:57,599] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 11:10:57,602] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,603] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,603] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,603] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,603] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,603] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,603] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,603] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,604] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,604] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,604] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,604] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,604] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,604] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,605] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,605] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:10:57,605] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:10:57,605] INFO Kafka startTimeMs: 1589343057605 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:10:57,632] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:10:57,639] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,640] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,641] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,642] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,642] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,642] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,642] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,642] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,643] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,643] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,643] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,643] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,643] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,643] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,643] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,644] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:10:57,644] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:10:57,644] INFO Kafka startTimeMs: 1589343057644 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:10:57,645] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:10:57,646] INFO [Producer clientId=producer-2] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:10:57,656] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,656] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,657] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,657] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,657] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,657] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,657] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,657] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,657] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,657] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,657] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,658] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,658] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,658] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,658] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:10:57,658] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:10:57,658] INFO Kafka startTimeMs: 1589343057658 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:10:57,664] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:10:57,676] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Subscribed to partition(s): connect-status-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1123)
[2020-05-13 11:10:57,678] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:564)
[2020-05-13 11:10:57,695] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Resetting offset for partition connect-status-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 11:10:57,737] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:159)
[2020-05-13 11:10:57,738] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:161)
[2020-05-13 11:10:57,739] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:262)
[2020-05-13 11:10:57,740] INFO Starting KafkaBasedLog with topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:126)
[2020-05-13 11:10:57,740] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 11:10:57,743] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,744] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,744] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,744] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,744] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,744] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,744] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,744] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,745] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,745] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,745] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,745] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,745] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,745] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,745] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:10:57,746] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:10:57,746] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:10:57,746] INFO Kafka startTimeMs: 1589343057746 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:10:57,775] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:10:57,780] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,781] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,781] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,781] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,781] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,781] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,781] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,782] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,782] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,782] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,782] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,783] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,783] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,784] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,784] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:10:57,784] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:10:57,784] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:10:57,784] INFO Kafka startTimeMs: 1589343057784 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:10:57,786] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:10:57,789] INFO [Producer clientId=producer-3] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:10:57,793] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,793] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,794] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,795] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,796] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,796] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,796] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,796] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,796] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,797] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,797] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,797] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,797] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,797] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:10:57,797] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:10:57,797] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:10:57,797] INFO Kafka startTimeMs: 1589343057797 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:10:57,812] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:10:57,834] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Subscribed to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1123)
[2020-05-13 11:10:57,835] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:564)
[2020-05-13 11:10:57,851] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 11:10:57,868] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:159)
[2020-05-13 11:10:57,868] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:161)
[2020-05-13 11:10:57,868] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:267)
[2020-05-13 11:10:57,868] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:279)
[2020-05-13 11:10:57,886] INFO [Worker clientId=connect-1, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:10:57,887] INFO [Worker clientId=connect-1, groupId=connect-cluster] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2020-05-13 11:10:57,889] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:222)
[2020-05-13 11:10:57,889] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:10:57,906] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:10:57,980] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation 18 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:484)
[2020-05-13 11:10:57,987] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 18 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-f4d120d5-0cb0-4a42-ab2c-803019d5bfd2', leaderUrl='http://localhost:8083/', offset=13, connectorIds=[mysql-connector-demo], taskIds=[mysql-connector-demo-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1542)
[2020-05-13 11:10:57,988] WARN [Worker clientId=connect-1, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1013)
[2020-05-13 11:10:57,988] INFO [Worker clientId=connect-1, groupId=connect-cluster] Current config state offset -1 is behind group assignment 13, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1074)
[2020-05-13 11:10:58,357] INFO Started o.e.j.s.ServletContextHandler@46678e49{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:824)
[2020-05-13 11:10:58,358] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-05-13 11:10:58,358] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:56)
[2020-05-13 11:10:58,365] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 13 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1078)
[2020-05-13 11:10:58,365] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 13 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1104)
[2020-05-13 11:10:58,366] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector mysql-connector-demo (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1179)
[2020-05-13 11:10:58,367] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task mysql-connector-demo-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1139)
[2020-05-13 11:10:58,372] INFO Creating task mysql-connector-demo-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-05-13 11:10:58,374] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-05-13 11:10:58,375] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-05-13 11:10:58,377] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-05-13 11:10:58,377] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-05-13 11:10:58,378] INFO Creating connector mysql-connector-demo of type io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-05-13 11:10:58,384] INFO Instantiated connector mysql-connector-demo with version 0.10.0.Beta2 of type class io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-05-13 11:10:58,385] INFO TaskConfig values: 
	task.class = class io.debezium.connector.mysql.MySqlConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-05-13 11:10:58,386] INFO Instantiated task mysql-connector-demo-0 with version 0.10.0.Beta2 of type io.debezium.connector.mysql.MySqlConnectorTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-05-13 11:10:58,386] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 11:10:58,387] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task mysql-connector-demo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-05-13 11:10:58,387] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 11:10:58,388] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mysql-connector-demo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-05-13 11:10:58,388] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mysql-connector-demo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-05-13 11:10:58,392] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:514)
[2020-05-13 11:10:58,397] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-mysql-connector-demo-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:10:58,407] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:10:58,407] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:10:58,407] INFO Kafka startTimeMs: 1589343058405 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:10:58,409] INFO [Producer clientId=connector-producer-mysql-connector-demo-0] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:10:58,424] INFO Finished creating connector mysql-connector-demo (org.apache.kafka.connect.runtime.Worker:273)
[2020-05-13 11:10:58,425] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-05-13 11:10:58,426] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-05-13 11:10:58,433] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1125)
[2020-05-13 11:10:58,474] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1440)
[2020-05-13 11:10:58,524] INFO Starting MySqlConnectorTask with configuration: (io.debezium.connector.common.BaseSourceTask:43)
[2020-05-13 11:10:58,526] INFO    connector.class = io.debezium.connector.mysql.MySqlConnector (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:10:58,527] INFO    database.user = debezium (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:10:58,527] INFO    database.server.id = 1 (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:10:58,527] INFO    database.history.kafka.bootstrap.servers = localhost:9092 (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:10:58,527] INFO    database.history.kafka.topic = dbhistory.demo (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:10:58,527] INFO    database.server.name = ghtk_chat (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:10:58,527] INFO    database.port = 3306 (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:10:58,527] INFO    include.schema.changes = true (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:10:58,528] INFO    table.whitelist = ghtk_chat.channels (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:10:58,528] INFO    task.class = io.debezium.connector.mysql.MySqlConnectorTask (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:10:58,528] INFO    database.hostname = localhost (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:10:58,528] INFO    database.password = ******** (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:10:58,528] INFO    name = mysql-connector-demo (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:10:58,833] INFO KafkaDatabaseHistory Consumer config: {key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, enable.auto.commit=false, group.id=mysql-connector-demo-dbhistory, bootstrap.servers=localhost:9092, fetch.min.bytes=1, session.timeout.ms=10000, auto.offset.reset=earliest, client.id=mysql-connector-demo-dbhistory} (io.debezium.relational.history.KafkaDatabaseHistory:171)
[2020-05-13 11:10:58,833] INFO KafkaDatabaseHistory Producer config: {retries=1, value.serializer=org.apache.kafka.common.serialization.StringSerializer, acks=1, batch.size=32768, max.block.ms=10000, bootstrap.servers=localhost:9092, buffer.memory=1048576, key.serializer=org.apache.kafka.common.serialization.StringSerializer, client.id=mysql-connector-demo-dbhistory, linger.ms=0} (io.debezium.relational.history.KafkaDatabaseHistory:172)
[2020-05-13 11:10:58,835] INFO ProducerConfig values: 
	acks = 1
	batch.size = 32768
	bootstrap.servers = [localhost:9092]
	buffer.memory = 1048576
	client.dns.lookup = default
	client.id = mysql-connector-demo-dbhistory
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 10000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:10:58,839] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:10:58,840] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:10:58,840] INFO Kafka startTimeMs: 1589343058839 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:10:58,842] INFO Found existing offset: {ts_sec=1589301382, file=mysql-bin.000008, pos=950, gtids=1507ff86-e9aa-11e9-b5ab-000c29f4a13b:1-3112, row=1, server_id=1, event=2} (io.debezium.connector.mysql.MySqlConnectorTask:82)
[2020-05-13 11:10:58,845] INFO [Producer clientId=mysql-connector-demo-dbhistory] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:10:58,846] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = mysql-connector-demo-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = mysql-connector-demo-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:10:58,850] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:10:58,850] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:10:58,850] INFO Kafka startTimeMs: 1589343058850 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:10:58,854] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:10:58,875] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = mysql-connector-demo-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = mysql-connector-demo-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:10:58,881] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:10:58,882] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:10:58,882] INFO Kafka startTimeMs: 1589343058881 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:10:58,883] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Subscribed to topic(s): dbhistory.demo (org.apache.kafka.clients.consumer.KafkaConsumer:969)
[2020-05-13 11:10:58,890] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:10:58,897] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2020-05-13 11:10:58,902] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:10:58,908] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:10:58,914] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Finished assignment for group at generation 3: {mysql-connector-demo-dbhistory-e76e458b-017f-4810-8c1d-fe6f4ff4e18a=Assignment(partitions=[dbhistory.demo-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:585)
[2020-05-13 11:10:58,921] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Successfully joined group with generation 3 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:484)
[2020-05-13 11:10:58,922] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Adding newly assigned partitions: dbhistory.demo-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:267)
[2020-05-13 11:10:58,925] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Found no committed offset for partition dbhistory.demo-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1241)
[2020-05-13 11:10:58,929] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Resetting offset for partition dbhistory.demo-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 11:10:59,548] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Revoke previously assigned partitions dbhistory.demo-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:286)
[2020-05-13 11:10:59,549] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Member mysql-connector-demo-dbhistory-e76e458b-017f-4810-8c1d-fe6f4ff4e18a sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:916)
[2020-05-13 11:10:59,587] INFO MySQL current GTID set 1507ff86-e9aa-11e9-b5ab-000c29f4a13b:1-3112 does contain the GTID set required by the connector 1507ff86-e9aa-11e9-b5ab-000c29f4a13b:1-3112 (io.debezium.connector.mysql.MySqlConnectorTask:493)
[2020-05-13 11:10:59,607] INFO GTIDs known by the server but not processed yet , for replication are available only  (io.debezium.connector.mysql.MySqlConnectorTask:498)
[2020-05-13 11:10:59,650] INFO Requested thread factory for connector MySqlConnector, id = ghtk_chat named = binlog-client (io.debezium.util.Threads:250)
[2020-05-13 11:10:59,687] INFO Creating thread debezium-mysqlconnector-ghtk_chat-binlog-client (io.debezium.util.Threads:267)
[2020-05-13 11:10:59,693] INFO Creating thread debezium-mysqlconnector-ghtk_chat-binlog-client (io.debezium.util.Threads:267)
[2020-05-13 11:10:59,789] INFO Connected to MySQL binlog at localhost:3306, starting at GTIDs 1507ff86-e9aa-11e9-b5ab-000c29f4a13b:1-3112 and binlog file 'mysql-bin.000008', pos=950, skipping 2 events plus 1 rows (io.debezium.connector.mysql.BinlogReader:1019)
[2020-05-13 11:10:59,790] INFO Creating thread debezium-mysqlconnector-ghtk_chat-binlog-client (io.debezium.util.Threads:267)
[2020-05-13 11:10:59,791] INFO WorkerSourceTask{id=mysql-connector-demo-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:209)
[2020-05-13 11:10:59,830] ERROR Error during binlog processing. Last offset stored = null, binlog reader near position = mysql-bin.000008/950 (io.debezium.connector.mysql.BinlogReader:1069)
[2020-05-13 11:10:59,832] INFO Stopped reading binlog after 0 events, no new offset was recorded (io.debezium.connector.mysql.BinlogReader:1007)
[2020-05-13 11:11:00,126] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:11:00,126] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:11:00,127] ERROR WorkerSourceTask{id=mysql-connector-demo-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:179)
org.apache.kafka.connect.errors.ConnectException: Could not open log file Error code: 1236; SQLSTATE: HY000.
	at io.debezium.connector.mysql.AbstractReader.wrap(AbstractReader.java:230)
	at io.debezium.connector.mysql.AbstractReader.failed(AbstractReader.java:197)
	at io.debezium.connector.mysql.BinlogReader$ReaderThreadLifecycleListener.onCommunicationFailure(BinlogReader.java:1033)
	at com.github.shyiko.mysql.binlog.BinaryLogClient.listenForEventPackets(BinaryLogClient.java:950)
	at com.github.shyiko.mysql.binlog.BinaryLogClient.connect(BinaryLogClient.java:580)
	at com.github.shyiko.mysql.binlog.BinaryLogClient$7.run(BinaryLogClient.java:825)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: com.github.shyiko.mysql.binlog.network.ServerException: Could not open log file
	at com.github.shyiko.mysql.binlog.BinaryLogClient.listenForEventPackets(BinaryLogClient.java:914)
	... 3 more
[2020-05-13 11:11:00,128] ERROR WorkerSourceTask{id=mysql-connector-demo-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:180)
[2020-05-13 11:11:00,128] INFO Stopping MySQL connector task (io.debezium.connector.mysql.MySqlConnectorTask:430)
[2020-05-13 11:11:00,129] INFO ChainedReader: Stopping the binlog reader (io.debezium.connector.mysql.ChainedReader:121)
[2020-05-13 11:11:00,129] INFO Discarding 0 unsent record(s) due to the connector shutting down (io.debezium.connector.mysql.BinlogReader:129)
[2020-05-13 11:11:00,129] INFO Discarding 0 unsent record(s) due to the connector shutting down (io.debezium.connector.mysql.BinlogReader:129)
[2020-05-13 11:11:00,129] INFO [Producer clientId=mysql-connector-demo-dbhistory] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:11:00,136] INFO Connector task finished all work and is now shutdown (io.debezium.connector.mysql.MySqlConnectorTask:465)
[2020-05-13 11:11:00,136] INFO [Producer clientId=connector-producer-mysql-connector-demo-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:11:08,424] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:11:08,427] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:11:18,428] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:11:18,430] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:11:28,431] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:11:28,434] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:11:38,435] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:11:38,447] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:11:48,447] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:11:48,452] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:11:58,453] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:11:58,466] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:12:08,467] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:12:08,468] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:12:18,469] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:12:18,489] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:12:28,490] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:12:28,490] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:12:38,491] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:12:38,492] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:12:48,492] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:12:48,492] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:12:58,493] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:12:58,494] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:13:08,495] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:13:08,496] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:13:18,496] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:13:18,497] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:13:28,497] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:13:28,497] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:13:38,498] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:13:38,498] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:13:48,499] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:13:48,500] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:13:58,500] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:13:58,501] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:14:08,501] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:14:08,502] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:14:18,503] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:14:18,503] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:14:28,504] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:14:28,505] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:14:38,506] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:14:38,507] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:14:48,507] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:14:48,508] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:14:58,509] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:14:58,509] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:15:08,510] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:15:08,511] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:15:18,512] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:15:18,641] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:15:28,642] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:15:28,643] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:15:38,643] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:15:38,646] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:15:48,647] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:15:48,651] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:15:58,653] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:15:58,658] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:16:08,658] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:16:08,664] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:16:18,665] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:16:18,672] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:16:28,672] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:16:28,682] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:16:38,683] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:16:38,693] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:16:48,694] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:16:48,704] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:16:58,705] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:16:58,715] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:17:08,716] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:17:08,728] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:17:18,729] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:17:18,753] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:17:28,754] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:17:28,754] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:17:38,755] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:17:38,768] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:17:48,768] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:17:48,769] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:17:58,769] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:17:58,784] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:18:08,785] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:18:08,799] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:18:18,800] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:18:18,816] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:18:28,817] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:18:28,833] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:18:38,833] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:18:38,850] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:18:48,851] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:18:48,868] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:18:58,869] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:18:58,886] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:19:08,887] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:19:08,905] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:19:18,905] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:19:18,924] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:19:28,925] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:19:28,944] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:19:38,945] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:19:38,964] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:19:48,965] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:19:48,986] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:19:55,164] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:66)
[2020-05-13 11:19:55,164] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-05-13 11:19:55,166] INFO Stopped http_localhost8083@5a12c728{HTTP/1.1,[http/1.1]}{localhost:8083} (org.eclipse.jetty.server.AbstractConnector:343)
[2020-05-13 11:19:55,167] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-05-13 11:19:55,167] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-05-13 11:19:55,167] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:609)
[2020-05-13 11:19:55,168] INFO [Worker clientId=connect-1, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:583)
[2020-05-13 11:19:55,168] INFO Stopping connector mysql-connector-demo (org.apache.kafka.connect.runtime.Worker:358)
[2020-05-13 11:19:55,169] INFO Stopping task mysql-connector-demo-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-05-13 11:19:55,170] INFO Stopped connector mysql-connector-demo (org.apache.kafka.connect.runtime.Worker:374)
[2020-05-13 11:19:55,171] INFO [Worker clientId=connect-1, groupId=connect-cluster] Member connect-1-f4d120d5-0cb0-4a42-ab2c-803019d5bfd2 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:916)
[2020-05-13 11:19:55,172] WARN [Worker clientId=connect-1, groupId=connect-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:897)
[2020-05-13 11:19:55,173] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:165)
[2020-05-13 11:19:55,174] INFO [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:19:55,176] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:191)
[2020-05-13 11:19:55,176] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:272)
[2020-05-13 11:19:55,177] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:165)
[2020-05-13 11:19:55,177] INFO [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:19:55,179] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:191)
[2020-05-13 11:19:55,179] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:274)
[2020-05-13 11:19:55,179] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-05-13 11:19:55,180] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:115)
[2020-05-13 11:19:55,180] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:165)
[2020-05-13 11:19:55,180] INFO [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:19:55,183] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:191)
[2020-05-13 11:19:55,184] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:117)
[2020-05-13 11:19:55,184] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-05-13 11:19:55,185] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:287)
[2020-05-13 11:19:55,186] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:629)
[2020-05-13 11:19:55,186] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:71)
[2020-05-13 11:19:56,346] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -Djava.awt.headless=true, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Private Build, OpenJDK 64-Bit Server VM, 11.0.5, 11.0.5+10-post-Ubuntu-0ubuntu1.119.04
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.4.1.jar:bin/../libs/connect-basic-auth-extension-2.4.1.jar:bin/../libs/connect-file-2.4.1.jar:bin/../libs/connect-json-2.4.1.jar:bin/../libs/connect-mirror-2.4.1.jar:bin/../libs/connect-mirror-client-2.4.1.jar:bin/../libs/connect-runtime-2.4.1.jar:bin/../libs/connect-transforms-2.4.1.jar:bin/../libs/guava-20.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.0.jar:bin/../libs/jackson-core-2.10.0.jar:bin/../libs/jackson-databind-2.10.0.jar:bin/../libs/jackson-dataformat-csv-2.10.0.jar:bin/../libs/jackson-datatype-jdk8-2.10.0.jar:bin/../libs/jackson-jaxrs-base-2.10.0.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:bin/../libs/jackson-module-paranamer-2.10.0.jar:bin/../libs/jackson-module-scala_2.12-2.10.0.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.20.v20190813.jar:bin/../libs/jetty-continuation-9.4.20.v20190813.jar:bin/../libs/jetty-http-9.4.20.v20190813.jar:bin/../libs/jetty-io-9.4.20.v20190813.jar:bin/../libs/jetty-security-9.4.20.v20190813.jar:bin/../libs/jetty-server-9.4.20.v20190813.jar:bin/../libs/jetty-servlet-9.4.20.v20190813.jar:bin/../libs/jetty-servlets-9.4.20.v20190813.jar:bin/../libs/jetty-util-9.4.20.v20190813.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.4.1.jar:bin/../libs/kafka_2.12-2.4.1-sources.jar:bin/../libs/kafka-clients-2.4.1.jar:bin/../libs/kafka-log4j-appender-2.4.1.jar:bin/../libs/kafka-streams-2.4.1.jar:bin/../libs/kafka-streams-examples-2.4.1.jar:bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:bin/../libs/kafka-streams-test-utils-2.4.1.jar:bin/../libs/kafka-tools-2.4.1.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.6.0.jar:bin/../libs/maven-artifact-3.6.1.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.0.jar:bin/../libs/reflections-0.9.11.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.2.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.28.jar:bin/../libs/slf4j-log4j12-1.7.28.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.3-1.jar
	os.spec = Linux, amd64, 5.0.0-38-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-05-13 11:19:56,353] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectDistributed:90)
[2020-05-13 11:19:56,377] INFO Loading plugin from: /home/admina/Desktop/ghtk/kafka/debezium-connector-mysql-0.10.0.Beta2-plugin/debezium-connector-mysql (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:241)
[2020-05-13 11:19:57,047] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/admina/Desktop/ghtk/kafka/debezium-connector-mysql-0.10.0.Beta2-plugin/debezium-connector-mysql/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:264)
[2020-05-13 11:19:57,049] INFO Added plugin 'io.debezium.connector.mysql.MySqlConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:57,049] INFO Added plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:57,049] INFO Added plugin 'io.debezium.transforms.UnwrapFromEnvelope' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:57,049] INFO Added plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:57,049] INFO Added plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:57,050] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:57,050] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:57,050] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,211] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@8bcc55f (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:264)
[2020-05-13 11:19:58,211] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,212] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,212] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,214] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,214] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,214] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,214] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,215] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,215] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,215] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,215] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,215] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,215] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,216] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,216] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,216] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,216] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,216] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,216] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,217] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,217] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,217] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,217] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,217] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,217] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,218] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,218] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,218] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,218] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,218] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,218] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,218] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,219] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,219] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,219] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,219] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,219] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,219] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,219] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,220] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,220] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,220] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,220] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:19:58,221] INFO Added aliases 'MySqlConnector' and 'MySql' to plugin 'io.debezium.connector.mysql.MySqlConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,222] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,222] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,222] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,222] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,222] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,223] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,223] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,223] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,223] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,223] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,223] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,224] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,224] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,224] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,224] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,224] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,224] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,225] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,225] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,225] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,225] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,225] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,225] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,226] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,226] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,226] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,226] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:19:58,226] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,227] INFO Added alias 'ByLogicalTableRouter' to plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:19:58,227] INFO Added alias 'ExtractNewRecordState' to plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:19:58,227] INFO Added alias 'UnwrapFromEnvelope' to plugin 'io.debezium.transforms.UnwrapFromEnvelope' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:19:58,227] INFO Added alias 'EventRouter' to plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:19:58,227] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:19:58,227] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:19:58,228] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:19:58,228] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:19:58,228] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,228] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,228] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:19:58,310] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = None
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = null
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.path = [/home/admina/Desktop/ghtk/kafka/debezium-connector-mysql-0.10.0.Beta2-plugin]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = localhost
	rest.port = 8083
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:347)
[2020-05-13 11:19:58,313] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-05-13 11:19:58,316] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 11:19:58,464] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,464] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,464] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,464] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,465] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,465] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,465] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,465] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,465] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,465] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,465] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,465] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,465] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,466] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,466] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,466] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:19:58,466] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:19:58,466] INFO Kafka startTimeMs: 1589343598466 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:19:58,698] INFO Kafka cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-05-13 11:19:58,714] INFO Logging initialized @2641ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-05-13 11:19:58,771] INFO Added connector for http://localhost:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-05-13 11:19:58,771] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-05-13 11:19:58,776] INFO jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 11.0.5+10-post-Ubuntu-0ubuntu1.119.04 (org.eclipse.jetty.server.Server:359)
[2020-05-13 11:19:58,802] INFO Started http_localhost8083@24528a25{HTTP/1.1,[http/1.1]}{localhost:8083} (org.eclipse.jetty.server.AbstractConnector:293)
[2020-05-13 11:19:58,802] INFO Started @2729ms (org.eclipse.jetty.server.Server:399)
[2020-05-13 11:19:58,826] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-05-13 11:19:58,826] INFO REST server listening at http://localhost:8083/, advertising URL http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-05-13 11:19:58,826] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-05-13 11:19:58,827] INFO REST admin endpoints at http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-05-13 11:19:58,827] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-05-13 11:19:58,830] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-05-13 11:19:58,839] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:19:58,839] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:19:58,839] INFO Kafka startTimeMs: 1589343598839 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:19:58,937] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 11:19:58,938] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 11:19:58,976] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:19:58,976] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:19:58,976] INFO Kafka startTimeMs: 1589343598976 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:19:58,978] INFO Kafka Connect distributed worker initialization took 2625ms (org.apache.kafka.connect.cli.ConnectDistributed:128)
[2020-05-13 11:19:58,978] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:50)
[2020-05-13 11:19:58,979] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-05-13 11:19:58,979] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:275)
[2020-05-13 11:19:58,981] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-05-13 11:19:58,981] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:108)
[2020-05-13 11:19:58,981] INFO Starting KafkaBasedLog with topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:126)
[2020-05-13 11:19:58,986] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 11:19:58,992] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,993] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,993] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,993] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,993] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,993] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,993] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,993] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,993] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,993] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,994] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,994] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,994] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,994] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,994] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:58,994] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:19:58,994] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:19:58,995] INFO Kafka startTimeMs: 1589343598994 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:19:59,030] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:19:59,040] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-05-13 11:19:59,066] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,067] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,067] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,067] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,067] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,068] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,068] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,068] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,068] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,068] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,068] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,069] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,069] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,069] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,069] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,069] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:19:59,069] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:19:59,069] INFO Kafka startTimeMs: 1589343599069 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:19:59,080] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:19:59,092] INFO [Producer clientId=producer-1] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:19:59,123] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,124] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,124] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,125] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,125] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,126] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,126] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,126] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,126] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,126] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,127] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,127] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,127] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,127] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,127] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:19:59,127] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:19:59,128] INFO Kafka startTimeMs: 1589343599127 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:19:59,141] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:19:59,160] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Subscribed to partition(s): connect-offsets-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1123)
[2020-05-13 11:19:59,160] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-05-13 11:19:59,161] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-05-13 11:19:59,162] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:140)
[2020-05-13 11:19:59,164] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:564)
[2020-05-13 11:19:59,192] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 11:19:59,244] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:159)
[2020-05-13 11:19:59,244] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:161)
[2020-05-13 11:19:59,244] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:110)
[2020-05-13 11:19:59,247] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-05-13 11:19:59,248] INFO Starting KafkaBasedLog with topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:126)
[2020-05-13 11:19:59,248] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 11:19:59,252] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,252] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,253] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,253] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,253] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,253] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,254] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,254] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,255] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,258] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,259] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,260] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,260] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,260] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,260] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,260] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:19:59,261] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:19:59,261] INFO Kafka startTimeMs: 1589343599260 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:19:59,293] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:19:59,302] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,304] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,304] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,304] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,306] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,306] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,306] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,306] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,306] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,306] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,307] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,307] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,307] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,307] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,307] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,307] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:19:59,307] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:19:59,307] INFO Kafka startTimeMs: 1589343599307 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:19:59,308] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:19:59,313] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,313] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,319] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,320] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,320] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,320] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,320] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,320] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,320] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,320] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,320] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,321] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,321] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,321] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,321] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:19:59,322] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:19:59,322] INFO Kafka startTimeMs: 1589343599321 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:19:59,324] INFO [Producer clientId=producer-2] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:19:59,338] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:19:59,356] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Subscribed to partition(s): connect-status-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1123)
[2020-05-13 11:19:59,357] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:564)
[2020-05-13 11:19:59,375] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Resetting offset for partition connect-status-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 11:19:59,424] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:159)
[2020-05-13 11:19:59,425] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:161)
[2020-05-13 11:19:59,432] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:262)
[2020-05-13 11:19:59,432] INFO Starting KafkaBasedLog with topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:126)
[2020-05-13 11:19:59,434] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 11:19:59,456] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,456] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,457] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,457] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,457] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,457] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,457] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,460] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,460] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,460] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,461] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,461] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,461] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,461] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,461] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:19:59,461] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:19:59,461] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:19:59,461] INFO Kafka startTimeMs: 1589343599461 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:19:59,480] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:19:59,485] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,489] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,489] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,490] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,490] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,490] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,490] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,490] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,490] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,490] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,490] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,490] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,490] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,491] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,491] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:19:59,491] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:19:59,491] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:19:59,491] INFO Kafka startTimeMs: 1589343599491 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:19:59,493] INFO [Producer clientId=producer-3] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:19:59,493] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:19:59,500] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,502] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,502] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,503] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,503] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,503] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,504] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,504] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,504] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,504] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,504] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,504] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,505] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,505] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:19:59,505] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:19:59,505] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:19:59,505] INFO Kafka startTimeMs: 1589343599505 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:19:59,511] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:19:59,520] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Subscribed to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1123)
[2020-05-13 11:19:59,521] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:564)
[2020-05-13 11:19:59,532] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 11:19:59,554] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:159)
[2020-05-13 11:19:59,556] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:161)
[2020-05-13 11:19:59,557] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:267)
[2020-05-13 11:19:59,558] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:279)
[2020-05-13 11:19:59,578] INFO [Worker clientId=connect-1, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:19:59,579] INFO [Worker clientId=connect-1, groupId=connect-cluster] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2020-05-13 11:19:59,581] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:222)
[2020-05-13 11:19:59,583] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:19:59,601] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:19:59,642] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation 20 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:484)
[2020-05-13 11:19:59,643] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 20 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-5894ef49-c2c1-48e5-b242-253271136141', leaderUrl='http://localhost:8083/', offset=14, connectorIds=[mysql-connector-demo], taskIds=[mysql-connector-demo-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1542)
[2020-05-13 11:19:59,643] WARN [Worker clientId=connect-1, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1013)
[2020-05-13 11:19:59,644] INFO [Worker clientId=connect-1, groupId=connect-cluster] Current config state offset -1 is behind group assignment 14, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1074)
[2020-05-13 11:19:59,963] INFO Started o.e.j.s.ServletContextHandler@16ade133{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:824)
[2020-05-13 11:19:59,963] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-05-13 11:19:59,963] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:56)
[2020-05-13 11:20:00,044] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 14 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1078)
[2020-05-13 11:20:00,044] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 14 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1104)
[2020-05-13 11:20:00,046] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector mysql-connector-demo (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1179)
[2020-05-13 11:20:00,046] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task mysql-connector-demo-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1139)
[2020-05-13 11:20:00,051] INFO Creating task mysql-connector-demo-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-05-13 11:20:00,052] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-05-13 11:20:00,053] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-05-13 11:20:00,053] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-05-13 11:20:00,053] INFO Creating connector mysql-connector-demo of type io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-05-13 11:20:00,054] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-05-13 11:20:00,057] INFO Instantiated connector mysql-connector-demo with version 0.10.0.Beta2 of type class io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-05-13 11:20:00,059] INFO TaskConfig values: 
	task.class = class io.debezium.connector.mysql.MySqlConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-05-13 11:20:00,061] INFO Instantiated task mysql-connector-demo-0 with version 0.10.0.Beta2 of type io.debezium.connector.mysql.MySqlConnectorTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-05-13 11:20:00,062] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 11:20:00,064] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task mysql-connector-demo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-05-13 11:20:00,064] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 11:20:00,064] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mysql-connector-demo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-05-13 11:20:00,065] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mysql-connector-demo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-05-13 11:20:00,069] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:514)
[2020-05-13 11:20:00,073] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-mysql-connector-demo-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:20:00,077] INFO Finished creating connector mysql-connector-demo (org.apache.kafka.connect.runtime.Worker:273)
[2020-05-13 11:20:00,079] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-05-13 11:20:00,079] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-05-13 11:20:00,083] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:20:00,084] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:20:00,085] INFO Kafka startTimeMs: 1589343600083 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:20:00,093] INFO [Producer clientId=connector-producer-mysql-connector-demo-0] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:20:00,106] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1125)
[2020-05-13 11:20:00,167] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1440)
[2020-05-13 11:20:00,223] INFO Starting MySqlConnectorTask with configuration: (io.debezium.connector.common.BaseSourceTask:43)
[2020-05-13 11:20:00,225] INFO    connector.class = io.debezium.connector.mysql.MySqlConnector (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:20:00,226] INFO    database.user = debezium (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:20:00,226] INFO    database.server.id = 1 (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:20:00,226] INFO    database.history.kafka.bootstrap.servers = localhost:9092 (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:20:00,226] INFO    database.history.kafka.topic = dbhistory.demo (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:20:00,227] INFO    database.server.name = ghtk_chat (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:20:00,227] INFO    database.port = 3306 (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:20:00,227] INFO    include.schema.changes = true (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:20:00,227] INFO    table.whitelist = ghtk_chat.channels (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:20:00,227] INFO    task.class = io.debezium.connector.mysql.MySqlConnectorTask (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:20:00,227] INFO    database.hostname = localhost (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:20:00,227] INFO    database.password = ******** (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:20:00,227] INFO    name = mysql-connector-demo (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:20:00,509] INFO KafkaDatabaseHistory Consumer config: {key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, enable.auto.commit=false, group.id=mysql-connector-demo-dbhistory, bootstrap.servers=localhost:9092, fetch.min.bytes=1, session.timeout.ms=10000, auto.offset.reset=earliest, client.id=mysql-connector-demo-dbhistory} (io.debezium.relational.history.KafkaDatabaseHistory:171)
[2020-05-13 11:20:00,509] INFO KafkaDatabaseHistory Producer config: {retries=1, value.serializer=org.apache.kafka.common.serialization.StringSerializer, acks=1, batch.size=32768, max.block.ms=10000, bootstrap.servers=localhost:9092, buffer.memory=1048576, key.serializer=org.apache.kafka.common.serialization.StringSerializer, client.id=mysql-connector-demo-dbhistory, linger.ms=0} (io.debezium.relational.history.KafkaDatabaseHistory:172)
[2020-05-13 11:20:00,512] INFO ProducerConfig values: 
	acks = 1
	batch.size = 32768
	bootstrap.servers = [localhost:9092]
	buffer.memory = 1048576
	client.dns.lookup = default
	client.id = mysql-connector-demo-dbhistory
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 10000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:20:00,516] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:20:00,516] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:20:00,517] INFO Kafka startTimeMs: 1589343600516 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:20:00,517] INFO Found existing offset: {ts_sec=1589301382, file=mysql-bin.000008, pos=950, gtids=1507ff86-e9aa-11e9-b5ab-000c29f4a13b:1-3112, row=1, server_id=1, event=2} (io.debezium.connector.mysql.MySqlConnectorTask:82)
[2020-05-13 11:20:00,520] INFO [Producer clientId=mysql-connector-demo-dbhistory] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:20:00,522] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = mysql-connector-demo-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = mysql-connector-demo-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:20:00,527] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:20:00,527] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:20:00,528] INFO Kafka startTimeMs: 1589343600527 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:20:00,537] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:20:00,564] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = mysql-connector-demo-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = mysql-connector-demo-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:20:00,568] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:20:00,568] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:20:00,568] INFO Kafka startTimeMs: 1589343600568 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:20:00,569] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Subscribed to topic(s): dbhistory.demo (org.apache.kafka.clients.consumer.KafkaConsumer:969)
[2020-05-13 11:20:00,575] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:20:00,581] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2020-05-13 11:20:00,583] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:20:00,589] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:20:00,594] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Finished assignment for group at generation 1: {mysql-connector-demo-dbhistory-b5ed2a0a-492e-467d-8037-c76119ca01bf=Assignment(partitions=[dbhistory.demo-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:585)
[2020-05-13 11:20:00,597] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Successfully joined group with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:484)
[2020-05-13 11:20:00,598] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Adding newly assigned partitions: dbhistory.demo-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:267)
[2020-05-13 11:20:00,601] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Found no committed offset for partition dbhistory.demo-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1241)
[2020-05-13 11:20:00,603] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Resetting offset for partition dbhistory.demo-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 11:20:01,240] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Revoke previously assigned partitions dbhistory.demo-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:286)
[2020-05-13 11:20:01,241] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Member mysql-connector-demo-dbhistory-b5ed2a0a-492e-467d-8037-c76119ca01bf sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:916)
[2020-05-13 11:20:01,275] INFO MySQL current GTID set 1507ff86-e9aa-11e9-b5ab-000c29f4a13b:1-3112 does contain the GTID set required by the connector 1507ff86-e9aa-11e9-b5ab-000c29f4a13b:1-3112 (io.debezium.connector.mysql.MySqlConnectorTask:493)
[2020-05-13 11:20:01,298] INFO GTIDs known by the server but not processed yet , for replication are available only  (io.debezium.connector.mysql.MySqlConnectorTask:498)
[2020-05-13 11:20:01,334] INFO Requested thread factory for connector MySqlConnector, id = ghtk_chat named = binlog-client (io.debezium.util.Threads:250)
[2020-05-13 11:20:01,363] INFO Creating thread debezium-mysqlconnector-ghtk_chat-binlog-client (io.debezium.util.Threads:267)
[2020-05-13 11:20:01,372] INFO Creating thread debezium-mysqlconnector-ghtk_chat-binlog-client (io.debezium.util.Threads:267)
[2020-05-13 11:20:01,496] INFO Connected to MySQL binlog at localhost:3306, starting at GTIDs 1507ff86-e9aa-11e9-b5ab-000c29f4a13b:1-3112 and binlog file 'mysql-bin.000008', pos=950, skipping 2 events plus 1 rows (io.debezium.connector.mysql.BinlogReader:1019)
[2020-05-13 11:20:01,496] INFO WorkerSourceTask{id=mysql-connector-demo-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:209)
[2020-05-13 11:20:01,497] INFO Creating thread debezium-mysqlconnector-ghtk_chat-binlog-client (io.debezium.util.Threads:267)
[2020-05-13 11:20:01,539] ERROR Error during binlog processing. Last offset stored = null, binlog reader near position = mysql-bin.000008/950 (io.debezium.connector.mysql.BinlogReader:1069)
[2020-05-13 11:20:01,542] INFO Stopped reading binlog after 0 events, no new offset was recorded (io.debezium.connector.mysql.BinlogReader:1007)
[2020-05-13 11:20:01,813] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:20:01,813] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:20:01,814] ERROR WorkerSourceTask{id=mysql-connector-demo-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:179)
org.apache.kafka.connect.errors.ConnectException: Could not open log file Error code: 1236; SQLSTATE: HY000.
	at io.debezium.connector.mysql.AbstractReader.wrap(AbstractReader.java:230)
	at io.debezium.connector.mysql.AbstractReader.failed(AbstractReader.java:197)
	at io.debezium.connector.mysql.BinlogReader$ReaderThreadLifecycleListener.onCommunicationFailure(BinlogReader.java:1033)
	at com.github.shyiko.mysql.binlog.BinaryLogClient.listenForEventPackets(BinaryLogClient.java:950)
	at com.github.shyiko.mysql.binlog.BinaryLogClient.connect(BinaryLogClient.java:580)
	at com.github.shyiko.mysql.binlog.BinaryLogClient$7.run(BinaryLogClient.java:825)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: com.github.shyiko.mysql.binlog.network.ServerException: Could not open log file
	at com.github.shyiko.mysql.binlog.BinaryLogClient.listenForEventPackets(BinaryLogClient.java:914)
	... 3 more
[2020-05-13 11:20:01,816] ERROR WorkerSourceTask{id=mysql-connector-demo-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:180)
[2020-05-13 11:20:01,816] INFO Stopping MySQL connector task (io.debezium.connector.mysql.MySqlConnectorTask:430)
[2020-05-13 11:20:01,816] INFO ChainedReader: Stopping the binlog reader (io.debezium.connector.mysql.ChainedReader:121)
[2020-05-13 11:20:01,816] INFO Discarding 0 unsent record(s) due to the connector shutting down (io.debezium.connector.mysql.BinlogReader:129)
[2020-05-13 11:20:01,816] INFO Discarding 0 unsent record(s) due to the connector shutting down (io.debezium.connector.mysql.BinlogReader:129)
[2020-05-13 11:20:01,817] INFO [Producer clientId=mysql-connector-demo-dbhistory] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:20:01,824] INFO Connector task finished all work and is now shutdown (io.debezium.connector.mysql.MySqlConnectorTask:465)
[2020-05-13 11:20:01,824] INFO [Producer clientId=connector-producer-mysql-connector-demo-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:20:10,102] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:20:10,107] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:20:20,108] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:20:20,111] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:20:30,112] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:20:30,116] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:20:40,117] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:20:40,139] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:20:50,140] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:20:50,163] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:21:00,164] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:21:00,167] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:21:10,168] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:21:10,192] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:21:20,193] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:21:20,217] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:21:30,218] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:21:30,221] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:21:40,222] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:21:40,226] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:21:50,227] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:21:50,230] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:22:00,231] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:22:00,406] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:22:10,408] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:22:10,411] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:22:20,411] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:22:20,417] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:22:30,417] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:22:30,418] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:22:40,418] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:22:40,421] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:22:50,422] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:22:50,428] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:23:00,429] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:23:00,433] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:23:10,433] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:23:10,435] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:23:20,436] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:23:20,437] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:23:30,438] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:23:30,446] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:23:40,447] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:23:40,449] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:23:50,449] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:23:50,458] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:24:00,458] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:24:00,461] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:24:10,462] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:24:10,465] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:24:20,465] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:24:20,469] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:24:30,469] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:24:30,473] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:24:40,474] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:24:40,477] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:24:50,478] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:24:50,489] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:25:00,490] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:25:00,493] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:25:10,494] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:25:10,496] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:25:20,497] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:25:20,499] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:25:30,500] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:25:30,503] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:25:40,504] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:25:40,507] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:25:50,508] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:25:50,521] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:26:00,522] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:26:00,536] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:26:10,537] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:26:10,540] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:26:20,541] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:26:20,557] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:26:30,557] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:26:30,573] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:26:40,574] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:26:40,584] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:26:50,585] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:26:50,585] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:27:00,586] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:27:00,605] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:27:10,606] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:27:10,609] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:27:20,610] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:27:20,630] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:27:30,631] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:27:30,631] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:27:32,920] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Error sending fetch request (sessionId=2080149351, epoch=906) to node 0: {}. (org.apache.kafka.clients.FetchSessionHandler:445)
org.apache.kafka.common.errors.DisconnectException
[2020-05-13 11:27:32,922] INFO [Worker clientId=connect-1, groupId=connect-cluster] Group coordinator localhost:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:808)
[2020-05-13 11:27:32,923] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Error sending fetch request (sessionId=893091799, epoch=908) to node 0: {}. (org.apache.kafka.clients.FetchSessionHandler:445)
org.apache.kafka.common.errors.DisconnectException
[2020-05-13 11:27:32,921] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Error sending fetch request (sessionId=1416578088, epoch=906) to node 0: {}. (org.apache.kafka.clients.FetchSessionHandler:445)
org.apache.kafka.common.errors.DisconnectException
[2020-05-13 11:27:33,022] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:33,022] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:33,023] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:33,022] WARN [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:33,022] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:33,022] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:33,022] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:33,122] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:33,122] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:33,123] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:33,123] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:33,173] WARN [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:33,173] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:33,173] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:33,323] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:33,323] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:33,324] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:33,324] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:33,374] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:33,424] WARN [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:33,424] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:33,675] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:33,724] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:33,774] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:33,775] WARN [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:33,775] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:33,826] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:33,875] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:34,428] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:34,527] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:34,676] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:34,677] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:34,727] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:34,728] WARN [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:34,779] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:35,581] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:35,629] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:35,629] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:35,679] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:35,879] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:35,923] INFO [Worker clientId=connect-1, groupId=connect-cluster] Broker coordinator was unreachable for 3000ms. Revoking previous assignment Assignment{error=0, leader='connect-1-5894ef49-c2c1-48e5-b242-253271136141', leaderUrl='http://localhost:8083/', offset=14, connectorIds=[mysql-connector-demo], taskIds=[mysql-connector-demo-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} to avoid running tasks while not being a member the group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:137)
[2020-05-13 11:27:35,930] INFO Stopping connector mysql-connector-demo (org.apache.kafka.connect.runtime.Worker:358)
[2020-05-13 11:27:35,930] INFO Stopping task mysql-connector-demo-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-05-13 11:27:35,932] INFO Stopped connector mysql-connector-demo (org.apache.kafka.connect.runtime.Worker:374)
[2020-05-13 11:27:35,932] WARN [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:35,932] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:35,932] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1617)
[2020-05-13 11:27:36,525] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:36,780] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:36,780] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:36,785] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:36,835] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:36,882] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:36,962] WARN [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:37,685] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:37,688] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:37,728] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:37,783] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:37,794] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:37,891] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:37,939] WARN [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:38,642] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:38,696] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:38,847] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:38,892] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:38,931] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:38,935] WARN [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:38,987] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:39,795] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:39,799] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:39,845] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:39,899] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:39,933] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:39,939] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:27:40,690] WARN [Producer clientId=producer-2] Error while fetching metadata with correlation id 9 : {connect-status=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:27:40,764] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Error while fetching metadata with correlation id 920 : {connect-status=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:27:40,810] WARN [Producer clientId=producer-2] Error while fetching metadata with correlation id 10 : {connect-status=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:27:40,854] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Error while fetching metadata with correlation id 919 : {connect-configs=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:27:40,872] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Error while fetching metadata with correlation id 921 : {connect-status=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:27:40,916] WARN [Producer clientId=producer-2] Error while fetching metadata with correlation id 11 : {connect-status=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:27:40,958] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Error while fetching metadata with correlation id 918 : {connect-offsets=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:27:40,960] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Error while fetching metadata with correlation id 920 : {connect-configs=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:27:40,976] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Error while fetching metadata with correlation id 922 : {connect-status=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:27:41,020] WARN [Producer clientId=producer-2] Error while fetching metadata with correlation id 12 : {connect-status=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:27:41,063] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Error while fetching metadata with correlation id 919 : {connect-offsets=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:27:41,068] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Error while fetching metadata with correlation id 921 : {connect-configs=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:27:41,080] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Error while fetching metadata with correlation id 923 : {connect-status=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:27:41,256] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1623)
[2020-05-13 11:27:41,259] INFO [Worker clientId=connect-1, groupId=connect-cluster] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2020-05-13 11:27:41,259] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:222)
[2020-05-13 11:27:41,259] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:27:41,305] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation 21 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:484)
[2020-05-13 11:27:41,305] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 21 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-5894ef49-c2c1-48e5-b242-253271136141', leaderUrl='http://localhost:8083/', offset=15, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=300000} with rebalance delay: 300000 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1542)
[2020-05-13 11:27:41,306] WARN [Worker clientId=connect-1, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1013)
[2020-05-13 11:27:41,306] INFO [Worker clientId=connect-1, groupId=connect-cluster] Current config state offset 14 is behind group assignment 15, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1074)
[2020-05-13 11:27:41,751] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 15 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1078)
[2020-05-13 11:27:41,751] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 15 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1104)
[2020-05-13 11:27:41,751] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1125)
[2020-05-13 11:32:16,272] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:66)
[2020-05-13 11:32:16,273] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-05-13 11:32:16,279] INFO Stopped http_localhost8083@24528a25{HTTP/1.1,[http/1.1]}{localhost:8083} (org.eclipse.jetty.server.AbstractConnector:343)
[2020-05-13 11:32:16,279] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-05-13 11:32:16,279] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-05-13 11:32:16,280] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:609)
[2020-05-13 11:32:16,280] INFO [Worker clientId=connect-1, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:583)
[2020-05-13 11:32:16,280] INFO [Worker clientId=connect-1, groupId=connect-cluster] Member connect-1-5894ef49-c2c1-48e5-b242-253271136141 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:916)
[2020-05-13 11:32:16,280] WARN [Worker clientId=connect-1, groupId=connect-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:897)
[2020-05-13 11:32:16,281] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:165)
[2020-05-13 11:32:16,281] INFO [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:32:16,283] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:191)
[2020-05-13 11:32:16,283] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:272)
[2020-05-13 11:32:16,283] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:165)
[2020-05-13 11:32:16,283] INFO [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:32:16,286] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:191)
[2020-05-13 11:32:16,286] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:274)
[2020-05-13 11:32:16,287] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-05-13 11:32:16,287] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:115)
[2020-05-13 11:32:16,288] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:165)
[2020-05-13 11:32:16,288] INFO [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:32:16,290] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:191)
[2020-05-13 11:32:16,290] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:117)
[2020-05-13 11:32:16,290] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-05-13 11:32:16,291] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:287)
[2020-05-13 11:32:16,292] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:629)
[2020-05-13 11:32:16,292] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:71)
[2020-05-13 11:32:17,209] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -Djava.awt.headless=true, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Private Build, OpenJDK 64-Bit Server VM, 11.0.5, 11.0.5+10-post-Ubuntu-0ubuntu1.119.04
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.4.1.jar:bin/../libs/connect-basic-auth-extension-2.4.1.jar:bin/../libs/connect-file-2.4.1.jar:bin/../libs/connect-json-2.4.1.jar:bin/../libs/connect-mirror-2.4.1.jar:bin/../libs/connect-mirror-client-2.4.1.jar:bin/../libs/connect-runtime-2.4.1.jar:bin/../libs/connect-transforms-2.4.1.jar:bin/../libs/guava-20.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.0.jar:bin/../libs/jackson-core-2.10.0.jar:bin/../libs/jackson-databind-2.10.0.jar:bin/../libs/jackson-dataformat-csv-2.10.0.jar:bin/../libs/jackson-datatype-jdk8-2.10.0.jar:bin/../libs/jackson-jaxrs-base-2.10.0.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:bin/../libs/jackson-module-paranamer-2.10.0.jar:bin/../libs/jackson-module-scala_2.12-2.10.0.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.20.v20190813.jar:bin/../libs/jetty-continuation-9.4.20.v20190813.jar:bin/../libs/jetty-http-9.4.20.v20190813.jar:bin/../libs/jetty-io-9.4.20.v20190813.jar:bin/../libs/jetty-security-9.4.20.v20190813.jar:bin/../libs/jetty-server-9.4.20.v20190813.jar:bin/../libs/jetty-servlet-9.4.20.v20190813.jar:bin/../libs/jetty-servlets-9.4.20.v20190813.jar:bin/../libs/jetty-util-9.4.20.v20190813.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.4.1.jar:bin/../libs/kafka_2.12-2.4.1-sources.jar:bin/../libs/kafka-clients-2.4.1.jar:bin/../libs/kafka-log4j-appender-2.4.1.jar:bin/../libs/kafka-streams-2.4.1.jar:bin/../libs/kafka-streams-examples-2.4.1.jar:bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:bin/../libs/kafka-streams-test-utils-2.4.1.jar:bin/../libs/kafka-tools-2.4.1.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.6.0.jar:bin/../libs/maven-artifact-3.6.1.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.0.jar:bin/../libs/reflections-0.9.11.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.2.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.28.jar:bin/../libs/slf4j-log4j12-1.7.28.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.3-1.jar
	os.spec = Linux, amd64, 5.0.0-38-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-05-13 11:32:17,218] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectDistributed:90)
[2020-05-13 11:32:17,245] INFO Loading plugin from: /home/admina/Desktop/ghtk/kafka/debezium-connector-mysql-0.9.2.Final-plugin/debezium-connector-mysql (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:241)
[2020-05-13 11:32:17,698] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/admina/Desktop/ghtk/kafka/debezium-connector-mysql-0.9.2.Final-plugin/debezium-connector-mysql/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:264)
[2020-05-13 11:32:17,700] INFO Added plugin 'io.debezium.connector.mysql.MySqlConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:17,701] INFO Added plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:17,701] INFO Added plugin 'io.debezium.transforms.UnwrapFromEnvelope' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:17,701] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:17,701] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:17,701] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,877] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@8bcc55f (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:264)
[2020-05-13 11:32:18,877] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,877] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,878] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,878] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,878] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,880] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,880] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,880] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,880] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,880] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,880] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,880] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,880] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,881] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,881] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,881] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,881] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,881] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,881] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,881] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,882] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,882] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,882] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,882] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,882] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,882] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,882] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,882] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,883] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,883] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,883] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,883] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,883] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,883] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,883] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,883] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,883] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,884] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,884] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,884] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,884] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,884] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,884] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:32:18,885] INFO Added aliases 'MySqlConnector' and 'MySql' to plugin 'io.debezium.connector.mysql.MySqlConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,885] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,885] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,886] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,886] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,886] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,886] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,886] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,886] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,887] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,887] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,887] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,887] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,887] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,887] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,888] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,888] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,888] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,888] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,888] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,888] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,889] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,889] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,889] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,889] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,890] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,890] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,890] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:32:18,890] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,891] INFO Added alias 'ByLogicalTableRouter' to plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:32:18,891] INFO Added alias 'UnwrapFromEnvelope' to plugin 'io.debezium.transforms.UnwrapFromEnvelope' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:32:18,891] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:32:18,892] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:32:18,892] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:32:18,892] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:32:18,892] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,892] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:18,893] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:32:19,028] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = None
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = null
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.path = [/home/admina/Desktop/ghtk/kafka/debezium-connector-mysql-0.9.2.Final-plugin]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = localhost
	rest.port = 8083
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:347)
[2020-05-13 11:32:19,031] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-05-13 11:32:19,034] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 11:32:19,203] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,203] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,203] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,204] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,204] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,204] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,204] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,204] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,204] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,204] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,204] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,204] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,204] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,205] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,205] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,205] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:32:19,205] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:32:19,205] INFO Kafka startTimeMs: 1589344339205 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:32:19,479] INFO Kafka cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-05-13 11:32:19,500] INFO Logging initialized @2592ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-05-13 11:32:19,535] INFO Added connector for http://localhost:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-05-13 11:32:19,536] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-05-13 11:32:19,542] INFO jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 11.0.5+10-post-Ubuntu-0ubuntu1.119.04 (org.eclipse.jetty.server.Server:359)
[2020-05-13 11:32:19,566] INFO Started http_localhost8083@d71adc2{HTTP/1.1,[http/1.1]}{localhost:8083} (org.eclipse.jetty.server.AbstractConnector:293)
[2020-05-13 11:32:19,566] INFO Started @2659ms (org.eclipse.jetty.server.Server:399)
[2020-05-13 11:32:19,591] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-05-13 11:32:19,592] INFO REST server listening at http://localhost:8083/, advertising URL http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-05-13 11:32:19,593] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-05-13 11:32:19,593] INFO REST admin endpoints at http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-05-13 11:32:19,594] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-05-13 11:32:19,599] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-05-13 11:32:19,609] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:32:19,610] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:32:19,610] INFO Kafka startTimeMs: 1589344339609 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:32:19,729] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 11:32:19,730] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 11:32:19,768] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:32:19,769] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:32:19,769] INFO Kafka startTimeMs: 1589344339768 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:32:19,773] INFO Kafka Connect distributed worker initialization took 2555ms (org.apache.kafka.connect.cli.ConnectDistributed:128)
[2020-05-13 11:32:19,773] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:50)
[2020-05-13 11:32:19,774] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-05-13 11:32:19,774] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:275)
[2020-05-13 11:32:19,776] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-05-13 11:32:19,777] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:108)
[2020-05-13 11:32:19,777] INFO Starting KafkaBasedLog with topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:126)
[2020-05-13 11:32:19,778] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 11:32:19,784] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,784] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,784] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,784] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,784] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,784] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,785] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,785] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,785] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,785] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,785] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,785] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,785] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,785] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,786] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:19,786] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:32:19,786] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:32:19,786] INFO Kafka startTimeMs: 1589344339786 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:32:19,830] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:32:19,836] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-05-13 11:32:19,861] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:19,863] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:19,864] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:19,864] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:19,865] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:19,865] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:19,865] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:19,865] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:19,866] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:19,866] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:19,866] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:19,867] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:19,868] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:19,868] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:19,868] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:19,868] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:32:19,868] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:32:19,869] INFO Kafka startTimeMs: 1589344339868 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:32:19,878] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:32:19,880] INFO [Producer clientId=producer-1] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:32:19,915] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:19,917] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:19,917] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:19,917] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:19,918] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:19,918] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:19,918] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:19,918] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:19,918] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:19,918] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:19,919] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:19,919] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:19,920] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:19,920] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:19,920] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:32:19,920] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:32:19,920] INFO Kafka startTimeMs: 1589344339920 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:32:19,934] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:32:19,944] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-05-13 11:32:19,944] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-05-13 11:32:19,945] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:140)
[2020-05-13 11:32:19,956] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Subscribed to partition(s): connect-offsets-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1123)
[2020-05-13 11:32:19,962] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:564)
[2020-05-13 11:32:20,007] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 11:32:20,061] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:159)
[2020-05-13 11:32:20,066] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:161)
[2020-05-13 11:32:20,066] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:110)
[2020-05-13 11:32:20,074] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-05-13 11:32:20,075] INFO Starting KafkaBasedLog with topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:126)
[2020-05-13 11:32:20,075] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 11:32:20,077] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,078] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,078] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,078] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,078] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,078] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,078] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,078] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,079] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,079] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,079] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,079] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,079] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,079] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,079] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,079] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:32:20,080] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:32:20,080] INFO Kafka startTimeMs: 1589344340079 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:32:20,099] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:32:20,106] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,106] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,107] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,107] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,107] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,107] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,107] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,108] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,109] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,109] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,110] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,110] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,110] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,111] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,111] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,111] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:32:20,112] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:32:20,112] INFO Kafka startTimeMs: 1589344340111 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:32:20,115] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:32:20,133] INFO [Producer clientId=producer-2] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:32:20,141] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:20,145] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:20,146] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:20,148] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:20,149] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:20,149] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:20,149] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:20,150] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:20,150] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:20,150] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:20,150] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:20,150] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:20,151] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:20,151] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:20,151] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:32:20,151] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:32:20,151] INFO Kafka startTimeMs: 1589344340151 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:32:20,157] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:32:20,166] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Subscribed to partition(s): connect-status-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1123)
[2020-05-13 11:32:20,166] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:564)
[2020-05-13 11:32:20,185] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Resetting offset for partition connect-status-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 11:32:20,241] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:159)
[2020-05-13 11:32:20,242] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:161)
[2020-05-13 11:32:20,243] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:262)
[2020-05-13 11:32:20,243] INFO Starting KafkaBasedLog with topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:126)
[2020-05-13 11:32:20,244] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 11:32:20,246] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,246] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,246] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,246] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,247] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,247] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,247] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,247] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,247] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,247] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,247] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,247] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,247] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,247] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,247] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:32:20,248] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:32:20,248] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:32:20,248] INFO Kafka startTimeMs: 1589344340248 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:32:20,266] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:32:20,275] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,276] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,278] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,283] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,284] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,284] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,285] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,285] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,286] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,286] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,287] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,288] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,289] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,289] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,289] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:32:20,290] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:32:20,290] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:32:20,290] INFO Kafka startTimeMs: 1589344340290 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:32:20,292] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:32:20,294] INFO [Producer clientId=producer-3] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:32:20,304] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:20,306] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:20,306] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:20,306] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:20,307] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:20,307] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:20,307] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:20,307] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:20,307] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:20,307] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:20,307] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:20,307] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:20,307] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:20,307] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:32:20,308] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:32:20,308] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:32:20,308] INFO Kafka startTimeMs: 1589344340308 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:32:20,313] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:32:20,319] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Subscribed to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1123)
[2020-05-13 11:32:20,319] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:564)
[2020-05-13 11:32:20,332] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 11:32:20,345] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:159)
[2020-05-13 11:32:20,346] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:161)
[2020-05-13 11:32:20,346] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:267)
[2020-05-13 11:32:20,346] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:279)
[2020-05-13 11:32:20,361] INFO [Worker clientId=connect-1, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:32:20,365] INFO [Worker clientId=connect-1, groupId=connect-cluster] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2020-05-13 11:32:20,373] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:222)
[2020-05-13 11:32:20,375] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:32:20,391] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:32:20,446] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation 23 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:484)
[2020-05-13 11:32:20,448] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 23 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-fa18788b-fd1d-4bb6-80f7-a97e61b59f65', leaderUrl='http://localhost:8083/', offset=15, connectorIds=[mysql-connector-demo], taskIds=[mysql-connector-demo-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1542)
[2020-05-13 11:32:20,448] WARN [Worker clientId=connect-1, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1013)
[2020-05-13 11:32:20,449] INFO [Worker clientId=connect-1, groupId=connect-cluster] Current config state offset -1 is behind group assignment 15, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1074)
[2020-05-13 11:32:20,728] INFO Started o.e.j.s.ServletContextHandler@971e903{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:824)
[2020-05-13 11:32:20,728] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-05-13 11:32:20,728] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:56)
[2020-05-13 11:32:20,842] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 15 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1078)
[2020-05-13 11:32:20,842] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 15 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1104)
[2020-05-13 11:32:20,843] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector mysql-connector-demo (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1179)
[2020-05-13 11:32:20,843] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task mysql-connector-demo-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1139)
[2020-05-13 11:32:20,848] INFO Creating task mysql-connector-demo-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-05-13 11:32:20,849] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-05-13 11:32:20,849] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-05-13 11:32:20,850] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-05-13 11:32:20,850] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-05-13 11:32:20,850] INFO Creating connector mysql-connector-demo of type io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-05-13 11:32:20,853] INFO TaskConfig values: 
	task.class = class io.debezium.connector.mysql.MySqlConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-05-13 11:32:20,853] INFO Instantiated task mysql-connector-demo-0 with version 0.9.2.Final of type io.debezium.connector.mysql.MySqlConnectorTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-05-13 11:32:20,854] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 11:32:20,854] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task mysql-connector-demo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-05-13 11:32:20,854] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 11:32:20,854] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mysql-connector-demo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-05-13 11:32:20,854] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mysql-connector-demo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-05-13 11:32:20,855] INFO Instantiated connector mysql-connector-demo with version 0.9.2.Final of type class io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-05-13 11:32:20,858] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:514)
[2020-05-13 11:32:20,862] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-mysql-connector-demo-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:32:20,866] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:32:20,866] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:32:20,866] INFO Kafka startTimeMs: 1589344340865 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:32:20,870] INFO [Producer clientId=connector-producer-mysql-connector-demo-0] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:32:20,883] INFO Finished creating connector mysql-connector-demo (org.apache.kafka.connect.runtime.Worker:273)
[2020-05-13 11:32:20,886] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-05-13 11:32:20,910] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-05-13 11:32:20,912] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1125)
[2020-05-13 11:32:20,945] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1440)
[2020-05-13 11:32:20,970] INFO Starting MySqlConnectorTask with configuration: (io.debezium.connector.common.BaseSourceTask:42)
[2020-05-13 11:32:20,974] INFO    connector.class = io.debezium.connector.mysql.MySqlConnector (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 11:32:20,974] INFO    database.user = debezium (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 11:32:20,975] INFO    database.server.id = 1 (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 11:32:20,975] INFO    database.history.kafka.bootstrap.servers = localhost:9092 (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 11:32:20,975] INFO    database.history.kafka.topic = dbhistory.demo (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 11:32:20,975] INFO    database.server.name = ghtk_chat (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 11:32:20,975] INFO    database.port = 3306 (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 11:32:20,975] INFO    include.schema.changes = true (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 11:32:20,975] INFO    table.whitelist = ghtk_chat.channels (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 11:32:20,975] INFO    task.class = io.debezium.connector.mysql.MySqlConnectorTask (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 11:32:20,975] INFO    database.hostname = localhost (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 11:32:20,975] INFO    database.password = ******** (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 11:32:20,975] INFO    name = mysql-connector-demo (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 11:32:21,266] INFO KafkaDatabaseHistory Consumer config: {key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, enable.auto.commit=false, group.id=mysql-connector-demo-dbhistory, bootstrap.servers=localhost:9092, fetch.min.bytes=1, session.timeout.ms=10000, auto.offset.reset=earliest, client.id=mysql-connector-demo-dbhistory} (io.debezium.relational.history.KafkaDatabaseHistory:163)
[2020-05-13 11:32:21,267] INFO KafkaDatabaseHistory Producer config: {retries=1, value.serializer=org.apache.kafka.common.serialization.StringSerializer, acks=1, batch.size=32768, max.block.ms=10000, bootstrap.servers=localhost:9092, buffer.memory=1048576, key.serializer=org.apache.kafka.common.serialization.StringSerializer, client.id=mysql-connector-demo-dbhistory, linger.ms=0} (io.debezium.relational.history.KafkaDatabaseHistory:164)
[2020-05-13 11:32:21,269] INFO ProducerConfig values: 
	acks = 1
	batch.size = 32768
	bootstrap.servers = [localhost:9092]
	buffer.memory = 1048576
	client.dns.lookup = default
	client.id = mysql-connector-demo-dbhistory
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 10000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:32:21,273] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:32:21,273] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:32:21,273] INFO Kafka startTimeMs: 1589344341273 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:32:21,274] INFO Found existing offset: {ts_sec=1589301382, file=mysql-bin.000008, pos=950, gtids=1507ff86-e9aa-11e9-b5ab-000c29f4a13b:1-3112, row=1, server_id=1, event=2} (io.debezium.connector.mysql.MySqlConnectorTask:82)
[2020-05-13 11:32:21,276] INFO [Producer clientId=mysql-connector-demo-dbhistory] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:32:21,278] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = mysql-connector-demo-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = mysql-connector-demo-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:32:21,283] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:32:21,283] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:32:21,283] INFO Kafka startTimeMs: 1589344341283 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:32:21,293] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:32:21,320] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = mysql-connector-demo-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = mysql-connector-demo-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:32:21,324] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:32:21,324] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:32:21,324] INFO Kafka startTimeMs: 1589344341324 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:32:21,325] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Subscribed to topic(s): dbhistory.demo (org.apache.kafka.clients.consumer.KafkaConsumer:969)
[2020-05-13 11:32:21,331] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:32:21,336] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2020-05-13 11:32:21,342] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:32:21,350] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:32:21,355] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Finished assignment for group at generation 1: {mysql-connector-demo-dbhistory-75dcbd35-52e3-4753-8572-481ca22284c6=Assignment(partitions=[dbhistory.demo-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:585)
[2020-05-13 11:32:21,380] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Successfully joined group with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:484)
[2020-05-13 11:32:21,382] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Adding newly assigned partitions: dbhistory.demo-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:267)
[2020-05-13 11:32:21,389] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Found no committed offset for partition dbhistory.demo-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1241)
[2020-05-13 11:32:21,392] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Resetting offset for partition dbhistory.demo-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 11:32:21,920] ERROR Unexpected exception while processing record 'ConsumerRecord(topic = dbhistory.demo, partition = 0, leaderEpoch = 0, offset = 7, CreateTime = 1589301948755, serialized key size = -1, serialized value size = 479, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {
  "source" : {
    "server" : "ghtk_chat"
  },
  "position" : {
    "ts_sec" : 1589301948,
    "file" : "mysql-bin.000008",
    "pos" : 1860,
    "gtids" : "1507ff86-e9aa-11e9-b5ab-000c29f4a13b:1-3112",
    "server_id" : 1
  },
  "databaseName" : "ghtk_chat",
  "ddl" : "CREATE DEFINER=`root`@`localhost` TRIGGER `channels_BEFORE_UPDATE` BEFORE UPDATE ON `channels` FOR EACH ROW\nBEGIN\n    if(New.updatedAt is null) then \n\t\tset New.updatedAt= Now(); \n    end if;\n\nEND"
})' (io.debezium.relational.history.KafkaDatabaseHistory:248)
io.debezium.text.ParsingException: no viable alternative at input 'CREATE DEFINER=`root`@`localhost` TRIGGER `channels_BEFORE_UPDATE` BEFORE UPDATE ON `channels` FOR EACH ROW\nBEGIN\n    if(New.updatedAt is null) then \n\t\tset New.updatedAt'
	at io.debezium.antlr.ParsingErrorListener.syntaxError(ParsingErrorListener.java:40)
	at org.antlr.v4.runtime.ProxyErrorListener.syntaxError(ProxyErrorListener.java:41)
	at org.antlr.v4.runtime.Parser.notifyErrorListeners(Parser.java:544)
	at org.antlr.v4.runtime.DefaultErrorStrategy.reportNoViableAlternative(DefaultErrorStrategy.java:282)
	at org.antlr.v4.runtime.DefaultErrorStrategy.reportError(DefaultErrorStrategy.java:121)
	at io.debezium.ddl.parser.mysql.generated.MySqlParser.sqlStatements(MySqlParser.java:1075)
	at io.debezium.ddl.parser.mysql.generated.MySqlParser.root(MySqlParser.java:809)
	at io.debezium.connector.mysql.antlr.MySqlAntlrDdlParser.parseTree(MySqlAntlrDdlParser.java:71)
	at io.debezium.connector.mysql.antlr.MySqlAntlrDdlParser.parseTree(MySqlAntlrDdlParser.java:44)
	at io.debezium.antlr.AntlrDdlParser.parse(AntlrDdlParser.java:80)
	at io.debezium.relational.history.AbstractDatabaseHistory.lambda$recover$1(AbstractDatabaseHistory.java:104)
	at io.debezium.relational.history.KafkaDatabaseHistory.recoverRecords(KafkaDatabaseHistory.java:238)
	at io.debezium.relational.history.AbstractDatabaseHistory.recover(AbstractDatabaseHistory.java:73)
	at io.debezium.connector.mysql.MySqlSchema.loadHistory(MySqlSchema.java:251)
	at io.debezium.connector.mysql.MySqlTaskContext.loadHistory(MySqlTaskContext.java:165)
	at io.debezium.connector.mysql.MySqlConnectorTask.start(MySqlConnectorTask.java:105)
	at io.debezium.connector.common.BaseSourceTask.start(BaseSourceTask.java:47)
	at org.apache.kafka.connect.runtime.WorkerSourceTask.execute(WorkerSourceTask.java:208)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:177)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:227)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.antlr.v4.runtime.NoViableAltException
	at org.antlr.v4.runtime.atn.ParserATNSimulator.noViableAlt(ParserATNSimulator.java:2023)
	at org.antlr.v4.runtime.atn.ParserATNSimulator.execATN(ParserATNSimulator.java:467)
	at org.antlr.v4.runtime.atn.ParserATNSimulator.adaptivePredict(ParserATNSimulator.java:393)
	at io.debezium.ddl.parser.mysql.generated.MySqlParser.sqlStatements(MySqlParser.java:883)
	... 19 more
[2020-05-13 11:32:21,923] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Revoke previously assigned partitions dbhistory.demo-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:286)
[2020-05-13 11:32:21,923] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Member mysql-connector-demo-dbhistory-75dcbd35-52e3-4753-8572-481ca22284c6 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:916)
[2020-05-13 11:32:21,930] INFO Stopping MySQL connector task (io.debezium.connector.mysql.MySqlConnectorTask:428)
[2020-05-13 11:32:21,930] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:32:21,930] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:32:21,930] ERROR WorkerSourceTask{id=mysql-connector-demo-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:179)
org.apache.kafka.connect.errors.ConnectException: io.debezium.text.ParsingException: no viable alternative at input 'CREATE DEFINER=`root`@`localhost` TRIGGER `channels_BEFORE_UPDATE` BEFORE UPDATE ON `channels` FOR EACH ROW\nBEGIN\n    if(New.updatedAt is null) then \n\t\tset New.updatedAt'
	at io.debezium.connector.mysql.MySqlConnectorTask.start(MySqlConnectorTask.java:273)
	at io.debezium.connector.common.BaseSourceTask.start(BaseSourceTask.java:47)
	at org.apache.kafka.connect.runtime.WorkerSourceTask.execute(WorkerSourceTask.java:208)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:177)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:227)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: io.debezium.text.ParsingException: no viable alternative at input 'CREATE DEFINER=`root`@`localhost` TRIGGER `channels_BEFORE_UPDATE` BEFORE UPDATE ON `channels` FOR EACH ROW\nBEGIN\n    if(New.updatedAt is null) then \n\t\tset New.updatedAt'
	at io.debezium.antlr.ParsingErrorListener.syntaxError(ParsingErrorListener.java:40)
	at org.antlr.v4.runtime.ProxyErrorListener.syntaxError(ProxyErrorListener.java:41)
	at org.antlr.v4.runtime.Parser.notifyErrorListeners(Parser.java:544)
	at org.antlr.v4.runtime.DefaultErrorStrategy.reportNoViableAlternative(DefaultErrorStrategy.java:282)
	at org.antlr.v4.runtime.DefaultErrorStrategy.reportError(DefaultErrorStrategy.java:121)
	at io.debezium.ddl.parser.mysql.generated.MySqlParser.sqlStatements(MySqlParser.java:1075)
	at io.debezium.ddl.parser.mysql.generated.MySqlParser.root(MySqlParser.java:809)
	at io.debezium.connector.mysql.antlr.MySqlAntlrDdlParser.parseTree(MySqlAntlrDdlParser.java:71)
	at io.debezium.connector.mysql.antlr.MySqlAntlrDdlParser.parseTree(MySqlAntlrDdlParser.java:44)
	at io.debezium.antlr.AntlrDdlParser.parse(AntlrDdlParser.java:80)
	at io.debezium.relational.history.AbstractDatabaseHistory.lambda$recover$1(AbstractDatabaseHistory.java:104)
	at io.debezium.relational.history.KafkaDatabaseHistory.recoverRecords(KafkaDatabaseHistory.java:238)
	at io.debezium.relational.history.AbstractDatabaseHistory.recover(AbstractDatabaseHistory.java:73)
	at io.debezium.connector.mysql.MySqlSchema.loadHistory(MySqlSchema.java:251)
	at io.debezium.connector.mysql.MySqlTaskContext.loadHistory(MySqlTaskContext.java:165)
	at io.debezium.connector.mysql.MySqlConnectorTask.start(MySqlConnectorTask.java:105)
	... 9 more
Caused by: org.antlr.v4.runtime.NoViableAltException
	at org.antlr.v4.runtime.atn.ParserATNSimulator.noViableAlt(ParserATNSimulator.java:2023)
	at org.antlr.v4.runtime.atn.ParserATNSimulator.execATN(ParserATNSimulator.java:467)
	at org.antlr.v4.runtime.atn.ParserATNSimulator.adaptivePredict(ParserATNSimulator.java:393)
	at io.debezium.ddl.parser.mysql.generated.MySqlParser.sqlStatements(MySqlParser.java:883)
	... 19 more
[2020-05-13 11:32:21,931] ERROR WorkerSourceTask{id=mysql-connector-demo-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:180)
[2020-05-13 11:32:21,932] INFO Stopping MySQL connector task (io.debezium.connector.mysql.MySqlConnectorTask:428)
[2020-05-13 11:32:21,932] INFO [Producer clientId=connector-producer-mysql-connector-demo-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:32:30,880] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:32:30,886] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:32:40,886] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:32:40,904] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:32:50,905] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:32:50,912] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:33:00,913] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:33:00,916] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:33:10,916] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:33:10,941] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:33:20,941] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:33:20,942] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:33:30,942] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:33:30,945] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:33:40,946] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:33:40,973] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:33:50,974] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:33:50,977] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:34:00,978] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:34:00,978] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:34:10,979] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:34:10,981] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:34:20,981] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:34:20,986] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:34:30,990] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:34:30,993] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:34:32,054] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:66)
[2020-05-13 11:34:32,055] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-05-13 11:34:32,061] INFO Stopped http_localhost8083@d71adc2{HTTP/1.1,[http/1.1]}{localhost:8083} (org.eclipse.jetty.server.AbstractConnector:343)
[2020-05-13 11:34:32,062] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-05-13 11:34:32,063] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-05-13 11:34:32,063] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:609)
[2020-05-13 11:34:32,063] INFO [Worker clientId=connect-1, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:583)
[2020-05-13 11:34:32,064] INFO Stopping connector mysql-connector-demo (org.apache.kafka.connect.runtime.Worker:358)
[2020-05-13 11:34:32,064] INFO Stopping task mysql-connector-demo-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-05-13 11:34:32,066] INFO Stopped connector mysql-connector-demo (org.apache.kafka.connect.runtime.Worker:374)
[2020-05-13 11:34:32,067] INFO [Worker clientId=connect-1, groupId=connect-cluster] Member connect-1-fa18788b-fd1d-4bb6-80f7-a97e61b59f65 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:916)
[2020-05-13 11:34:32,067] WARN [Worker clientId=connect-1, groupId=connect-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:897)
[2020-05-13 11:34:32,069] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:165)
[2020-05-13 11:34:32,074] INFO [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:34:32,078] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:191)
[2020-05-13 11:34:32,078] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:272)
[2020-05-13 11:34:32,078] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:165)
[2020-05-13 11:34:32,078] INFO [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:34:32,082] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:191)
[2020-05-13 11:34:32,083] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:274)
[2020-05-13 11:34:32,083] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-05-13 11:34:32,083] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:115)
[2020-05-13 11:34:32,083] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:165)
[2020-05-13 11:34:32,083] INFO [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:34:32,086] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:191)
[2020-05-13 11:34:32,086] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:117)
[2020-05-13 11:34:32,086] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-05-13 11:34:32,087] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:287)
[2020-05-13 11:34:32,089] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:629)
[2020-05-13 11:34:32,090] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:71)
[2020-05-13 11:34:33,224] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -Djava.awt.headless=true, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Private Build, OpenJDK 64-Bit Server VM, 11.0.5, 11.0.5+10-post-Ubuntu-0ubuntu1.119.04
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.4.1.jar:bin/../libs/connect-basic-auth-extension-2.4.1.jar:bin/../libs/connect-file-2.4.1.jar:bin/../libs/connect-json-2.4.1.jar:bin/../libs/connect-mirror-2.4.1.jar:bin/../libs/connect-mirror-client-2.4.1.jar:bin/../libs/connect-runtime-2.4.1.jar:bin/../libs/connect-transforms-2.4.1.jar:bin/../libs/guava-20.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.0.jar:bin/../libs/jackson-core-2.10.0.jar:bin/../libs/jackson-databind-2.10.0.jar:bin/../libs/jackson-dataformat-csv-2.10.0.jar:bin/../libs/jackson-datatype-jdk8-2.10.0.jar:bin/../libs/jackson-jaxrs-base-2.10.0.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:bin/../libs/jackson-module-paranamer-2.10.0.jar:bin/../libs/jackson-module-scala_2.12-2.10.0.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.20.v20190813.jar:bin/../libs/jetty-continuation-9.4.20.v20190813.jar:bin/../libs/jetty-http-9.4.20.v20190813.jar:bin/../libs/jetty-io-9.4.20.v20190813.jar:bin/../libs/jetty-security-9.4.20.v20190813.jar:bin/../libs/jetty-server-9.4.20.v20190813.jar:bin/../libs/jetty-servlet-9.4.20.v20190813.jar:bin/../libs/jetty-servlets-9.4.20.v20190813.jar:bin/../libs/jetty-util-9.4.20.v20190813.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.4.1.jar:bin/../libs/kafka_2.12-2.4.1-sources.jar:bin/../libs/kafka-clients-2.4.1.jar:bin/../libs/kafka-log4j-appender-2.4.1.jar:bin/../libs/kafka-streams-2.4.1.jar:bin/../libs/kafka-streams-examples-2.4.1.jar:bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:bin/../libs/kafka-streams-test-utils-2.4.1.jar:bin/../libs/kafka-tools-2.4.1.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.6.0.jar:bin/../libs/maven-artifact-3.6.1.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.0.jar:bin/../libs/reflections-0.9.11.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.2.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.28.jar:bin/../libs/slf4j-log4j12-1.7.28.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.3-1.jar
	os.spec = Linux, amd64, 5.0.0-38-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-05-13 11:34:33,230] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectDistributed:90)
[2020-05-13 11:34:33,250] INFO Loading plugin from: /home/admina/Desktop/ghtk/kafka/debezium-connector-mysql-0.9.2.Final-plugin/debezium-connector-mysql (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:241)
[2020-05-13 11:34:33,925] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/admina/Desktop/ghtk/kafka/debezium-connector-mysql-0.9.2.Final-plugin/debezium-connector-mysql/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:264)
[2020-05-13 11:34:33,928] INFO Added plugin 'io.debezium.connector.mysql.MySqlConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:33,928] INFO Added plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:33,928] INFO Added plugin 'io.debezium.transforms.UnwrapFromEnvelope' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:33,929] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:33,929] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:33,929] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,235] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@8bcc55f (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:264)
[2020-05-13 11:34:35,236] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,236] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,236] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,236] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,236] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,238] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,238] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,239] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,239] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,239] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,239] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,239] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,239] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,239] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,240] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,240] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,240] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,240] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,240] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,240] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,240] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,240] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,241] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,241] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,241] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,241] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,241] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,241] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,241] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,242] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,242] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,242] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,242] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,242] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,242] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,242] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,243] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,243] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,243] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,243] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,243] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,243] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,243] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:34:35,244] INFO Added aliases 'MySqlConnector' and 'MySql' to plugin 'io.debezium.connector.mysql.MySqlConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,244] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,245] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,245] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,245] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,245] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,245] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,246] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,246] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,246] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,246] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,247] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,247] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,247] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,247] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,247] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,248] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,248] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,248] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,248] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,248] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,249] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,249] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,249] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,249] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,249] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,250] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,250] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:34:35,250] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,250] INFO Added alias 'ByLogicalTableRouter' to plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:34:35,251] INFO Added alias 'UnwrapFromEnvelope' to plugin 'io.debezium.transforms.UnwrapFromEnvelope' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:34:35,251] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:34:35,251] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:34:35,251] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:34:35,252] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:34:35,252] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,252] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,253] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:34:35,329] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = None
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = null
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.path = [/home/admina/Desktop/ghtk/kafka/debezium-connector-mysql-0.9.2.Final-plugin]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = localhost
	rest.port = 8083
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:347)
[2020-05-13 11:34:35,332] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-05-13 11:34:35,335] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 11:34:35,489] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:35,489] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:35,489] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:35,489] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:35,490] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:35,490] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:35,490] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:35,490] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:35,490] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:35,490] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:35,490] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:35,490] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:35,490] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:35,490] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:35,490] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:35,491] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:34:35,491] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:34:35,491] INFO Kafka startTimeMs: 1589344475491 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:34:35,761] INFO Kafka cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-05-13 11:34:35,807] INFO Logging initialized @2916ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-05-13 11:34:35,852] INFO Added connector for http://localhost:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-05-13 11:34:35,853] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-05-13 11:34:35,859] INFO jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 11.0.5+10-post-Ubuntu-0ubuntu1.119.04 (org.eclipse.jetty.server.Server:359)
[2020-05-13 11:34:35,897] INFO Started http_localhost8083@6b5f8707{HTTP/1.1,[http/1.1]}{localhost:8083} (org.eclipse.jetty.server.AbstractConnector:293)
[2020-05-13 11:34:35,898] INFO Started @3007ms (org.eclipse.jetty.server.Server:399)
[2020-05-13 11:34:35,933] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-05-13 11:34:35,933] INFO REST server listening at http://localhost:8083/, advertising URL http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-05-13 11:34:35,934] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-05-13 11:34:35,934] INFO REST admin endpoints at http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-05-13 11:34:35,934] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-05-13 11:34:35,939] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-05-13 11:34:35,952] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:34:35,952] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:34:35,952] INFO Kafka startTimeMs: 1589344475951 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:34:36,106] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 11:34:36,113] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 11:34:36,164] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:34:36,164] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:34:36,165] INFO Kafka startTimeMs: 1589344476164 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:34:36,168] INFO Kafka Connect distributed worker initialization took 2938ms (org.apache.kafka.connect.cli.ConnectDistributed:128)
[2020-05-13 11:34:36,168] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:50)
[2020-05-13 11:34:36,169] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-05-13 11:34:36,169] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:275)
[2020-05-13 11:34:36,171] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-05-13 11:34:36,171] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:108)
[2020-05-13 11:34:36,171] INFO Starting KafkaBasedLog with topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:126)
[2020-05-13 11:34:36,172] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 11:34:36,177] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,178] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,178] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,178] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,178] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,178] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,178] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,178] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,179] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,179] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,179] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,179] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,179] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,179] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,179] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,179] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:34:36,180] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:34:36,180] INFO Kafka startTimeMs: 1589344476179 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:34:36,217] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:34:36,226] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-05-13 11:34:36,245] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,254] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,255] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,255] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,255] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,256] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,256] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,257] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,257] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,258] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,258] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,259] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,259] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,259] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,259] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,259] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:34:36,260] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:34:36,260] INFO Kafka startTimeMs: 1589344476259 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:34:36,270] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:34:36,276] INFO [Producer clientId=producer-1] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:34:36,312] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,314] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,314] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,315] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,315] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,315] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,315] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,315] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,315] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,315] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,315] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,315] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,316] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,316] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,316] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:34:36,316] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:34:36,316] INFO Kafka startTimeMs: 1589344476316 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:34:36,328] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:34:36,337] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-05-13 11:34:36,337] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-05-13 11:34:36,338] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:140)
[2020-05-13 11:34:36,347] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Subscribed to partition(s): connect-offsets-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1123)
[2020-05-13 11:34:36,351] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:564)
[2020-05-13 11:34:36,392] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 11:34:36,441] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:159)
[2020-05-13 11:34:36,442] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:161)
[2020-05-13 11:34:36,442] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:110)
[2020-05-13 11:34:36,447] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-05-13 11:34:36,447] INFO Starting KafkaBasedLog with topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:126)
[2020-05-13 11:34:36,448] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 11:34:36,452] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,453] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,453] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,453] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,453] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,453] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,453] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,453] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,453] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,454] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,454] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,454] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,454] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,454] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,454] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,454] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:34:36,454] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:34:36,455] INFO Kafka startTimeMs: 1589344476454 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:34:36,480] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:34:36,487] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,487] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,487] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,487] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,487] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,488] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,488] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,488] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,488] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,488] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,488] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,488] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,488] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,489] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,489] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,489] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:34:36,489] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:34:36,489] INFO Kafka startTimeMs: 1589344476489 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:34:36,490] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:34:36,498] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,506] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,512] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,513] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,513] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,514] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,514] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,522] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,523] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,524] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,524] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,525] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,526] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,526] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,526] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:34:36,527] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:34:36,527] INFO Kafka startTimeMs: 1589344476526 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:34:36,533] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:34:36,534] INFO [Producer clientId=producer-2] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:34:36,540] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Subscribed to partition(s): connect-status-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1123)
[2020-05-13 11:34:36,540] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:564)
[2020-05-13 11:34:36,553] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Resetting offset for partition connect-status-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 11:34:36,613] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:159)
[2020-05-13 11:34:36,614] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:161)
[2020-05-13 11:34:36,617] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:262)
[2020-05-13 11:34:36,618] INFO Starting KafkaBasedLog with topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:126)
[2020-05-13 11:34:36,618] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 11:34:36,623] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,623] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,624] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,624] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,624] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,624] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,624] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,624] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,625] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,625] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,625] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,625] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,629] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,630] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,630] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:34:36,630] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:34:36,630] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:34:36,630] INFO Kafka startTimeMs: 1589344476630 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:34:36,645] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:34:36,649] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,650] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,650] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,650] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,650] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,650] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,650] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,650] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,650] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,650] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,651] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,651] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,651] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,651] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,651] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:34:36,651] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:34:36,651] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:34:36,651] INFO Kafka startTimeMs: 1589344476651 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:34:36,652] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:34:36,661] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,661] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,661] INFO [Producer clientId=producer-3] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:34:36,661] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,665] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,665] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,665] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,666] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,666] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,666] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,666] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,666] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,666] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,666] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,666] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:34:36,666] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:34:36,666] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:34:36,667] INFO Kafka startTimeMs: 1589344476666 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:34:36,677] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:34:36,689] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Subscribed to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1123)
[2020-05-13 11:34:36,689] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:564)
[2020-05-13 11:34:36,698] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 11:34:36,821] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:159)
[2020-05-13 11:34:36,822] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:161)
[2020-05-13 11:34:36,823] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:267)
[2020-05-13 11:34:36,823] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:279)
[2020-05-13 11:34:36,837] INFO [Worker clientId=connect-1, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:34:36,838] INFO [Worker clientId=connect-1, groupId=connect-cluster] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2020-05-13 11:34:36,841] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:222)
[2020-05-13 11:34:36,842] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:34:36,861] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:34:36,909] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation 25 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:484)
[2020-05-13 11:34:36,911] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 25 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-765a3305-214e-4605-beb7-3bbb765dd0d8', leaderUrl='http://localhost:8083/', offset=16, connectorIds=[mysql-connector-demo], taskIds=[mysql-connector-demo-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1542)
[2020-05-13 11:34:36,912] WARN [Worker clientId=connect-1, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1013)
[2020-05-13 11:34:36,912] INFO [Worker clientId=connect-1, groupId=connect-cluster] Current config state offset -1 is behind group assignment 16, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1074)
[2020-05-13 11:34:37,252] INFO Started o.e.j.s.ServletContextHandler@4a68135e{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:824)
[2020-05-13 11:34:37,252] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-05-13 11:34:37,252] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:56)
[2020-05-13 11:34:37,313] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 16 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1078)
[2020-05-13 11:34:37,313] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 16 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1104)
[2020-05-13 11:34:37,315] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector mysql-connector-demo (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1179)
[2020-05-13 11:34:37,318] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task mysql-connector-demo-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1139)
[2020-05-13 11:34:37,324] INFO Creating task mysql-connector-demo-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-05-13 11:34:37,325] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-05-13 11:34:37,326] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-05-13 11:34:37,326] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-05-13 11:34:37,326] INFO Creating connector mysql-connector-demo of type io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-05-13 11:34:37,327] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-05-13 11:34:37,333] INFO Instantiated connector mysql-connector-demo with version 0.9.2.Final of type class io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-05-13 11:34:37,335] INFO TaskConfig values: 
	task.class = class io.debezium.connector.mysql.MySqlConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-05-13 11:34:37,336] INFO Instantiated task mysql-connector-demo-0 with version 0.9.2.Final of type io.debezium.connector.mysql.MySqlConnectorTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-05-13 11:34:37,337] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 11:34:37,337] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task mysql-connector-demo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-05-13 11:34:37,338] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 11:34:37,338] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mysql-connector-demo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-05-13 11:34:37,339] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mysql-connector-demo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-05-13 11:34:37,346] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:514)
[2020-05-13 11:34:37,352] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-mysql-connector-demo-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:34:37,358] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:34:37,358] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:34:37,358] INFO Kafka startTimeMs: 1589344477357 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:34:37,361] INFO Finished creating connector mysql-connector-demo (org.apache.kafka.connect.runtime.Worker:273)
[2020-05-13 11:34:37,363] INFO [Producer clientId=connector-producer-mysql-connector-demo-0] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:34:37,366] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-05-13 11:34:37,367] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-05-13 11:34:37,371] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1125)
[2020-05-13 11:34:37,402] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1440)
[2020-05-13 11:34:37,441] INFO Starting MySqlConnectorTask with configuration: (io.debezium.connector.common.BaseSourceTask:42)
[2020-05-13 11:34:37,443] INFO    connector.class = io.debezium.connector.mysql.MySqlConnector (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 11:34:37,443] INFO    database.user = debezium (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 11:34:37,443] INFO    database.server.id = 1 (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 11:34:37,443] INFO    database.history.kafka.bootstrap.servers = localhost:9092 (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 11:34:37,444] INFO    database.history.kafka.topic = dbhistory.demo (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 11:34:37,444] INFO    database.server.name = ghtk_chat (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 11:34:37,444] INFO    database.port = 3306 (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 11:34:37,444] INFO    include.schema.changes = true (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 11:34:37,444] INFO    table.whitelist = ghtk_chat.channels (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 11:34:37,444] INFO    task.class = io.debezium.connector.mysql.MySqlConnectorTask (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 11:34:37,444] INFO    database.hostname = localhost (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 11:34:37,444] INFO    database.password = ******** (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 11:34:37,444] INFO    name = mysql-connector-demo (io.debezium.connector.common.BaseSourceTask:44)
[2020-05-13 11:34:38,176] INFO KafkaDatabaseHistory Consumer config: {key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, enable.auto.commit=false, group.id=mysql-connector-demo-dbhistory, bootstrap.servers=localhost:9092, fetch.min.bytes=1, session.timeout.ms=10000, auto.offset.reset=earliest, client.id=mysql-connector-demo-dbhistory} (io.debezium.relational.history.KafkaDatabaseHistory:163)
[2020-05-13 11:34:38,176] INFO KafkaDatabaseHistory Producer config: {retries=1, value.serializer=org.apache.kafka.common.serialization.StringSerializer, acks=1, batch.size=32768, max.block.ms=10000, bootstrap.servers=localhost:9092, buffer.memory=1048576, key.serializer=org.apache.kafka.common.serialization.StringSerializer, client.id=mysql-connector-demo-dbhistory, linger.ms=0} (io.debezium.relational.history.KafkaDatabaseHistory:164)
[2020-05-13 11:34:38,178] INFO ProducerConfig values: 
	acks = 1
	batch.size = 32768
	bootstrap.servers = [localhost:9092]
	buffer.memory = 1048576
	client.dns.lookup = default
	client.id = mysql-connector-demo-dbhistory
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 10000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:34:38,182] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:34:38,182] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:34:38,182] INFO Kafka startTimeMs: 1589344478182 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:34:38,183] INFO Found existing offset: {ts_sec=1589301382, file=mysql-bin.000008, pos=950, gtids=1507ff86-e9aa-11e9-b5ab-000c29f4a13b:1-3112, row=1, server_id=1, event=2} (io.debezium.connector.mysql.MySqlConnectorTask:82)
[2020-05-13 11:34:38,187] INFO [Producer clientId=mysql-connector-demo-dbhistory] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:34:38,190] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = mysql-connector-demo-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = mysql-connector-demo-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:34:38,198] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:34:38,198] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:34:38,199] INFO Kafka startTimeMs: 1589344478198 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:34:38,203] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:34:38,237] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = mysql-connector-demo-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = mysql-connector-demo-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:34:38,241] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:34:38,241] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:34:38,241] INFO Kafka startTimeMs: 1589344478241 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:34:38,242] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Subscribed to topic(s): dbhistory.demo (org.apache.kafka.clients.consumer.KafkaConsumer:969)
[2020-05-13 11:34:38,247] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:34:38,252] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2020-05-13 11:34:38,255] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:34:38,260] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:34:38,265] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Finished assignment for group at generation 3: {mysql-connector-demo-dbhistory-427fd744-eeda-450c-b97a-bccc463f0058=Assignment(partitions=[dbhistory.demo-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:585)
[2020-05-13 11:34:38,268] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Successfully joined group with generation 3 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:484)
[2020-05-13 11:34:38,269] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Adding newly assigned partitions: dbhistory.demo-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:267)
[2020-05-13 11:34:38,274] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Found no committed offset for partition dbhistory.demo-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1241)
[2020-05-13 11:34:38,277] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Resetting offset for partition dbhistory.demo-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 11:34:38,933] ERROR Unexpected exception while processing record 'ConsumerRecord(topic = dbhistory.demo, partition = 0, leaderEpoch = 0, offset = 7, CreateTime = 1589301948755, serialized key size = -1, serialized value size = 479, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {
  "source" : {
    "server" : "ghtk_chat"
  },
  "position" : {
    "ts_sec" : 1589301948,
    "file" : "mysql-bin.000008",
    "pos" : 1860,
    "gtids" : "1507ff86-e9aa-11e9-b5ab-000c29f4a13b:1-3112",
    "server_id" : 1
  },
  "databaseName" : "ghtk_chat",
  "ddl" : "CREATE DEFINER=`root`@`localhost` TRIGGER `channels_BEFORE_UPDATE` BEFORE UPDATE ON `channels` FOR EACH ROW\nBEGIN\n    if(New.updatedAt is null) then \n\t\tset New.updatedAt= Now(); \n    end if;\n\nEND"
})' (io.debezium.relational.history.KafkaDatabaseHistory:248)
io.debezium.text.ParsingException: no viable alternative at input 'CREATE DEFINER=`root`@`localhost` TRIGGER `channels_BEFORE_UPDATE` BEFORE UPDATE ON `channels` FOR EACH ROW\nBEGIN\n    if(New.updatedAt is null) then \n\t\tset New.updatedAt'
	at io.debezium.antlr.ParsingErrorListener.syntaxError(ParsingErrorListener.java:40)
	at org.antlr.v4.runtime.ProxyErrorListener.syntaxError(ProxyErrorListener.java:41)
	at org.antlr.v4.runtime.Parser.notifyErrorListeners(Parser.java:544)
	at org.antlr.v4.runtime.DefaultErrorStrategy.reportNoViableAlternative(DefaultErrorStrategy.java:282)
	at org.antlr.v4.runtime.DefaultErrorStrategy.reportError(DefaultErrorStrategy.java:121)
	at io.debezium.ddl.parser.mysql.generated.MySqlParser.sqlStatements(MySqlParser.java:1075)
	at io.debezium.ddl.parser.mysql.generated.MySqlParser.root(MySqlParser.java:809)
	at io.debezium.connector.mysql.antlr.MySqlAntlrDdlParser.parseTree(MySqlAntlrDdlParser.java:71)
	at io.debezium.connector.mysql.antlr.MySqlAntlrDdlParser.parseTree(MySqlAntlrDdlParser.java:44)
	at io.debezium.antlr.AntlrDdlParser.parse(AntlrDdlParser.java:80)
	at io.debezium.relational.history.AbstractDatabaseHistory.lambda$recover$1(AbstractDatabaseHistory.java:104)
	at io.debezium.relational.history.KafkaDatabaseHistory.recoverRecords(KafkaDatabaseHistory.java:238)
	at io.debezium.relational.history.AbstractDatabaseHistory.recover(AbstractDatabaseHistory.java:73)
	at io.debezium.connector.mysql.MySqlSchema.loadHistory(MySqlSchema.java:251)
	at io.debezium.connector.mysql.MySqlTaskContext.loadHistory(MySqlTaskContext.java:165)
	at io.debezium.connector.mysql.MySqlConnectorTask.start(MySqlConnectorTask.java:105)
	at io.debezium.connector.common.BaseSourceTask.start(BaseSourceTask.java:47)
	at org.apache.kafka.connect.runtime.WorkerSourceTask.execute(WorkerSourceTask.java:208)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:177)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:227)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.antlr.v4.runtime.NoViableAltException
	at org.antlr.v4.runtime.atn.ParserATNSimulator.noViableAlt(ParserATNSimulator.java:2023)
	at org.antlr.v4.runtime.atn.ParserATNSimulator.execATN(ParserATNSimulator.java:467)
	at org.antlr.v4.runtime.atn.ParserATNSimulator.adaptivePredict(ParserATNSimulator.java:393)
	at io.debezium.ddl.parser.mysql.generated.MySqlParser.sqlStatements(MySqlParser.java:883)
	... 19 more
[2020-05-13 11:34:38,937] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Revoke previously assigned partitions dbhistory.demo-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:286)
[2020-05-13 11:34:38,937] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Member mysql-connector-demo-dbhistory-427fd744-eeda-450c-b97a-bccc463f0058 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:916)
[2020-05-13 11:34:38,944] INFO Stopping MySQL connector task (io.debezium.connector.mysql.MySqlConnectorTask:428)
[2020-05-13 11:34:38,944] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:34:38,945] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:34:38,945] ERROR WorkerSourceTask{id=mysql-connector-demo-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:179)
org.apache.kafka.connect.errors.ConnectException: io.debezium.text.ParsingException: no viable alternative at input 'CREATE DEFINER=`root`@`localhost` TRIGGER `channels_BEFORE_UPDATE` BEFORE UPDATE ON `channels` FOR EACH ROW\nBEGIN\n    if(New.updatedAt is null) then \n\t\tset New.updatedAt'
	at io.debezium.connector.mysql.MySqlConnectorTask.start(MySqlConnectorTask.java:273)
	at io.debezium.connector.common.BaseSourceTask.start(BaseSourceTask.java:47)
	at org.apache.kafka.connect.runtime.WorkerSourceTask.execute(WorkerSourceTask.java:208)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:177)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:227)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: io.debezium.text.ParsingException: no viable alternative at input 'CREATE DEFINER=`root`@`localhost` TRIGGER `channels_BEFORE_UPDATE` BEFORE UPDATE ON `channels` FOR EACH ROW\nBEGIN\n    if(New.updatedAt is null) then \n\t\tset New.updatedAt'
	at io.debezium.antlr.ParsingErrorListener.syntaxError(ParsingErrorListener.java:40)
	at org.antlr.v4.runtime.ProxyErrorListener.syntaxError(ProxyErrorListener.java:41)
	at org.antlr.v4.runtime.Parser.notifyErrorListeners(Parser.java:544)
	at org.antlr.v4.runtime.DefaultErrorStrategy.reportNoViableAlternative(DefaultErrorStrategy.java:282)
	at org.antlr.v4.runtime.DefaultErrorStrategy.reportError(DefaultErrorStrategy.java:121)
	at io.debezium.ddl.parser.mysql.generated.MySqlParser.sqlStatements(MySqlParser.java:1075)
	at io.debezium.ddl.parser.mysql.generated.MySqlParser.root(MySqlParser.java:809)
	at io.debezium.connector.mysql.antlr.MySqlAntlrDdlParser.parseTree(MySqlAntlrDdlParser.java:71)
	at io.debezium.connector.mysql.antlr.MySqlAntlrDdlParser.parseTree(MySqlAntlrDdlParser.java:44)
	at io.debezium.antlr.AntlrDdlParser.parse(AntlrDdlParser.java:80)
	at io.debezium.relational.history.AbstractDatabaseHistory.lambda$recover$1(AbstractDatabaseHistory.java:104)
	at io.debezium.relational.history.KafkaDatabaseHistory.recoverRecords(KafkaDatabaseHistory.java:238)
	at io.debezium.relational.history.AbstractDatabaseHistory.recover(AbstractDatabaseHistory.java:73)
	at io.debezium.connector.mysql.MySqlSchema.loadHistory(MySqlSchema.java:251)
	at io.debezium.connector.mysql.MySqlTaskContext.loadHistory(MySqlTaskContext.java:165)
	at io.debezium.connector.mysql.MySqlConnectorTask.start(MySqlConnectorTask.java:105)
	... 9 more
Caused by: org.antlr.v4.runtime.NoViableAltException
	at org.antlr.v4.runtime.atn.ParserATNSimulator.noViableAlt(ParserATNSimulator.java:2023)
	at org.antlr.v4.runtime.atn.ParserATNSimulator.execATN(ParserATNSimulator.java:467)
	at org.antlr.v4.runtime.atn.ParserATNSimulator.adaptivePredict(ParserATNSimulator.java:393)
	at io.debezium.ddl.parser.mysql.generated.MySqlParser.sqlStatements(MySqlParser.java:883)
	... 19 more
[2020-05-13 11:34:38,946] ERROR WorkerSourceTask{id=mysql-connector-demo-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:180)
[2020-05-13 11:34:38,946] INFO Stopping MySQL connector task (io.debezium.connector.mysql.MySqlConnectorTask:428)
[2020-05-13 11:34:38,946] INFO [Producer clientId=connector-producer-mysql-connector-demo-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:34:47,370] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:34:47,374] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:34:57,375] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:34:57,378] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:35:07,379] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:35:07,384] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:35:17,384] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:35:17,390] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:35:27,390] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:35:27,396] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:35:37,396] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:35:37,406] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:35:42,425] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:42,426] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Error sending fetch request (sessionId=1214282555, epoch=133) to node 0: {}. (org.apache.kafka.clients.FetchSessionHandler:445)
org.apache.kafka.common.errors.DisconnectException
[2020-05-13 11:35:42,431] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Error sending fetch request (sessionId=1034883083, epoch=132) to node 0: {}. (org.apache.kafka.clients.FetchSessionHandler:445)
org.apache.kafka.common.errors.DisconnectException
[2020-05-13 11:35:42,432] WARN [Producer clientId=mysql-connector-demo-dbhistory] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:42,433] INFO [Worker clientId=connect-1, groupId=connect-cluster] Group coordinator localhost:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:808)
[2020-05-13 11:35:42,434] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:42,435] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Error sending fetch request (sessionId=1130391627, epoch=132) to node 0: {}. (org.apache.kafka.clients.FetchSessionHandler:445)
org.apache.kafka.common.errors.DisconnectException
[2020-05-13 11:35:42,526] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:42,528] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:42,531] WARN [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:42,532] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:42,533] WARN [Producer clientId=mysql-connector-demo-dbhistory] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:42,535] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:42,536] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:42,538] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:42,626] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:42,631] WARN [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:42,633] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:42,633] WARN [Producer clientId=mysql-connector-demo-dbhistory] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:42,636] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:42,637] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:42,639] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:42,680] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:42,839] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:42,878] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:42,882] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:42,883] WARN [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:42,887] WARN [Producer clientId=mysql-connector-demo-dbhistory] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:42,887] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:42,889] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:42,890] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:43,191] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:43,236] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:43,239] WARN [Producer clientId=mysql-connector-demo-dbhistory] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:43,292] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:43,341] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:43,341] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:43,379] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:43,386] WARN [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:43,944] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:43,991] WARN [Producer clientId=mysql-connector-demo-dbhistory] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:44,039] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:44,094] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:44,094] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:44,233] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:44,245] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:44,340] WARN [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:44,898] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:44,943] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:45,088] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:45,146] WARN [Producer clientId=mysql-connector-demo-dbhistory] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:45,248] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:45,248] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:45,351] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:45,433] INFO [Worker clientId=connect-1, groupId=connect-cluster] Broker coordinator was unreachable for 3000ms. Revoking previous assignment Assignment{error=0, leader='connect-1-765a3305-214e-4605-beb7-3bbb765dd0d8', leaderUrl='http://localhost:8083/', offset=16, connectorIds=[mysql-connector-demo], taskIds=[mysql-connector-demo-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} to avoid running tasks while not being a member the group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:137)
[2020-05-13 11:35:45,435] INFO Stopping connector mysql-connector-demo (org.apache.kafka.connect.runtime.Worker:358)
[2020-05-13 11:35:45,435] INFO Stopping task mysql-connector-demo-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-05-13 11:35:45,436] INFO Stopped connector mysql-connector-demo (org.apache.kafka.connect.runtime.Worker:374)
[2020-05-13 11:35:45,438] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1617)
[2020-05-13 11:35:45,532] WARN [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:46,048] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:46,052] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:46,101] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:46,203] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:46,236] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:46,301] WARN [Producer clientId=mysql-connector-demo-dbhistory] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:46,451] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:46,726] WARN [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:46,902] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:47,154] WARN [Producer clientId=mysql-connector-demo-dbhistory] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:47,255] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:47,255] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:47,339] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:47,410] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:47,617] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:47,764] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:47,798] WARN [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:48,068] WARN [Producer clientId=mysql-connector-demo-dbhistory] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:48,409] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:48,471] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:48,545] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:48,570] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:48,619] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:48,619] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:48,839] WARN [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:49,072] WARN [Producer clientId=mysql-connector-demo-dbhistory] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:49,414] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:49,574] WARN [Producer clientId=producer-3] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:49,574] WARN [Producer clientId=producer-1] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:49,626] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:49,649] WARN [Worker clientId=connect-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:49,730] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:49,904] WARN [Producer clientId=producer-2] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:50,077] WARN [Producer clientId=mysql-connector-demo-dbhistory] Connection to node 0 (localhost/127.0.0.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:756)
[2020-05-13 11:35:51,174] WARN [Producer clientId=producer-2] Error while fetching metadata with correlation id 8 : {connect-status=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,181] WARN [Producer clientId=producer-3] Error while fetching metadata with correlation id 6 : {connect-configs=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,182] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Error while fetching metadata with correlation id 143 : {connect-offsets=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,183] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Error while fetching metadata with correlation id 143 : {connect-status=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,184] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Error while fetching metadata with correlation id 145 : {connect-configs=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,295] WARN [Producer clientId=producer-2] Error while fetching metadata with correlation id 9 : {connect-status=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,296] WARN [Producer clientId=producer-3] Error while fetching metadata with correlation id 7 : {connect-configs=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,298] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Error while fetching metadata with correlation id 146 : {connect-configs=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,300] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Error while fetching metadata with correlation id 144 : {connect-status=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,307] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Error while fetching metadata with correlation id 144 : {connect-offsets=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,403] WARN [Producer clientId=producer-2] Error while fetching metadata with correlation id 10 : {connect-status=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,406] WARN [Producer clientId=producer-3] Error while fetching metadata with correlation id 8 : {connect-configs=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,413] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Error while fetching metadata with correlation id 147 : {connect-configs=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,415] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Error while fetching metadata with correlation id 145 : {connect-status=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,424] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Error while fetching metadata with correlation id 145 : {connect-offsets=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,512] WARN [Producer clientId=producer-2] Error while fetching metadata with correlation id 11 : {connect-status=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,517] WARN [Producer clientId=producer-3] Error while fetching metadata with correlation id 9 : {connect-configs=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,521] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Error while fetching metadata with correlation id 146 : {connect-status=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,524] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Error while fetching metadata with correlation id 148 : {connect-configs=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,543] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Error while fetching metadata with correlation id 146 : {connect-offsets=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,620] WARN [Producer clientId=producer-2] Error while fetching metadata with correlation id 12 : {connect-status=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,622] WARN [Producer clientId=producer-3] Error while fetching metadata with correlation id 10 : {connect-configs=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,628] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Error while fetching metadata with correlation id 147 : {connect-status=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,632] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Error while fetching metadata with correlation id 149 : {connect-configs=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,649] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Error while fetching metadata with correlation id 147 : {connect-offsets=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,733] WARN [Producer clientId=producer-2] Error while fetching metadata with correlation id 13 : {connect-status=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,735] WARN [Producer clientId=producer-3] Error while fetching metadata with correlation id 11 : {connect-configs=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,738] WARN [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Error while fetching metadata with correlation id 148 : {connect-status=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,740] WARN [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Error while fetching metadata with correlation id 150 : {connect-configs=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,766] WARN [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Error while fetching metadata with correlation id 148 : {connect-offsets=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1064)
[2020-05-13 11:35:51,865] INFO [Worker clientId=connect-1, groupId=connect-cluster] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2020-05-13 11:35:52,062] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1623)
[2020-05-13 11:35:52,063] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:222)
[2020-05-13 11:35:52,063] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:35:52,121] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation 26 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:484)
[2020-05-13 11:35:52,122] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 26 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-765a3305-214e-4605-beb7-3bbb765dd0d8', leaderUrl='http://localhost:8083/', offset=17, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=300000} with rebalance delay: 300000 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1542)
[2020-05-13 11:35:52,123] WARN [Worker clientId=connect-1, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1013)
[2020-05-13 11:35:52,123] INFO [Worker clientId=connect-1, groupId=connect-cluster] Current config state offset 16 is behind group assignment 17, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1074)
[2020-05-13 11:35:52,452] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 17 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1078)
[2020-05-13 11:35:52,452] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 17 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1104)
[2020-05-13 11:35:52,452] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1125)
[2020-05-13 11:40:12,166] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:66)
[2020-05-13 11:40:12,344] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-05-13 11:40:12,346] INFO Stopped http_localhost8083@6b5f8707{HTTP/1.1,[http/1.1]}{localhost:8083} (org.eclipse.jetty.server.AbstractConnector:343)
[2020-05-13 11:40:12,346] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-05-13 11:40:12,348] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-05-13 11:40:12,348] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:609)
[2020-05-13 11:40:12,348] INFO [Worker clientId=connect-1, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:583)
[2020-05-13 11:40:12,348] INFO [Worker clientId=connect-1, groupId=connect-cluster] Member connect-1-765a3305-214e-4605-beb7-3bbb765dd0d8 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:916)
[2020-05-13 11:40:12,349] WARN [Worker clientId=connect-1, groupId=connect-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:897)
[2020-05-13 11:40:12,350] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:165)
[2020-05-13 11:40:12,350] INFO [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:40:12,353] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:191)
[2020-05-13 11:40:12,353] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:272)
[2020-05-13 11:40:12,353] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:165)
[2020-05-13 11:40:12,353] INFO [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:40:12,356] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:191)
[2020-05-13 11:40:12,356] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:274)
[2020-05-13 11:40:12,356] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-05-13 11:40:12,356] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:115)
[2020-05-13 11:40:12,357] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:165)
[2020-05-13 11:40:12,357] INFO [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:40:12,365] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:191)
[2020-05-13 11:40:12,366] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:117)
[2020-05-13 11:40:12,366] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-05-13 11:40:12,367] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:287)
[2020-05-13 11:40:12,369] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:629)
[2020-05-13 11:40:12,369] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:71)
[2020-05-13 11:40:30,691] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -Djava.awt.headless=true, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Private Build, OpenJDK 64-Bit Server VM, 11.0.5, 11.0.5+10-post-Ubuntu-0ubuntu1.119.04
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.4.1.jar:bin/../libs/connect-basic-auth-extension-2.4.1.jar:bin/../libs/connect-file-2.4.1.jar:bin/../libs/connect-json-2.4.1.jar:bin/../libs/connect-mirror-2.4.1.jar:bin/../libs/connect-mirror-client-2.4.1.jar:bin/../libs/connect-runtime-2.4.1.jar:bin/../libs/connect-transforms-2.4.1.jar:bin/../libs/guava-20.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.0.jar:bin/../libs/jackson-core-2.10.0.jar:bin/../libs/jackson-databind-2.10.0.jar:bin/../libs/jackson-dataformat-csv-2.10.0.jar:bin/../libs/jackson-datatype-jdk8-2.10.0.jar:bin/../libs/jackson-jaxrs-base-2.10.0.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:bin/../libs/jackson-module-paranamer-2.10.0.jar:bin/../libs/jackson-module-scala_2.12-2.10.0.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.20.v20190813.jar:bin/../libs/jetty-continuation-9.4.20.v20190813.jar:bin/../libs/jetty-http-9.4.20.v20190813.jar:bin/../libs/jetty-io-9.4.20.v20190813.jar:bin/../libs/jetty-security-9.4.20.v20190813.jar:bin/../libs/jetty-server-9.4.20.v20190813.jar:bin/../libs/jetty-servlet-9.4.20.v20190813.jar:bin/../libs/jetty-servlets-9.4.20.v20190813.jar:bin/../libs/jetty-util-9.4.20.v20190813.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.4.1.jar:bin/../libs/kafka_2.12-2.4.1-sources.jar:bin/../libs/kafka-clients-2.4.1.jar:bin/../libs/kafka-log4j-appender-2.4.1.jar:bin/../libs/kafka-streams-2.4.1.jar:bin/../libs/kafka-streams-examples-2.4.1.jar:bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:bin/../libs/kafka-streams-test-utils-2.4.1.jar:bin/../libs/kafka-tools-2.4.1.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.6.0.jar:bin/../libs/maven-artifact-3.6.1.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.0.jar:bin/../libs/reflections-0.9.11.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.2.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.28.jar:bin/../libs/slf4j-log4j12-1.7.28.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.3-1.jar
	os.spec = Linux, amd64, 5.0.0-38-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-05-13 11:40:30,700] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectDistributed:90)
[2020-05-13 11:40:30,719] INFO Loading plugin from: /home/admina/Desktop/ghtk/kafka/debezium-connector-mysql-0.10.0.Beta2-plugin/debezium-connector-mysql (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:241)
[2020-05-13 11:40:31,476] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/admina/Desktop/ghtk/kafka/debezium-connector-mysql-0.10.0.Beta2-plugin/debezium-connector-mysql/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:264)
[2020-05-13 11:40:31,479] INFO Added plugin 'io.debezium.connector.mysql.MySqlConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:31,479] INFO Added plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:31,479] INFO Added plugin 'io.debezium.transforms.UnwrapFromEnvelope' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:31,479] INFO Added plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:31,479] INFO Added plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:31,480] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:31,480] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:31,480] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,556] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@8bcc55f (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:264)
[2020-05-13 11:40:32,556] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,556] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,557] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,558] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,558] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,558] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,558] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,559] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,559] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,559] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,559] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,559] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,559] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,559] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,559] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,560] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,560] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,560] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,560] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,560] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,560] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,560] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,561] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,561] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,561] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,561] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,561] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,561] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,561] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,561] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,562] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,562] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,562] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,562] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,562] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,562] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,562] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,562] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,563] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,563] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,563] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,563] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,563] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:40:32,564] INFO Added aliases 'MySqlConnector' and 'MySql' to plugin 'io.debezium.connector.mysql.MySqlConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,564] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,564] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,564] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,565] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,565] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,565] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,565] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,565] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,566] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,566] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,566] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,566] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,567] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,567] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,567] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,567] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,567] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,567] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,568] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,568] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,568] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,568] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,568] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,569] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,569] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,569] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,569] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:40:32,569] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,570] INFO Added alias 'ByLogicalTableRouter' to plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:40:32,570] INFO Added alias 'ExtractNewRecordState' to plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:40:32,570] INFO Added alias 'UnwrapFromEnvelope' to plugin 'io.debezium.transforms.UnwrapFromEnvelope' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:40:32,570] INFO Added alias 'EventRouter' to plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:40:32,570] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:40:32,571] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:40:32,571] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:40:32,571] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:40:32,571] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,571] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,571] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:40:32,637] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = None
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = null
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.path = [/home/admina/Desktop/ghtk/kafka/debezium-connector-mysql-0.10.0.Beta2-plugin]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = localhost
	rest.port = 8083
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:347)
[2020-05-13 11:40:32,640] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-05-13 11:40:32,643] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 11:40:32,808] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:32,808] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:32,808] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:32,808] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:32,808] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:32,808] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:32,809] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:32,809] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:32,809] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:32,809] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:32,809] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:32,809] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:32,809] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:32,809] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:32,809] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:32,810] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:40:32,810] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:40:32,810] INFO Kafka startTimeMs: 1589344832809 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:40:33,099] INFO Kafka cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-05-13 11:40:33,117] INFO Logging initialized @2752ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-05-13 11:40:33,159] INFO Added connector for http://localhost:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-05-13 11:40:33,160] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-05-13 11:40:33,165] INFO jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 11.0.5+10-post-Ubuntu-0ubuntu1.119.04 (org.eclipse.jetty.server.Server:359)
[2020-05-13 11:40:33,193] INFO Started http_localhost8083@5a12c728{HTTP/1.1,[http/1.1]}{localhost:8083} (org.eclipse.jetty.server.AbstractConnector:293)
[2020-05-13 11:40:33,193] INFO Started @2829ms (org.eclipse.jetty.server.Server:399)
[2020-05-13 11:40:33,216] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-05-13 11:40:33,217] INFO REST server listening at http://localhost:8083/, advertising URL http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-05-13 11:40:33,217] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-05-13 11:40:33,217] INFO REST admin endpoints at http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-05-13 11:40:33,217] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-05-13 11:40:33,221] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-05-13 11:40:33,230] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:40:33,230] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:40:33,231] INFO Kafka startTimeMs: 1589344833230 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:40:33,334] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 11:40:33,335] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 11:40:33,372] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:40:33,373] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:40:33,373] INFO Kafka startTimeMs: 1589344833372 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:40:33,375] INFO Kafka Connect distributed worker initialization took 2675ms (org.apache.kafka.connect.cli.ConnectDistributed:128)
[2020-05-13 11:40:33,376] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:50)
[2020-05-13 11:40:33,376] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-05-13 11:40:33,377] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:275)
[2020-05-13 11:40:33,379] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-05-13 11:40:33,379] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:108)
[2020-05-13 11:40:33,379] INFO Starting KafkaBasedLog with topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:126)
[2020-05-13 11:40:33,380] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 11:40:33,385] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,385] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,386] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,386] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,386] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,386] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,386] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,386] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,387] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,387] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,387] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,387] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,387] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,387] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,388] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,388] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:40:33,388] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:40:33,389] INFO Kafka startTimeMs: 1589344833388 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:40:33,435] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-05-13 11:40:33,437] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:40:33,461] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,462] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,462] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,462] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,462] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,462] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,463] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,463] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,464] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,464] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,464] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,464] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,464] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,465] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,465] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,465] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:40:33,466] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:40:33,466] INFO Kafka startTimeMs: 1589344833465 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:40:33,480] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:40:33,483] INFO [Producer clientId=producer-1] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:40:33,515] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,515] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,516] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,516] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,516] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,516] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,516] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,516] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,516] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,516] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,516] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,516] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,517] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,517] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,517] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:40:33,517] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:40:33,517] INFO Kafka startTimeMs: 1589344833517 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:40:33,523] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:40:33,531] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-05-13 11:40:33,532] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-05-13 11:40:33,534] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:140)
[2020-05-13 11:40:33,537] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Subscribed to partition(s): connect-offsets-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1123)
[2020-05-13 11:40:33,542] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:564)
[2020-05-13 11:40:33,579] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 11:40:33,629] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:159)
[2020-05-13 11:40:33,630] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:161)
[2020-05-13 11:40:33,630] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:110)
[2020-05-13 11:40:33,636] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-05-13 11:40:33,637] INFO Starting KafkaBasedLog with topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:126)
[2020-05-13 11:40:33,637] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 11:40:33,640] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,640] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,640] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,640] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,641] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,641] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,641] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,641] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,641] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,641] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,641] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,641] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,642] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,642] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,642] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,642] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:40:33,642] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:40:33,642] INFO Kafka startTimeMs: 1589344833642 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:40:33,675] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:40:33,682] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,682] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,683] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,684] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,684] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,684] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,684] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,684] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,684] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,684] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,684] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,684] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,684] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,684] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,685] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,685] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:40:33,685] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:40:33,685] INFO Kafka startTimeMs: 1589344833685 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:40:33,686] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:40:33,694] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,694] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,695] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,695] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,695] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,695] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,695] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,696] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,696] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,696] INFO [Producer clientId=producer-2] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:40:33,697] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,698] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,699] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,699] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,700] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,700] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:40:33,700] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:40:33,700] INFO Kafka startTimeMs: 1589344833700 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:40:33,706] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:40:33,713] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Subscribed to partition(s): connect-status-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1123)
[2020-05-13 11:40:33,713] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:564)
[2020-05-13 11:40:33,723] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Resetting offset for partition connect-status-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 11:40:33,779] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:159)
[2020-05-13 11:40:33,780] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:161)
[2020-05-13 11:40:33,781] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:262)
[2020-05-13 11:40:33,782] INFO Starting KafkaBasedLog with topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:126)
[2020-05-13 11:40:33,788] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 11:40:33,791] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,791] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,791] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,792] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,792] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,792] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,792] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,792] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,792] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,792] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,792] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,792] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,792] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,792] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,792] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:40:33,792] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:40:33,793] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:40:33,793] INFO Kafka startTimeMs: 1589344833792 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:40:33,813] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:40:33,821] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,821] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,822] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,822] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,822] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,822] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,822] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,822] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,822] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,822] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,822] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,822] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,823] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,823] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,823] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:40:33,823] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:40:33,823] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:40:33,823] INFO Kafka startTimeMs: 1589344833823 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:40:33,824] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:40:33,831] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,832] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,832] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,833] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,833] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,833] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,833] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,833] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,834] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,836] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,837] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,838] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,838] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,838] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:40:33,838] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:40:33,839] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:40:33,839] INFO Kafka startTimeMs: 1589344833838 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:40:33,845] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:40:33,850] INFO [Producer clientId=producer-3] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:40:33,852] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Subscribed to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1123)
[2020-05-13 11:40:33,852] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:564)
[2020-05-13 11:40:33,867] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 11:40:33,885] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:159)
[2020-05-13 11:40:33,886] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:161)
[2020-05-13 11:40:33,886] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:267)
[2020-05-13 11:40:33,887] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:279)
[2020-05-13 11:40:33,902] INFO [Worker clientId=connect-1, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:40:33,903] INFO [Worker clientId=connect-1, groupId=connect-cluster] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2020-05-13 11:40:33,906] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:222)
[2020-05-13 11:40:33,908] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:40:33,919] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:40:33,962] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation 28 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:484)
[2020-05-13 11:40:33,964] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 28 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-0709c41d-5be6-472a-a6ea-648bcc349f84', leaderUrl='http://localhost:8083/', offset=17, connectorIds=[mysql-connector-demo], taskIds=[mysql-connector-demo-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1542)
[2020-05-13 11:40:33,964] WARN [Worker clientId=connect-1, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1013)
[2020-05-13 11:40:33,964] INFO [Worker clientId=connect-1, groupId=connect-cluster] Current config state offset -1 is behind group assignment 17, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1074)
[2020-05-13 11:40:34,223] INFO Started o.e.j.s.ServletContextHandler@46678e49{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:824)
[2020-05-13 11:40:34,224] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-05-13 11:40:34,224] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:56)
[2020-05-13 11:40:34,380] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 17 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1078)
[2020-05-13 11:40:34,380] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 17 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1104)
[2020-05-13 11:40:34,381] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector mysql-connector-demo (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1179)
[2020-05-13 11:40:34,381] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task mysql-connector-demo-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1139)
[2020-05-13 11:40:34,387] INFO Creating task mysql-connector-demo-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-05-13 11:40:34,388] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-05-13 11:40:34,389] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-05-13 11:40:34,389] INFO Creating connector mysql-connector-demo of type io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-05-13 11:40:34,389] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-05-13 11:40:34,389] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-05-13 11:40:34,392] INFO Instantiated connector mysql-connector-demo with version 0.10.0.Beta2 of type class io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-05-13 11:40:34,394] INFO TaskConfig values: 
	task.class = class io.debezium.connector.mysql.MySqlConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-05-13 11:40:34,395] INFO Instantiated task mysql-connector-demo-0 with version 0.10.0.Beta2 of type io.debezium.connector.mysql.MySqlConnectorTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-05-13 11:40:34,395] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 11:40:34,396] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task mysql-connector-demo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-05-13 11:40:34,396] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 11:40:34,396] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mysql-connector-demo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-05-13 11:40:34,397] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mysql-connector-demo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-05-13 11:40:34,401] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:514)
[2020-05-13 11:40:34,407] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-mysql-connector-demo-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:40:34,413] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:40:34,413] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:40:34,414] INFO Kafka startTimeMs: 1589344834412 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:40:34,420] INFO [Producer clientId=connector-producer-mysql-connector-demo-0] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:40:34,424] INFO Finished creating connector mysql-connector-demo (org.apache.kafka.connect.runtime.Worker:273)
[2020-05-13 11:40:34,427] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-05-13 11:40:34,427] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-05-13 11:40:34,429] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1125)
[2020-05-13 11:40:34,475] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1440)
[2020-05-13 11:40:34,514] INFO Starting MySqlConnectorTask with configuration: (io.debezium.connector.common.BaseSourceTask:43)
[2020-05-13 11:40:34,516] INFO    connector.class = io.debezium.connector.mysql.MySqlConnector (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:40:34,516] INFO    database.user = debezium (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:40:34,517] INFO    database.server.id = 1 (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:40:34,517] INFO    database.history.kafka.bootstrap.servers = localhost:9092 (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:40:34,517] INFO    database.history.kafka.topic = dbhistory.demo (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:40:34,517] INFO    database.server.name = ghtk_chat (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:40:34,517] INFO    database.port = 3306 (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:40:34,517] INFO    include.schema.changes = true (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:40:34,517] INFO    table.whitelist = ghtk_chat.channels (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:40:34,517] INFO    task.class = io.debezium.connector.mysql.MySqlConnectorTask (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:40:34,517] INFO    database.hostname = localhost (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:40:34,517] INFO    database.password = ******** (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:40:34,517] INFO    name = mysql-connector-demo (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:40:34,858] INFO KafkaDatabaseHistory Consumer config: {key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, enable.auto.commit=false, group.id=mysql-connector-demo-dbhistory, bootstrap.servers=localhost:9092, fetch.min.bytes=1, session.timeout.ms=10000, auto.offset.reset=earliest, client.id=mysql-connector-demo-dbhistory} (io.debezium.relational.history.KafkaDatabaseHistory:171)
[2020-05-13 11:40:34,858] INFO KafkaDatabaseHistory Producer config: {retries=1, value.serializer=org.apache.kafka.common.serialization.StringSerializer, acks=1, batch.size=32768, max.block.ms=10000, bootstrap.servers=localhost:9092, buffer.memory=1048576, key.serializer=org.apache.kafka.common.serialization.StringSerializer, client.id=mysql-connector-demo-dbhistory, linger.ms=0} (io.debezium.relational.history.KafkaDatabaseHistory:172)
[2020-05-13 11:40:34,861] INFO ProducerConfig values: 
	acks = 1
	batch.size = 32768
	bootstrap.servers = [localhost:9092]
	buffer.memory = 1048576
	client.dns.lookup = default
	client.id = mysql-connector-demo-dbhistory
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 10000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:40:34,864] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:40:34,864] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:40:34,864] INFO Kafka startTimeMs: 1589344834864 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:40:34,865] INFO Found existing offset: {ts_sec=1589301382, file=mysql-bin.000008, pos=950, gtids=1507ff86-e9aa-11e9-b5ab-000c29f4a13b:1-3112, row=1, server_id=1, event=2} (io.debezium.connector.mysql.MySqlConnectorTask:82)
[2020-05-13 11:40:34,868] INFO [Producer clientId=mysql-connector-demo-dbhistory] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:40:34,870] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = mysql-connector-demo-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = mysql-connector-demo-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:40:34,872] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:40:34,872] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:40:34,873] INFO Kafka startTimeMs: 1589344834872 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:40:34,881] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:40:34,912] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = mysql-connector-demo-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = mysql-connector-demo-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:40:34,915] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:40:34,916] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:40:34,916] INFO Kafka startTimeMs: 1589344834915 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:40:34,916] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Subscribed to topic(s): dbhistory.demo (org.apache.kafka.clients.consumer.KafkaConsumer:969)
[2020-05-13 11:40:34,922] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:40:34,928] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2020-05-13 11:40:34,930] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:40:34,934] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:40:34,941] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Finished assignment for group at generation 5: {mysql-connector-demo-dbhistory-b3807f8c-f374-4b17-8885-8f69e8d6527b=Assignment(partitions=[dbhistory.demo-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:585)
[2020-05-13 11:40:34,946] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Successfully joined group with generation 5 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:484)
[2020-05-13 11:40:34,948] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Adding newly assigned partitions: dbhistory.demo-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:267)
[2020-05-13 11:40:34,952] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Found no committed offset for partition dbhistory.demo-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1241)
[2020-05-13 11:40:34,956] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Resetting offset for partition dbhistory.demo-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 11:40:35,470] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Revoke previously assigned partitions dbhistory.demo-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:286)
[2020-05-13 11:40:35,471] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Member mysql-connector-demo-dbhistory-b3807f8c-f374-4b17-8885-8f69e8d6527b sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:916)
[2020-05-13 11:40:35,496] INFO MySQL current GTID set 1507ff86-e9aa-11e9-b5ab-000c29f4a13b:1-3112 does contain the GTID set required by the connector 1507ff86-e9aa-11e9-b5ab-000c29f4a13b:1-3112 (io.debezium.connector.mysql.MySqlConnectorTask:493)
[2020-05-13 11:40:35,515] INFO GTIDs known by the server but not processed yet , for replication are available only  (io.debezium.connector.mysql.MySqlConnectorTask:498)
[2020-05-13 11:40:35,544] INFO Requested thread factory for connector MySqlConnector, id = ghtk_chat named = binlog-client (io.debezium.util.Threads:250)
[2020-05-13 11:40:35,564] INFO Creating thread debezium-mysqlconnector-ghtk_chat-binlog-client (io.debezium.util.Threads:267)
[2020-05-13 11:40:35,569] INFO Creating thread debezium-mysqlconnector-ghtk_chat-binlog-client (io.debezium.util.Threads:267)
[2020-05-13 11:40:35,664] INFO Connected to MySQL binlog at localhost:3306, starting at GTIDs 1507ff86-e9aa-11e9-b5ab-000c29f4a13b:1-3112 and binlog file 'mysql-bin.000008', pos=950, skipping 2 events plus 1 rows (io.debezium.connector.mysql.BinlogReader:1019)
[2020-05-13 11:40:35,665] INFO WorkerSourceTask{id=mysql-connector-demo-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:209)
[2020-05-13 11:40:35,666] INFO Creating thread debezium-mysqlconnector-ghtk_chat-binlog-client (io.debezium.util.Threads:267)
[2020-05-13 11:40:35,708] ERROR Error during binlog processing. Last offset stored = null, binlog reader near position = mysql-bin.000008/950 (io.debezium.connector.mysql.BinlogReader:1069)
[2020-05-13 11:40:35,710] INFO Stopped reading binlog after 0 events, no new offset was recorded (io.debezium.connector.mysql.BinlogReader:1007)
[2020-05-13 11:40:36,028] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:40:36,028] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:40:36,029] ERROR WorkerSourceTask{id=mysql-connector-demo-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:179)
org.apache.kafka.connect.errors.ConnectException: Could not open log file Error code: 1236; SQLSTATE: HY000.
	at io.debezium.connector.mysql.AbstractReader.wrap(AbstractReader.java:230)
	at io.debezium.connector.mysql.AbstractReader.failed(AbstractReader.java:197)
	at io.debezium.connector.mysql.BinlogReader$ReaderThreadLifecycleListener.onCommunicationFailure(BinlogReader.java:1033)
	at com.github.shyiko.mysql.binlog.BinaryLogClient.listenForEventPackets(BinaryLogClient.java:950)
	at com.github.shyiko.mysql.binlog.BinaryLogClient.connect(BinaryLogClient.java:580)
	at com.github.shyiko.mysql.binlog.BinaryLogClient$7.run(BinaryLogClient.java:825)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: com.github.shyiko.mysql.binlog.network.ServerException: Could not open log file
	at com.github.shyiko.mysql.binlog.BinaryLogClient.listenForEventPackets(BinaryLogClient.java:914)
	... 3 more
[2020-05-13 11:40:36,031] ERROR WorkerSourceTask{id=mysql-connector-demo-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:180)
[2020-05-13 11:40:36,031] INFO Stopping MySQL connector task (io.debezium.connector.mysql.MySqlConnectorTask:430)
[2020-05-13 11:40:36,031] INFO ChainedReader: Stopping the binlog reader (io.debezium.connector.mysql.ChainedReader:121)
[2020-05-13 11:40:36,031] INFO Discarding 0 unsent record(s) due to the connector shutting down (io.debezium.connector.mysql.BinlogReader:129)
[2020-05-13 11:40:36,032] INFO Discarding 0 unsent record(s) due to the connector shutting down (io.debezium.connector.mysql.BinlogReader:129)
[2020-05-13 11:40:36,032] INFO [Producer clientId=mysql-connector-demo-dbhistory] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:40:36,039] INFO Connector task finished all work and is now shutdown (io.debezium.connector.mysql.MySqlConnectorTask:465)
[2020-05-13 11:40:36,039] INFO [Producer clientId=connector-producer-mysql-connector-demo-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:40:44,424] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:40:44,427] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:40:54,428] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:40:54,433] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:41:04,434] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:41:04,436] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:41:14,437] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:41:14,437] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:41:24,437] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:41:24,445] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:41:34,445] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:41:34,447] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:41:44,448] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:41:44,457] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:41:54,458] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:41:54,460] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:42:04,461] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:42:04,461] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:42:14,461] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:42:14,465] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:42:24,465] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:42:24,475] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:42:34,476] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:42:34,476] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:42:44,476] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:42:44,479] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:42:54,479] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:42:54,480] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:43:04,480] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:43:04,480] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:43:14,481] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:43:14,493] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:43:24,493] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:43:24,494] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:43:34,494] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:43:34,496] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:43:44,496] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:43:44,497] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:43:54,497] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:43:54,497] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:44:04,498] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:44:04,512] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:44:14,512] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:44:14,513] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:44:24,513] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:44:24,513] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:44:34,514] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:44:34,518] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:44:44,518] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:44:44,520] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:44:54,520] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:44:54,521] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:45:04,521] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:45:04,540] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:45:14,540] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:45:14,541] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:45:24,541] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:45:24,541] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:45:34,542] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:45:34,562] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:45:44,562] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:45:44,565] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:45:54,566] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:45:54,587] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:46:04,587] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:46:04,588] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:46:14,588] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:46:14,610] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:46:24,610] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:46:24,614] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:46:34,614] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:46:34,616] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:46:44,617] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:46:44,620] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:46:54,621] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:46:54,621] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:47:04,621] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:47:04,627] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:47:05,322] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:66)
[2020-05-13 11:47:05,323] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:321)
[2020-05-13 11:47:05,325] INFO Stopped http_localhost8083@5a12c728{HTTP/1.1,[http/1.1]}{localhost:8083} (org.eclipse.jetty.server.AbstractConnector:343)
[2020-05-13 11:47:05,326] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:158)
[2020-05-13 11:47:05,327] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:338)
[2020-05-13 11:47:05,327] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:609)
[2020-05-13 11:47:05,327] INFO [Worker clientId=connect-1, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:583)
[2020-05-13 11:47:05,329] INFO Stopping connector mysql-connector-demo (org.apache.kafka.connect.runtime.Worker:358)
[2020-05-13 11:47:05,333] INFO Stopping task mysql-connector-demo-0 (org.apache.kafka.connect.runtime.Worker:704)
[2020-05-13 11:47:05,333] INFO Stopped connector mysql-connector-demo (org.apache.kafka.connect.runtime.Worker:374)
[2020-05-13 11:47:05,334] INFO [Worker clientId=connect-1, groupId=connect-cluster] Member connect-1-0709c41d-5be6-472a-a6ea-648bcc349f84 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:916)
[2020-05-13 11:47:05,335] WARN [Worker clientId=connect-1, groupId=connect-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:897)
[2020-05-13 11:47:05,336] INFO Stopping KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:165)
[2020-05-13 11:47:05,337] INFO [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:47:05,341] INFO Stopped KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:191)
[2020-05-13 11:47:05,341] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:272)
[2020-05-13 11:47:05,341] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:165)
[2020-05-13 11:47:05,343] INFO [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:47:05,346] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:191)
[2020-05-13 11:47:05,346] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:274)
[2020-05-13 11:47:05,346] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:198)
[2020-05-13 11:47:05,347] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:115)
[2020-05-13 11:47:05,347] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:165)
[2020-05-13 11:47:05,347] INFO [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:47:05,350] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:191)
[2020-05-13 11:47:05,351] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:117)
[2020-05-13 11:47:05,351] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:219)
[2020-05-13 11:47:05,352] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:287)
[2020-05-13 11:47:05,355] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:629)
[2020-05-13 11:47:05,355] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:71)
[2020-05-13 11:47:06,447] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -Djava.awt.headless=true, -Dkafka.logs.dir=bin/../logs, -Dlog4j.configuration=file:bin/../config/connect-log4j.properties
	jvm.spec = Private Build, OpenJDK 64-Bit Server VM, 11.0.5, 11.0.5+10-post-Ubuntu-0ubuntu1.119.04
	jvm.classpath = bin/../libs/activation-1.1.1.jar:bin/../libs/aopalliance-repackaged-2.5.0.jar:bin/../libs/argparse4j-0.7.0.jar:bin/../libs/audience-annotations-0.5.0.jar:bin/../libs/commons-cli-1.4.jar:bin/../libs/commons-lang3-3.8.1.jar:bin/../libs/connect-api-2.4.1.jar:bin/../libs/connect-basic-auth-extension-2.4.1.jar:bin/../libs/connect-file-2.4.1.jar:bin/../libs/connect-json-2.4.1.jar:bin/../libs/connect-mirror-2.4.1.jar:bin/../libs/connect-mirror-client-2.4.1.jar:bin/../libs/connect-runtime-2.4.1.jar:bin/../libs/connect-transforms-2.4.1.jar:bin/../libs/guava-20.0.jar:bin/../libs/hk2-api-2.5.0.jar:bin/../libs/hk2-locator-2.5.0.jar:bin/../libs/hk2-utils-2.5.0.jar:bin/../libs/jackson-annotations-2.10.0.jar:bin/../libs/jackson-core-2.10.0.jar:bin/../libs/jackson-databind-2.10.0.jar:bin/../libs/jackson-dataformat-csv-2.10.0.jar:bin/../libs/jackson-datatype-jdk8-2.10.0.jar:bin/../libs/jackson-jaxrs-base-2.10.0.jar:bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:bin/../libs/jackson-module-paranamer-2.10.0.jar:bin/../libs/jackson-module-scala_2.12-2.10.0.jar:bin/../libs/jakarta.activation-api-1.2.1.jar:bin/../libs/jakarta.annotation-api-1.3.4.jar:bin/../libs/jakarta.inject-2.5.0.jar:bin/../libs/jakarta.ws.rs-api-2.1.5.jar:bin/../libs/jakarta.xml.bind-api-2.3.2.jar:bin/../libs/javassist-3.22.0-CR2.jar:bin/../libs/javax.servlet-api-3.1.0.jar:bin/../libs/javax.ws.rs-api-2.1.1.jar:bin/../libs/jaxb-api-2.3.0.jar:bin/../libs/jersey-client-2.28.jar:bin/../libs/jersey-common-2.28.jar:bin/../libs/jersey-container-servlet-2.28.jar:bin/../libs/jersey-container-servlet-core-2.28.jar:bin/../libs/jersey-hk2-2.28.jar:bin/../libs/jersey-media-jaxb-2.28.jar:bin/../libs/jersey-server-2.28.jar:bin/../libs/jetty-client-9.4.20.v20190813.jar:bin/../libs/jetty-continuation-9.4.20.v20190813.jar:bin/../libs/jetty-http-9.4.20.v20190813.jar:bin/../libs/jetty-io-9.4.20.v20190813.jar:bin/../libs/jetty-security-9.4.20.v20190813.jar:bin/../libs/jetty-server-9.4.20.v20190813.jar:bin/../libs/jetty-servlet-9.4.20.v20190813.jar:bin/../libs/jetty-servlets-9.4.20.v20190813.jar:bin/../libs/jetty-util-9.4.20.v20190813.jar:bin/../libs/jopt-simple-5.0.4.jar:bin/../libs/kafka_2.12-2.4.1.jar:bin/../libs/kafka_2.12-2.4.1-sources.jar:bin/../libs/kafka-clients-2.4.1.jar:bin/../libs/kafka-log4j-appender-2.4.1.jar:bin/../libs/kafka-streams-2.4.1.jar:bin/../libs/kafka-streams-examples-2.4.1.jar:bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:bin/../libs/kafka-streams-test-utils-2.4.1.jar:bin/../libs/kafka-tools-2.4.1.jar:bin/../libs/log4j-1.2.17.jar:bin/../libs/lz4-java-1.6.0.jar:bin/../libs/maven-artifact-3.6.1.jar:bin/../libs/metrics-core-2.2.0.jar:bin/../libs/netty-buffer-4.1.45.Final.jar:bin/../libs/netty-codec-4.1.45.Final.jar:bin/../libs/netty-common-4.1.45.Final.jar:bin/../libs/netty-handler-4.1.45.Final.jar:bin/../libs/netty-resolver-4.1.45.Final.jar:bin/../libs/netty-transport-4.1.45.Final.jar:bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:bin/../libs/osgi-resource-locator-1.0.1.jar:bin/../libs/paranamer-2.8.jar:bin/../libs/plexus-utils-3.2.0.jar:bin/../libs/reflections-0.9.11.jar:bin/../libs/rocksdbjni-5.18.3.jar:bin/../libs/scala-collection-compat_2.12-2.1.2.jar:bin/../libs/scala-java8-compat_2.12-0.9.0.jar:bin/../libs/scala-library-2.12.10.jar:bin/../libs/scala-logging_2.12-3.9.2.jar:bin/../libs/scala-reflect-2.12.10.jar:bin/../libs/slf4j-api-1.7.28.jar:bin/../libs/slf4j-log4j12-1.7.28.jar:bin/../libs/snappy-java-1.1.7.3.jar:bin/../libs/validation-api-2.0.1.Final.jar:bin/../libs/zookeeper-3.5.7.jar:bin/../libs/zookeeper-jute-3.5.7.jar:bin/../libs/zstd-jni-1.4.3-1.jar
	os.spec = Linux, amd64, 5.0.0-38-generic
	os.vcpus = 8
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2020-05-13 11:47:06,455] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectDistributed:90)
[2020-05-13 11:47:06,478] INFO Loading plugin from: /home/admina/Desktop/ghtk/kafka/debezium-connector-mysql-0.10.0.Beta2-plugin/debezium-connector-mysql (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:241)
[2020-05-13 11:47:07,068] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/admina/Desktop/ghtk/kafka/debezium-connector-mysql-0.10.0.Beta2-plugin/debezium-connector-mysql/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:264)
[2020-05-13 11:47:07,070] INFO Added plugin 'io.debezium.connector.mysql.MySqlConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:07,071] INFO Added plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:07,071] INFO Added plugin 'io.debezium.transforms.UnwrapFromEnvelope' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:07,071] INFO Added plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:07,071] INFO Added plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:07,072] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:07,072] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:07,072] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,190] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@8bcc55f (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:264)
[2020-05-13 11:47:08,215] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,216] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,217] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,221] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,222] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,222] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,223] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,223] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,223] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,223] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,223] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,224] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,224] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,224] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,224] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,224] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,225] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,225] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,225] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,227] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,227] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,227] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,227] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,227] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,228] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,228] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,228] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,228] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,228] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,228] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,229] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,229] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,229] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,229] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,229] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,229] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,229] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,230] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,230] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,230] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,230] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,230] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,230] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:193)
[2020-05-13 11:47:08,231] INFO Added aliases 'MySqlConnector' and 'MySql' to plugin 'io.debezium.connector.mysql.MySqlConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,232] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,232] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,232] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,232] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,232] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,233] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,233] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,233] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,233] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,233] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,234] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,234] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,234] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,234] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,234] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,234] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,235] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,235] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,235] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,235] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,235] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,235] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,236] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,236] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,236] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,236] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,236] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:47:08,236] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,237] INFO Added alias 'ByLogicalTableRouter' to plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:47:08,237] INFO Added alias 'ExtractNewRecordState' to plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:47:08,237] INFO Added alias 'UnwrapFromEnvelope' to plugin 'io.debezium.transforms.UnwrapFromEnvelope' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:47:08,237] INFO Added alias 'EventRouter' to plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:47:08,238] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:47:08,238] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:47:08,238] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:47:08,238] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:411)
[2020-05-13 11:47:08,239] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,239] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,239] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:414)
[2020-05-13 11:47:08,335] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = None
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = null
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.path = [/home/admina/Desktop/ghtk/kafka/debezium-connector-mysql-0.10.0.Beta2-plugin]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = localhost
	rest.port = 8083
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:347)
[2020-05-13 11:47:08,339] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
[2020-05-13 11:47:08,342] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 11:47:08,524] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:08,525] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:08,525] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:08,525] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:08,525] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:08,525] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:08,525] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:08,526] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:08,526] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:08,526] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:08,526] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:08,526] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:08,526] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:08,526] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:08,526] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:08,527] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:47:08,527] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:47:08,527] INFO Kafka startTimeMs: 1589345228527 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:47:08,823] INFO Kafka cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.connect.util.ConnectUtils:59)
[2020-05-13 11:47:08,845] INFO Logging initialized @2649ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:169)
[2020-05-13 11:47:08,894] INFO Added connector for http://localhost:8083 (org.apache.kafka.connect.runtime.rest.RestServer:131)
[2020-05-13 11:47:08,896] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:203)
[2020-05-13 11:47:08,904] INFO jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 11.0.5+10-post-Ubuntu-0ubuntu1.119.04 (org.eclipse.jetty.server.Server:359)
[2020-05-13 11:47:08,939] INFO Started http_localhost8083@1a1d3c1a{HTTP/1.1,[http/1.1]}{localhost:8083} (org.eclipse.jetty.server.AbstractConnector:293)
[2020-05-13 11:47:08,940] INFO Started @2745ms (org.eclipse.jetty.server.Server:399)
[2020-05-13 11:47:08,967] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-05-13 11:47:08,967] INFO REST server listening at http://localhost:8083/, advertising URL http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:218)
[2020-05-13 11:47:08,967] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-05-13 11:47:08,967] INFO REST admin endpoints at http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2020-05-13 11:47:08,968] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:365)
[2020-05-13 11:47:08,972] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2020-05-13 11:47:08,981] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:47:08,981] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:47:08,981] INFO Kafka startTimeMs: 1589345228981 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:47:09,095] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 11:47:09,096] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 11:47:09,135] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:47:09,135] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:47:09,135] INFO Kafka startTimeMs: 1589345229135 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:47:09,138] INFO Kafka Connect distributed worker initialization took 2682ms (org.apache.kafka.connect.cli.ConnectDistributed:128)
[2020-05-13 11:47:09,138] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:50)
[2020-05-13 11:47:09,139] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:223)
[2020-05-13 11:47:09,139] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:275)
[2020-05-13 11:47:09,140] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:184)
[2020-05-13 11:47:09,140] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:108)
[2020-05-13 11:47:09,140] INFO Starting KafkaBasedLog with topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:126)
[2020-05-13 11:47:09,141] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 11:47:09,146] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,146] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,146] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,146] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,147] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,147] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,147] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,147] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,147] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,147] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,147] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,147] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,148] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,148] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,148] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,148] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:47:09,148] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:47:09,148] INFO Kafka startTimeMs: 1589345229148 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:47:09,192] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:47:09,202] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:240)
[2020-05-13 11:47:09,217] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,218] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,218] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,218] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,218] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,219] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,219] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,219] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,219] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,219] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,219] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,220] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,220] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,220] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,220] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,220] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:47:09,220] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:47:09,220] INFO Kafka startTimeMs: 1589345229220 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:47:09,229] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:47:09,230] INFO [Producer clientId=producer-1] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:47:09,267] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,268] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,268] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,268] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,268] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,268] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,268] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,268] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,269] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,269] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,269] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,269] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,269] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,269] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,269] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:47:09,269] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:47:09,270] INFO Kafka startTimeMs: 1589345229269 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:47:09,278] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:47:09,300] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Subscribed to partition(s): connect-offsets-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1123)
[2020-05-13 11:47:09,300] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:333)
[2020-05-13 11:47:09,300] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:338)
[2020-05-13 11:47:09,302] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:140)
[2020-05-13 11:47:09,304] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:564)
[2020-05-13 11:47:09,344] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 11:47:09,393] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:159)
[2020-05-13 11:47:09,394] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:161)
[2020-05-13 11:47:09,394] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:110)
[2020-05-13 11:47:09,396] INFO Worker started (org.apache.kafka.connect.runtime.Worker:191)
[2020-05-13 11:47:09,397] INFO Starting KafkaBasedLog with topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:126)
[2020-05-13 11:47:09,397] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 11:47:09,400] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,400] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,400] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,400] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,400] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,400] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,400] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,401] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,401] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,401] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,401] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,401] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,401] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,401] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,401] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,402] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:47:09,402] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:47:09,402] INFO Kafka startTimeMs: 1589345229401 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:47:09,424] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:47:09,429] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,430] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,431] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,431] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,431] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,431] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,431] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,432] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,432] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,432] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,432] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,432] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,432] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,432] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,432] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,432] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:47:09,432] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:47:09,433] INFO Kafka startTimeMs: 1589345229432 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:47:09,434] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:47:09,434] INFO [Producer clientId=producer-2] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:47:09,443] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,445] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,445] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,445] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,445] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,445] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,446] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,446] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,446] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,446] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,446] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,446] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,446] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,446] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,447] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:47:09,447] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:47:09,448] INFO Kafka startTimeMs: 1589345229446 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:47:09,452] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:47:09,460] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Subscribed to partition(s): connect-status-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1123)
[2020-05-13 11:47:09,461] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:564)
[2020-05-13 11:47:09,479] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Resetting offset for partition connect-status-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 11:47:09,533] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:159)
[2020-05-13 11:47:09,535] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:161)
[2020-05-13 11:47:09,546] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:262)
[2020-05-13 11:47:09,546] INFO Starting KafkaBasedLog with topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:126)
[2020-05-13 11:47:09,550] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:347)
[2020-05-13 11:47:09,555] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,555] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,555] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,556] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,556] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,556] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,556] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,556] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,556] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,556] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,556] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,556] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,557] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,557] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,557] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:355)
[2020-05-13 11:47:09,557] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:47:09,557] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:47:09,558] INFO Kafka startTimeMs: 1589345229557 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:47:09,599] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:47:09,604] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,604] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,605] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,605] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,605] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,605] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,605] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,606] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,606] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,606] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,606] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,606] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,606] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,606] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,606] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:355)
[2020-05-13 11:47:09,607] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:47:09,607] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:47:09,607] INFO Kafka startTimeMs: 1589345229607 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:47:09,608] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:47:09,608] INFO [Producer clientId=producer-3] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:47:09,614] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,622] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,622] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,622] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,622] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,622] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,622] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,623] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,623] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,623] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,623] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,624] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,624] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,624] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:355)
[2020-05-13 11:47:09,624] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:47:09,624] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:47:09,624] INFO Kafka startTimeMs: 1589345229624 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:47:09,634] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:47:09,648] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Subscribed to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1123)
[2020-05-13 11:47:09,649] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:564)
[2020-05-13 11:47:09,659] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 11:47:09,673] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:159)
[2020-05-13 11:47:09,674] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:161)
[2020-05-13 11:47:09,676] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:267)
[2020-05-13 11:47:09,679] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:279)
[2020-05-13 11:47:09,691] INFO [Worker clientId=connect-1, groupId=connect-cluster] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:47:09,693] INFO [Worker clientId=connect-1, groupId=connect-cluster] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2020-05-13 11:47:09,697] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:222)
[2020-05-13 11:47:09,698] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:47:09,715] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:47:09,752] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation 30 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:484)
[2020-05-13 11:47:09,757] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 30 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-66f3e81c-8246-4e30-b6db-a309eaca90dc', leaderUrl='http://localhost:8083/', offset=18, connectorIds=[mysql-connector-demo], taskIds=[mysql-connector-demo-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1542)
[2020-05-13 11:47:09,758] WARN [Worker clientId=connect-1, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1013)
[2020-05-13 11:47:09,760] INFO [Worker clientId=connect-1, groupId=connect-cluster] Current config state offset -1 is behind group assignment 18, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1074)
[2020-05-13 11:47:10,059] INFO Started o.e.j.s.ServletContextHandler@35636217{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:824)
[2020-05-13 11:47:10,059] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:313)
[2020-05-13 11:47:10,059] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:56)
[2020-05-13 11:47:10,166] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 18 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1078)
[2020-05-13 11:47:10,166] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 18 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1104)
[2020-05-13 11:47:10,167] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector mysql-connector-demo (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1179)
[2020-05-13 11:47:10,168] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task mysql-connector-demo-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1139)
[2020-05-13 11:47:10,173] INFO Creating task mysql-connector-demo-0 (org.apache.kafka.connect.runtime.Worker:419)
[2020-05-13 11:47:10,174] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-05-13 11:47:10,175] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:347)
[2020-05-13 11:47:10,175] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-05-13 11:47:10,175] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-05-13 11:47:10,175] INFO Creating connector mysql-connector-demo of type io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:251)
[2020-05-13 11:47:10,178] INFO Instantiated connector mysql-connector-demo with version 0.10.0.Beta2 of type class io.debezium.connector.mysql.MySqlConnector (org.apache.kafka.connect.runtime.Worker:254)
[2020-05-13 11:47:10,180] INFO TaskConfig values: 
	task.class = class io.debezium.connector.mysql.MySqlConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:347)
[2020-05-13 11:47:10,182] INFO Instantiated task mysql-connector-demo-0 with version 0.10.0.Beta2 of type io.debezium.connector.mysql.MySqlConnectorTask (org.apache.kafka.connect.runtime.Worker:434)
[2020-05-13 11:47:10,183] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 11:47:10,183] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task mysql-connector-demo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:447)
[2020-05-13 11:47:10,183] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:347)
[2020-05-13 11:47:10,183] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mysql-connector-demo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:453)
[2020-05-13 11:47:10,184] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mysql-connector-demo-0 using the worker config (org.apache.kafka.connect.runtime.Worker:460)
[2020-05-13 11:47:10,188] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:514)
[2020-05-13 11:47:10,192] INFO ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = connector-producer-mysql-connector-demo-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 2147483647
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:47:10,197] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:47:10,197] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:47:10,198] INFO Kafka startTimeMs: 1589345230197 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:47:10,206] INFO Finished creating connector mysql-connector-demo (org.apache.kafka.connect.runtime.Worker:273)
[2020-05-13 11:47:10,214] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:347)
[2020-05-13 11:47:10,208] INFO [Producer clientId=connector-producer-mysql-connector-demo-0] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:47:10,218] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.mysql.MySqlConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = mysql-connector-demo
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:347)
[2020-05-13 11:47:10,256] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1125)
[2020-05-13 11:47:10,277] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1440)
[2020-05-13 11:47:10,324] INFO Starting MySqlConnectorTask with configuration: (io.debezium.connector.common.BaseSourceTask:43)
[2020-05-13 11:47:10,326] INFO    connector.class = io.debezium.connector.mysql.MySqlConnector (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:47:10,326] INFO    database.user = debezium (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:47:10,326] INFO    database.server.id = 1 (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:47:10,326] INFO    database.history.kafka.bootstrap.servers = localhost:9092 (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:47:10,326] INFO    database.history.kafka.topic = dbhistory.demo (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:47:10,326] INFO    database.server.name = ghtk_chat (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:47:10,326] INFO    database.port = 3306 (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:47:10,326] INFO    include.schema.changes = true (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:47:10,327] INFO    table.whitelist = ghtk_chat.channels (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:47:10,327] INFO    task.class = io.debezium.connector.mysql.MySqlConnectorTask (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:47:10,327] INFO    database.hostname = localhost (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:47:10,327] INFO    database.password = ******** (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:47:10,327] INFO    name = mysql-connector-demo (io.debezium.connector.common.BaseSourceTask:45)
[2020-05-13 11:47:10,627] INFO KafkaDatabaseHistory Consumer config: {key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, enable.auto.commit=false, group.id=mysql-connector-demo-dbhistory, bootstrap.servers=localhost:9092, fetch.min.bytes=1, session.timeout.ms=10000, auto.offset.reset=earliest, client.id=mysql-connector-demo-dbhistory} (io.debezium.relational.history.KafkaDatabaseHistory:171)
[2020-05-13 11:47:10,627] INFO KafkaDatabaseHistory Producer config: {retries=1, value.serializer=org.apache.kafka.common.serialization.StringSerializer, acks=1, batch.size=32768, max.block.ms=10000, bootstrap.servers=localhost:9092, buffer.memory=1048576, key.serializer=org.apache.kafka.common.serialization.StringSerializer, client.id=mysql-connector-demo-dbhistory, linger.ms=0} (io.debezium.relational.history.KafkaDatabaseHistory:172)
[2020-05-13 11:47:10,630] INFO ProducerConfig values: 
	acks = 1
	batch.size = 32768
	bootstrap.servers = [localhost:9092]
	buffer.memory = 1048576
	client.dns.lookup = default
	client.id = mysql-connector-demo-dbhistory
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 10000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
 (org.apache.kafka.clients.producer.ProducerConfig:347)
[2020-05-13 11:47:10,634] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:47:10,634] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:47:10,634] INFO Kafka startTimeMs: 1589345230634 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:47:10,635] INFO Found existing offset: {ts_sec=1589301382, file=mysql-bin.000008, pos=950, gtids=1507ff86-e9aa-11e9-b5ab-000c29f4a13b:1-3112, row=1, server_id=1, event=2} (io.debezium.connector.mysql.MySqlConnectorTask:82)
[2020-05-13 11:47:10,638] INFO [Producer clientId=mysql-connector-demo-dbhistory] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:47:10,640] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = mysql-connector-demo-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = mysql-connector-demo-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:47:10,648] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:47:10,649] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:47:10,649] INFO Kafka startTimeMs: 1589345230648 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:47:10,652] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:47:10,675] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = mysql-connector-demo-dbhistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = mysql-connector-demo-dbhistory
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:347)
[2020-05-13 11:47:10,677] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser:117)
[2020-05-13 11:47:10,677] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser:118)
[2020-05-13 11:47:10,677] INFO Kafka startTimeMs: 1589345230677 (org.apache.kafka.common.utils.AppInfoParser:119)
[2020-05-13 11:47:10,678] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Subscribed to topic(s): dbhistory.demo (org.apache.kafka.clients.consumer.KafkaConsumer:969)
[2020-05-13 11:47:10,682] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Cluster ID: A5w5HCZ6T3umJvw0AEmt6A (org.apache.kafka.clients.Metadata:259)
[2020-05-13 11:47:10,690] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Discovered group coordinator localhost:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:756)
[2020-05-13 11:47:10,693] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:47:10,700] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:533)
[2020-05-13 11:47:10,703] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Finished assignment for group at generation 1: {mysql-connector-demo-dbhistory-38972b5e-d3d1-4935-870a-c19b8eebf32b=Assignment(partitions=[dbhistory.demo-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:585)
[2020-05-13 11:47:10,706] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Successfully joined group with generation 1 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:484)
[2020-05-13 11:47:10,707] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Adding newly assigned partitions: dbhistory.demo-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:267)
[2020-05-13 11:47:10,710] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Found no committed offset for partition dbhistory.demo-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1241)
[2020-05-13 11:47:10,712] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Resetting offset for partition dbhistory.demo-0 to offset 0. (org.apache.kafka.clients.consumer.internals.SubscriptionState:381)
[2020-05-13 11:47:11,273] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Revoke previously assigned partitions dbhistory.demo-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:286)
[2020-05-13 11:47:11,274] INFO [Consumer clientId=mysql-connector-demo-dbhistory, groupId=mysql-connector-demo-dbhistory] Member mysql-connector-demo-dbhistory-38972b5e-d3d1-4935-870a-c19b8eebf32b sending LeaveGroup request to coordinator localhost:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:916)
[2020-05-13 11:47:11,301] INFO MySQL current GTID set 1507ff86-e9aa-11e9-b5ab-000c29f4a13b:1-3112 does contain the GTID set required by the connector 1507ff86-e9aa-11e9-b5ab-000c29f4a13b:1-3112 (io.debezium.connector.mysql.MySqlConnectorTask:493)
[2020-05-13 11:47:11,314] INFO GTIDs known by the server but not processed yet , for replication are available only  (io.debezium.connector.mysql.MySqlConnectorTask:498)
[2020-05-13 11:47:11,336] INFO Requested thread factory for connector MySqlConnector, id = ghtk_chat named = binlog-client (io.debezium.util.Threads:250)
[2020-05-13 11:47:11,364] INFO Creating thread debezium-mysqlconnector-ghtk_chat-binlog-client (io.debezium.util.Threads:267)
[2020-05-13 11:47:11,368] INFO Creating thread debezium-mysqlconnector-ghtk_chat-binlog-client (io.debezium.util.Threads:267)
[2020-05-13 11:47:11,502] INFO Connected to MySQL binlog at localhost:3306, starting at GTIDs 1507ff86-e9aa-11e9-b5ab-000c29f4a13b:1-3112 and binlog file 'mysql-bin.000008', pos=950, skipping 2 events plus 1 rows (io.debezium.connector.mysql.BinlogReader:1019)
[2020-05-13 11:47:11,502] INFO WorkerSourceTask{id=mysql-connector-demo-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSourceTask:209)
[2020-05-13 11:47:11,508] INFO Creating thread debezium-mysqlconnector-ghtk_chat-binlog-client (io.debezium.util.Threads:267)
[2020-05-13 11:47:11,543] ERROR Error during binlog processing. Last offset stored = null, binlog reader near position = mysql-bin.000008/950 (io.debezium.connector.mysql.BinlogReader:1069)
[2020-05-13 11:47:11,544] INFO Stopped reading binlog after 0 events, no new offset was recorded (io.debezium.connector.mysql.BinlogReader:1007)
[2020-05-13 11:47:11,825] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:47:11,826] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:47:11,826] ERROR WorkerSourceTask{id=mysql-connector-demo-0} Task threw an uncaught and unrecoverable exception (org.apache.kafka.connect.runtime.WorkerTask:179)
org.apache.kafka.connect.errors.ConnectException: Could not find first log file name in binary log index file Error code: 1236; SQLSTATE: HY000.
	at io.debezium.connector.mysql.AbstractReader.wrap(AbstractReader.java:230)
	at io.debezium.connector.mysql.AbstractReader.failed(AbstractReader.java:197)
	at io.debezium.connector.mysql.BinlogReader$ReaderThreadLifecycleListener.onCommunicationFailure(BinlogReader.java:1033)
	at com.github.shyiko.mysql.binlog.BinaryLogClient.listenForEventPackets(BinaryLogClient.java:950)
	at com.github.shyiko.mysql.binlog.BinaryLogClient.connect(BinaryLogClient.java:580)
	at com.github.shyiko.mysql.binlog.BinaryLogClient$7.run(BinaryLogClient.java:825)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: com.github.shyiko.mysql.binlog.network.ServerException: Could not find first log file name in binary log index file
	at com.github.shyiko.mysql.binlog.BinaryLogClient.listenForEventPackets(BinaryLogClient.java:914)
	... 3 more
[2020-05-13 11:47:11,829] ERROR WorkerSourceTask{id=mysql-connector-demo-0} Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:180)
[2020-05-13 11:47:11,829] INFO Stopping MySQL connector task (io.debezium.connector.mysql.MySqlConnectorTask:430)
[2020-05-13 11:47:11,829] INFO ChainedReader: Stopping the binlog reader (io.debezium.connector.mysql.ChainedReader:121)
[2020-05-13 11:47:11,829] INFO Discarding 0 unsent record(s) due to the connector shutting down (io.debezium.connector.mysql.BinlogReader:129)
[2020-05-13 11:47:11,830] INFO Discarding 0 unsent record(s) due to the connector shutting down (io.debezium.connector.mysql.BinlogReader:129)
[2020-05-13 11:47:11,830] INFO [Producer clientId=mysql-connector-demo-dbhistory] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:47:11,837] INFO Connector task finished all work and is now shutdown (io.debezium.connector.mysql.MySqlConnectorTask:465)
[2020-05-13 11:47:11,838] INFO [Producer clientId=connector-producer-mysql-connector-demo-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1183)
[2020-05-13 11:47:20,217] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:47:20,219] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:47:30,220] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:47:30,222] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:47:40,223] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:47:40,226] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:47:50,227] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:47:50,230] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:48:00,231] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:48:00,235] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:48:10,235] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:48:10,239] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:48:20,239] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:48:20,245] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:48:30,246] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:48:30,253] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:48:40,254] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:48:40,257] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:48:50,258] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:48:50,266] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:49:00,267] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:49:00,275] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:49:10,275] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:49:10,279] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:49:20,279] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:49:20,288] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:49:30,289] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:49:30,299] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:49:40,299] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:49:40,303] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:49:50,303] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:49:50,307] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:50:00,307] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:50:00,317] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:50:10,318] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:50:10,322] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:50:20,322] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:50:20,333] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:50:30,334] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:50:30,334] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:50:40,335] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:50:40,338] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:50:50,339] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:50:50,342] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:51:00,343] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:51:00,345] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:51:10,346] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:51:10,359] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:51:20,360] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:51:20,360] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:51:30,361] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:51:30,363] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:51:40,363] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:51:40,366] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:51:50,367] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:51:50,370] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:52:00,371] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:52:00,372] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:52:10,373] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:52:10,389] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:52:20,390] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:52:20,406] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:52:30,407] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:52:30,425] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:52:40,425] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:52:40,429] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:52:50,429] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:52:50,432] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:53:00,433] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:53:00,452] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:53:10,452] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:53:10,471] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:53:20,472] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:53:20,491] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:53:30,492] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:53:30,511] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:53:40,512] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:53:40,515] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:53:50,515] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:53:50,518] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:54:00,519] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:54:00,522] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:54:10,523] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:54:10,526] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:54:20,527] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:54:20,548] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:54:30,549] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:54:30,552] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:54:40,553] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:54:40,556] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:54:50,556] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:54:50,559] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:55:00,560] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:55:00,563] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:55:10,564] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:55:10,567] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:55:20,567] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:55:20,591] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:55:30,592] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:55:30,595] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:55:40,596] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:55:40,599] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:55:50,600] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:55:50,603] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:56:00,604] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:56:00,606] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:56:10,606] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:56:10,610] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:56:20,610] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:56:20,628] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:56:30,629] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:56:30,632] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:56:40,633] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:56:40,651] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:56:50,652] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:56:50,655] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:57:00,656] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:57:00,659] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:57:10,660] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:57:10,680] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:57:20,680] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:57:20,700] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:57:30,701] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:57:30,722] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:57:40,722] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:57:40,744] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:57:50,744] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:57:50,748] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:58:00,748] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:58:00,751] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:58:10,752] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:58:10,755] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:58:20,756] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:58:20,778] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:58:30,779] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:58:30,801] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:58:40,802] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:58:40,826] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:58:50,826] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:58:50,829] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:59:00,830] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:59:00,833] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:59:10,834] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:59:10,837] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:59:20,838] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:59:20,863] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:59:30,864] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:59:30,865] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:59:40,865] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:59:40,868] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
[2020-05-13 11:59:50,869] INFO WorkerSourceTask{id=mysql-connector-demo-0} Committing offsets (org.apache.kafka.connect.runtime.WorkerSourceTask:416)
[2020-05-13 11:59:50,872] INFO WorkerSourceTask{id=mysql-connector-demo-0} flushing 0 outstanding messages for offset commit (org.apache.kafka.connect.runtime.WorkerSourceTask:433)
